{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries for NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n",
      "../trained_models/Cardiomegaly\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os.path\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "from torch.utils.tensorboard import SummaryWriter  # to print to tensorboard\n",
    "import torchvision\n",
    "\n",
    "# Name of the disease label\n",
    "disease = 'Cardiomegaly'\n",
    "\n",
    "# Directory to save models\n",
    "models_dir_prefix = '../trained_models/'\n",
    "models_dir_suffix = disease\n",
    "models_dir = models_dir_prefix+models_dir_suffix\n",
    "print(models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset Loading Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation',\n",
    "              'Infiltration','Fibrosis','Pneumonia','No Finding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_full_path(img_name):\n",
    "    original_is_found = False\n",
    "    \n",
    "    # Read 1 image file\n",
    "    folder_idx_range = 13\n",
    "    img_path = ''\n",
    "    for folder_idx in range(folder_idx_range):\n",
    "        path_prefix = path.expanduser(\"~/data/kaggle/nih-chest-xrays/data/images_\")\n",
    "        path_suffix = \"images/\"\n",
    "        cur_img_dir = path_prefix +str(folder_idx).zfill(3) +'/'\n",
    "        img_folder_path = path.join(cur_img_dir, path_suffix)\n",
    "        img_path = os.path.join(img_folder_path, img_name) \n",
    "        if(path.exists(img_path)):\n",
    "            original_is_found = True\n",
    "            break\n",
    "    if(not original_is_found):\n",
    "        raise Exception('Couldn\\'t find: {} last:{}'.format(img_name, img_path))\n",
    "\n",
    "    return img_path\n",
    "        \n",
    "    \n",
    "class DatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.data_len = len(self.data.index)            # csv data length\n",
    "        \n",
    "        self.image_names = np.array(self.data.loc[:,'Image Index'])  # image names\n",
    "        self.heights = np.asarray(self.data.loc[:,'Height]'])    # heights are at 8th column \n",
    "        self.widths =  np.asarray(self.data.loc[:'OriginalImage[Width'])    # widths are at  7th column\n",
    "        \n",
    "        # createa a tensor to store labels\n",
    "        self.labels = torch.zeros(self.data_len, 15)\n",
    "        labels = self.data.loc[:,'Finding Labels'] #.map(lambda x: x.split('|'))\n",
    "        self.multi_hot_encoding_label(labels)\n",
    "    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Read 1 image name\n",
    "        img_name = self.image_names[index]\n",
    "        img_path = resolve_full_path(img_name)\n",
    "        img_as_img = Image.open(img_path)\n",
    "\n",
    "        img_as_img = img_as_img.convert(\"RGB\")\n",
    "        # Transform image to tensor\n",
    "        img_as_tensor = self.transform(img_as_img)\n",
    "\n",
    "        # Read 1 label:\n",
    "        image_label = self.labels[index]\n",
    "\n",
    "        return img_as_tensor, image_label\n",
    "    \n",
    "    def multi_hot_encoding_label(self, labels):\n",
    "            for i,label in enumerate(labels):\n",
    "                for idx in range(len(label_list)):\n",
    "                    if label_list[idx] in label:\n",
    "                        self.labels[i][idx] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of workers for dataloader\n",
    "workers = 8\n",
    "\n",
    "# Batch size during training\n",
    "batch_size_ = 64\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 128\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 32\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 32\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 600\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use dataloader to load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv path: original_image_csv/Cardiomegaly.csv\n",
      "train_origin_dataset len:  1093\n",
      "train_loader len:  110\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([transforms.Resize(256),\n",
    "#                                 transforms.RandomResizedCrop(224),\n",
    "                                transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "#                                 transforms.RandomRotation(10),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Define custom dataset\n",
    "csv_path = 'original_image_csv/'+disease+'.csv'\n",
    "print(\"csv path:\", csv_path)\n",
    "train_origin_dataset = DatasetFromCSV(csv_path,transform=transform)\n",
    "print(\"train_origin_dataset len: \", len(train_origin_dataset))\n",
    "\n",
    "# Concatenate datasets and load into Dataloader\n",
    "train_loader = torch.utils.data.DataLoader(dataset= train_origin_dataset,\n",
    "                                                   batch_size=batch_size_,\n",
    "                                                   num_workers=workers,\n",
    "                                                   shuffle=True)\n",
    "\n",
    "\n",
    "print(\"train_loader len: \", len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "               \n",
    "# Plot some training images\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:5], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "#Save shuffle data\n",
    "vutils.save_image(real_batch[0], 'shuffle_test.png', normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d( nz, ngf * 32, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 32),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*32) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 32, ngf * 16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 16),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*16) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 16, ngf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 64 x 64\n",
    "            nn.ConvTranspose2d( ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 128 x 128\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            # state size. (nc) x 256 x 256\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 256 x 256\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 128 x 128\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 64 x 64\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 32 x 32\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 16 x 16\n",
    "            nn.Conv2d(ndf * 8, ndf*16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*16) x 8 x 8\n",
    "            nn.Conv2d(ndf * 16, ndf*32, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*32) x 4 x 4\n",
    "            nn.Conv2d(ndf * 32, 1, 4, 1, 0, bias=False),\n",
    "            # state size. (1) x 1 x 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "netG.train()\n",
    "netD.train()\n",
    "\n",
    "suffix_real_path = 'image/test_real'\n",
    "suffix_fake_path = 'image/test_fake'\n",
    "real_path = os.path.join(models_dir, suffix_real_path)\n",
    "fake_path = os.path.join(models_dir, suffix_fake_path)\n",
    "print('Tensorboard real image path: ', real_path)\n",
    "print('Tensorboard fake image path: ',fake_path)\n",
    "\n",
    "writer_real = SummaryWriter(real_path)\n",
    "writer_fake = SummaryWriter(fake_path)\n",
    "writer = SummaryWriter('runs/'+disease)\n",
    "\n",
    "if not os.path.exists(os.path.join(models_dir, 'saved_model')):\n",
    "    os.makedirs(os.path.join(models_dir, 'saved_model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        batch_size = data.shape[0]\n",
    "        \n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        netD.zero_grad()\n",
    "        label = (torch.ones(batch_size)*0.9).to(device)\n",
    "        output = netD(data).reshape(-1)\n",
    "        lossD_real = criterion(output, label)\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        noise = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "        fake = netG(noise)\n",
    "        label = (torch.ones(batch_size)*0.1).to(device)\n",
    "        \n",
    "        output = netD(fake.detach()).reshape(-1)\n",
    "        D_G_z1 = output.mean().item()\n",
    "        lossD_fake = criterion(output, label)\n",
    "        \n",
    "        lossD = lossD_real + lossD_fake\n",
    "        lossD.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        ### Train Generator: max log(D(G(z)))\n",
    "        netG.zero_grad()\n",
    "        label = torch.ones(batch_size).to(device)\n",
    "        output = netD(fake).reshape(-1)\n",
    "        lossG = criterion(output, label)\n",
    "        lossG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Print losses ocassionally and print to tensorboard\n",
    "        if batch_idx % 50 == 0:\n",
    "            if not os.path.exists(os.path.join(models_dir, 'saved_model')):\n",
    "                os.makedirs(os.path.exists(os.path.join(models_dir, 'saved_model')))\n",
    "            torch.save(netG.state_dict(), os.path.join(models_dir, 'saved_model/netG_'+disease+'.pt'))\n",
    "            torch.save(netD.state_dict(), os.path.join(models_dir, 'saved_model/netD_'+disease+'.pt'))\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(train_loader)} \\\n",
    "                  Loss D: {lossD:.4f}, loss G: {lossG:.4f} D(x): {D_x:.4f} D(G(z1)): {D_G_z1} D(G(z2)): {D_G_z2}  \"\n",
    "            )\n",
    "            \n",
    "            writer.add_scalar('runs/LossD', lossD, epoch * len(train_loader) + batch_idx, epoch)\n",
    "            writer.add_scalar('runs/LossG', lossG, epoch * len(train_loader) + batch_idx, epoch)\n",
    "            writer.add_scalar('runs/Dx', D_x, epoch * len(train_loader) + batch_idx, epoch)\n",
    "            writer.add_scalar('runs/Dg_z1', D_G_z1, epoch * len(train_loader) + batch_idx, epoch)\n",
    "            writer.add_scalar('runs/Dg_z2', D_G_z2, epoch * len(train_loader) + batch_idx, epoch)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise)\n",
    "\n",
    "                img_grid_real = torchvision.utils.make_grid(data[:32], normalize=True)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                writer_real.add_image(\"Real Images\", img_grid_real, epoch)\n",
    "                writer_fake.add_image(\"Fake Images\", img_grid_fake, epoch)\n",
    "                \n",
    "    torch.cuda.synchronize()            \n",
    "    print('{} seconds'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DCGAN synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG.load_state_dict(torch.load(os.path.join(models_dir, 'saved_model/netG_'+disease+'.pt')))\n",
    "netG.eval()\n",
    "\n",
    "print(os.path.join(models_dir, 'saved_model/netG_'+disease+'.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image_size = 50\n",
    "episode = 20\n",
    "noise = torch.randn(generated_image_size, nz, 1, 1).to(device)\n",
    "\n",
    "gan_fake = netG(noise)\n",
    "print(gan_fake.shape)\n",
    "\n",
    "\n",
    "# show synthetic images\n",
    "grid = utils.make_grid(gan_fake)\n",
    "grid = grid.cpu()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(grid.detach().numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: save_images\n",
    "def save_images(imgs, name, episode, epoch):\n",
    "    img_name = '{}_{:03d}_{:03d}.png'.format(name, episode, epoch)\n",
    "    img_path = os.path.join('dcgan_image/'+disease, img_name)\n",
    "    vutils.save_image(imgs, img_path, normalize=True)\n",
    "\n",
    "# iteratively save images\n",
    "import shutil\n",
    "\n",
    "if os.path.exists('dcgan_image/'+disease):\n",
    "    shutil.rmtree(\"dcgan_image/\"+disease)    \n",
    "os.makedirs('dcgan_image/'+disease)\n",
    "    \n",
    "\n",
    "\n",
    "for j in range(episode):\n",
    "    for i in range(generated_image_size):\n",
    "        save_images(gan_fake[i-1],disease,j,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import image names and write image_name and label to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "\"\"\n",
    "\n",
    "class GenerateAugmentedDataCSV:\n",
    "    def __init__(self, writefilename, fileNames):\n",
    "        self.writeCSV = writefilename\n",
    "        self.filenames = fileNames\n",
    "        \n",
    "    def WriteToFile(self):\n",
    "        with open(self.writeCSV, 'w',newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if os.stat(self.writeCSV).st_size == 0:\n",
    "                writer.writerow(['Image Index', 'Finding Labels'])\n",
    "            for idx in range(generated_image_size*episode):\n",
    "                imgName = self.filenames[idx]\n",
    "                label = disease\n",
    "                writer.writerow([imgName, label])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "if(os.getcwd() != ('dcgan_image/'+disease)):\n",
    "    os.chdir('dcgan_image/'+disease)\n",
    "fileNames = glob.glob(\"*.png\")\n",
    "fileNames = sorted(fileNames)\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "generate_DCGAN_CSV = GenerateAugmentedDataCSV('dcgan_image_csv/dcgan_'+disease+'.csv', fileNames)\n",
    "generate_DCGAN_CSV.WriteToFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

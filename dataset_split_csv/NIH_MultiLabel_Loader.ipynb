{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os.path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing data set and splitting it into training, test and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patient ids: training: 21563, validation: 3079, testing: 6161\n"
     ]
    }
   ],
   "source": [
    "#reference : https://aws.amazon.com/blogs/machine-learning/classifying-high-resolution-chest-x-ray-medical-images-with-amazon-sagemaker/\n",
    "data_dir = \"../../../../../../data/kaggle/nih-chest-xrays/data/\"\n",
    "#splitting thr data set into training, validation and testing data sets\n",
    "#70% training data\n",
    "trainper = 0.7\n",
    "#10% validation data\n",
    "valper = 0.1\n",
    "file_name = data_dir + 'Data_Entry_2017.csv'\n",
    "\n",
    "a = pd.read_csv(file_name)\n",
    "patient_ids = a['Patient ID']\n",
    "uniq_pids = np.unique(patient_ids)\n",
    "np.random.shuffle(uniq_pids)\n",
    "total_ids = len(uniq_pids)\n",
    "\n",
    "trainset = int(trainper*total_ids)\n",
    "valset = trainset+int(valper*total_ids)\n",
    "#remaining data is used as a test set\n",
    "testset = trainset+valset\n",
    "\n",
    "train = uniq_pids[:trainset]\n",
    "val = uniq_pids[trainset+1:valset]\n",
    "test = uniq_pids[valset+1:]\n",
    "print('Number of patient ids: training: %d, validation: %d, testing: %d'%(len(train), len(val), len(test)))\n",
    "\n",
    "traindata = a.loc[a['Patient ID'].isin(train)]\n",
    "valdata = a.loc[a['Patient ID'].isin(val)]\n",
    "testdata = a.loc[a['Patient ID'].isin(test)]\n",
    "\n",
    "traindata.to_csv('traindata.csv', sep=',', header=False, index=False)\n",
    "valdata.to_csv('valdata.csv', sep=',', header=False, index=False)\n",
    "testdata.to_csv('testdata.csv', sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training data into the data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                        transforms.RandomResizedCrop(224),\n",
    "                                        transforms.RandomHorizontalFlip(), # randomly flip and rotate\n",
    "                                        transforms.RandomRotation(10),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transform = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a bag of words of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_set(csvfile, outputfile):\n",
    "    disease_list = ['Atelectasis', 'Consolidation', 'Infiltration', 'Pneumothorax', 'Edema', 'Emphysema', \\\n",
    "                   'Fibrosis', 'Effusion', 'Pneumonia', 'Pleural_Thickening', 'Cardiomegaly', 'Nodule', 'Mass', \\\n",
    "                   'Hernia']\n",
    "    alldiseases = {disease:i for i,disease in enumerate(disease_list)}\n",
    "    with open(outputfile, 'w') as fp:\n",
    "        with open(csvfile, 'r') as cfile:\n",
    "            line = csv.reader(cfile, delimiter=',')\n",
    "            index = 0\n",
    "            for element in line:\n",
    "                # the first column is the image filename, while the second\n",
    "                # column has the list of diseases separated by |\n",
    "                diseases = element[1].split('|')\n",
    "                #fp.write('%d\\t'%index)\n",
    "                for d in alldiseases:\n",
    "                    if ((d in diseases) and (d == 'Atelectasis')):\n",
    "                        fp.write('%d\\t'%1)\n",
    "                    elif((d in diseases) and (d == 'Consolidation')):\n",
    "                        fp.write('%d\\t'%2)\n",
    "                    elif((d in diseases) and (d == 'Infiltration')):\n",
    "                        fp.write('%d\\t'%3)\n",
    "                    elif((d in diseases) and (d == 'Pneumothorax')):\n",
    "                        fp.write('%d\\t'%4)\n",
    "                    elif((d in diseases) and (d == 'Edema')):\n",
    "                        fp.write('%d\\t'%5)\n",
    "                    elif((d in diseases) and (d == 'Emphysema')):\n",
    "                        fp.write('%d\\t'%6)\n",
    "                    elif((d in diseases) and (d == 'Fibrosis')):\n",
    "                        fp.write('%d\\t'%7)\n",
    "                    elif((d in diseases) and (d == 'Effusion')):\n",
    "                        fp.write('%d\\t'%8)\n",
    "                    elif((d in diseases) and (d == 'Pneumonia')):\n",
    "                        fp.write('%d\\t'%9)\n",
    "                    elif((d in diseases) and (d == 'Pleural_Thickening')):\n",
    "                        fp.write('%d\\t'%10)\n",
    "                    elif((d in diseases) and (d == 'Cardiomegaly')):\n",
    "                        fp.write('%d\\t'%11)\n",
    "                    elif((d in diseases) and (d == 'Nodule')):\n",
    "                        fp.write('%d\\t'%12)\n",
    "                    elif((d in diseases) and (d == 'Mass')):\n",
    "                        fp.write('%d\\t'%13)\n",
    "                    elif((d in diseases) and (d == 'Hernia')):\n",
    "                        fp.write('%d\\t'%14)\n",
    "                    else:\n",
    "                        fp.write('%d\\t'%0)\n",
    "                fp.write('images/%s\\n' % element[0])\n",
    "                index += 1\n",
    "#when used in local machine, to be commented out otherwise\n",
    "#path = 'D:/EIT_AUS_TUB/SoSe2020_MLInMIP/MedicalImageProcessing/'    \n",
    "#os.chdir(path)                 \n",
    "gen_set('traindata.csv', 'chestxraytrain.txt')\n",
    "gen_set('valdata.csv', 'chestxrayval.txt')\n",
    "gen_set('testdata.csv', 'chestxraytest.txt')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to identify the diagnosis label associated with an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diagnosis(word):\n",
    "    #print(\"word\", word)\n",
    "    if(word == 1):\n",
    "        diag = 'Atelectasis'\n",
    "    elif(word == 2):\n",
    "        diag = 'Consolidation'\n",
    "    elif(word == 3):\n",
    "        diag = 'Infiltration'\n",
    "    elif(word == 4):\n",
    "        diag = 'Pneumothorax'\n",
    "    elif(word == 5):\n",
    "        diag = 'Edema'\n",
    "    elif(word == 6):\n",
    "        diag = 'Emphysema'\n",
    "    elif(word == 7):\n",
    "        diag = 'Fibrosis'\n",
    "    elif(word == 8):\n",
    "        diag = 'Effusion'\n",
    "    elif(word == 9):\n",
    "        diag = 'Pneumonia'\n",
    "    elif(word == 10):\n",
    "        diag = 'Pleural_Thickening'\n",
    "    elif(word == 11):\n",
    "        diag = 'Cardiomegaly'\n",
    "    elif(word == 12):\n",
    "        diag = 'Nodule'\n",
    "    elif(word == 13):\n",
    "        diag = 'Mass'\n",
    "    elif(word == 14):\n",
    "        diag = 'Hernia'\n",
    "    else:\n",
    "        diag = \"Undiagnosed\"\n",
    "\n",
    "    #print(diag)\n",
    "    return diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom dataloader - __to do__\n",
    "The idea is, in __getitem__:\n",
    "A. to read the lst file which contains the labels associated with images\n",
    "B. For each image, check which ailment is '1'\n",
    "C. Append those to labels for that image\n",
    "D. Return image and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XRaysTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_name, transform=None):\n",
    "        file1 = open(csv_name, \"r\")\n",
    "        self.data =  file1.readlines()           \n",
    "        self.data_len = len(self.data)         \n",
    "        self.transform = transform\n",
    "             \n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    \n",
    "    def __getitem__(self, index):       \n",
    "        #read labels in each line in the txt file\n",
    "        cnt = 0 \n",
    "        imageName = []            \n",
    "        imgLab = []\n",
    "        for word in self.data[index].split():          \n",
    "            #diagnose until the last index which is the image name\n",
    "            if(cnt < 14):\n",
    "                #print(word)\n",
    "                diag = Diagnosis(int(word))\n",
    "                #print(diag)\n",
    "                if(diag != 'Undiagnosed'):\n",
    "                    imgLab.append(diag)\n",
    "\n",
    "            if(cnt == 14):\n",
    "                imageName.append(word)\n",
    "            cnt+=1 \n",
    "         \n",
    "        if not imgLab:\n",
    "            imgLab.append(\"Undiagnosed\")\n",
    "\n",
    "        return imageName, imgLab  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataLoader = XRaysTrainDataset('chestxraytrain.txt', transform = train_transform)\n",
    "trainLoader = torch.utils.data.DataLoader(traindataLoader, batch_size = 1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in trainloader\n",
      "[('images/00026191_000.png', 'images/00028640_008.png', 'images/00014398_031.png', 'images/00021489_004.png', 'images/00002892_012.png')]\n",
      "[('Undiagnosed', 'Consolidation', 'Effusion', 'Infiltration', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00012278_001.png', 'images/00011579_017.png', 'images/00005566_008.png', 'images/00014253_006.png', 'images/00016732_007.png')]\n",
      "[('Undiagnosed', 'Atelectasis', 'Cardiomegaly', 'Atelectasis', 'Effusion')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00019765_004.png', 'images/00023160_003.png', 'images/00021988_010.png', 'images/00003064_014.png', 'images/00025419_000.png')]\n",
      "[('Undiagnosed', 'Infiltration', 'Undiagnosed', 'Undiagnosed', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00010222_018.png', 'images/00010011_000.png', 'images/00022684_006.png', 'images/00003072_012.png', 'images/00017402_000.png')]\n",
      "[('Atelectasis', 'Undiagnosed', 'Undiagnosed', 'Infiltration', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00000459_051.png', 'images/00030699_000.png', 'images/00014063_001.png', 'images/00001075_019.png', 'images/00020458_023.png')]\n",
      "[('Infiltration', 'Atelectasis', 'Undiagnosed', 'Undiagnosed', 'Emphysema')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00020158_006.png', 'images/00002143_010.png', 'images/00000179_007.png', 'images/00003230_004.png', 'images/00004428_001.png')]\n",
      "[('Undiagnosed', 'Undiagnosed', 'Consolidation', 'Effusion', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00011448_005.png', 'images/00025954_013.png', 'images/00016527_000.png', 'images/00020537_000.png', 'images/00013890_021.png')]\n",
      "[('Undiagnosed', 'Pneumothorax', 'Undiagnosed', 'Effusion', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00026194_006.png', 'images/00013904_010.png', 'images/00011061_003.png', 'images/00028392_005.png', 'images/00023116_014.png')]\n",
      "[('Undiagnosed', 'Nodule', 'Undiagnosed', 'Effusion', 'Pneumothorax')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00003209_001.png', 'images/00007624_008.png', 'images/00015115_005.png', 'images/00016051_002.png', 'images/00022526_000.png')]\n",
      "[('Undiagnosed', 'Undiagnosed', 'Mass', 'Pneumothorax', 'Pneumothorax')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00025303_025.png', 'images/00018724_027.png', 'images/00000820_002.png', 'images/00013635_004.png', 'images/00014128_011.png')]\n",
      "[('Atelectasis', 'Undiagnosed', 'Infiltration', 'Undiagnosed', 'Effusion')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00026185_007.png', 'images/00013894_006.png', 'images/00022620_000.png', 'images/00027119_001.png', 'images/00030570_006.png')]\n",
      "[('Nodule', 'Effusion', 'Undiagnosed', 'Effusion', 'Infiltration')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00022881_001.png', 'images/00016237_001.png', 'images/00020294_007.png', 'images/00010822_000.png', 'images/00016009_031.png')]\n",
      "[('Pneumothorax', 'Infiltration', 'Atelectasis', 'Undiagnosed', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00003227_004.png', 'images/00019836_000.png', 'images/00008841_015.png', 'images/00018578_000.png', 'images/00004858_023.png')]\n",
      "[('Undiagnosed', 'Undiagnosed', 'Atelectasis', 'Undiagnosed', 'Undiagnosed')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00027637_002.png', 'images/00030713_000.png', 'images/00007959_000.png', 'images/00010996_007.png', 'images/00025536_001.png')]\n",
      "[('Undiagnosed', 'Undiagnosed', 'Undiagnosed', 'Undiagnosed', 'Infiltration')]\n",
      "--------------------------------------------------------------------\n",
      "[('images/00011797_000.png', 'images/00021954_006.png', 'images/00018422_000.png', 'images/00017182_001.png', 'images/00027556_005.png')]\n",
      "[('Effusion', 'Atelectasis', 'Undiagnosed', 'Undiagnosed', 'Mass')]\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 15\n",
    "print(\"in trainloader\")\n",
    "for b in range(batch_size):\n",
    "    dataiter = iter(trainLoader)\n",
    "    images, labels = dataiter.next()\n",
    "    print(images)\n",
    "    print(labels)\n",
    "    print(\"--------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

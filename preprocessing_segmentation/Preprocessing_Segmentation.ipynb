{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from os import path\n",
    "from collections import OrderedDict\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group/donut/Anupama/medical_ip/NIH_code/Preprocessing_Segmentation/images/images_002\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data sets and read image index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ValData_Segmented.csv'\n",
    "a = pd.read_csv(file_name)\n",
    "imgIdx = a['Image Index'] \n",
    "labelName = a['Finding Labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessing(image):\n",
    "    #step 1 : resize the image to 512 x 512\n",
    "    resized = cv2.resize(image, (512, 512))\n",
    "    \n",
    "    #step 2: Convert image to grayscale\n",
    "    if(len(image.shape) > 2):\n",
    "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = resized;\n",
    "\n",
    "    #step 3: Smoothing out the noise in the image\n",
    "    filImg = cv2.GaussianBlur(gray, (5,5), 6)\n",
    "\n",
    "    #step 4: Histogram equalisation\n",
    "    hist = cv2.equalizeHist(filImg)\n",
    "\n",
    "    #step 5: Thresholding\n",
    "    ret, binImg = cv2.threshold(hist, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    #cropping unnecessary height and width\n",
    "    return hist, binImg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting segments of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Segments(crop):\n",
    "    \n",
    "    #finding edges\n",
    "    edged = cv2.Canny(crop, 0, 1000)\n",
    "\n",
    "    #closing the gaps between the edges - dilation morphological operation\n",
    "    kernel = np.zeros((5,5),np.uint8)\n",
    "    edged = cv2.dilate(edged, kernel, iterations = 10)\n",
    "\n",
    "    #find contours\n",
    "    cnt, hierarchy = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)         \n",
    "    openImg = edged\n",
    "    cnts = sorted(cnt, key = cv2.contourArea, reverse = True)[:len(cnt)]                \n",
    "\n",
    "    # Find the convex hull object for each contour\n",
    "    hull_list = []\n",
    "    for i in range(len(cnts)):       \n",
    "        #print(cv2.contourArea(cnts[i]))\n",
    "        hull = cv2.convexHull(cnts[i])\n",
    "        hull_list.append(hull)\n",
    "\n",
    "    cv2.drawContours(openImg, hull_list, -1, (255,255,255), -1)\n",
    "\n",
    "    return openImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the image from the dataset folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_full_path(img_name):\n",
    "    is_found = False\n",
    "\n",
    "    # Read 1 image file\n",
    "    folder_idx_range = 13\n",
    "    img_path = ''\n",
    "    for folder_idx in range(folder_idx_range):\n",
    "        path_prefix = path.expanduser(\"~/data/kaggle/nih-chest-xrays/data/images_\")\n",
    "        path_suffix = \"images/\"\n",
    "        cur_img_dir = path_prefix +str(folder_idx).zfill(3) +'/'\n",
    "        img_folder_path = path.join(cur_img_dir, path_suffix)\n",
    "        img_path = os.path.join(img_folder_path, img_name)\n",
    "\n",
    "        if(path.exists(img_path)):\n",
    "            is_found = True\n",
    "            break\n",
    "    if(not is_found):\n",
    "        \n",
    "        raise Exception('Couldn\\'t find: {} last:{}'.format(img_name, img_path))\n",
    "    return img_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group/donut/Anupama/medical_ip/NIH_code/Preprocessing_Segmentation\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"Preprocessing_Segmentation\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and segmenting the image and storing in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group/donut/Anupama/medical_ip/NIH_code/Preprocessing_Segmentation/Segmentation_Validation\n"
     ]
    }
   ],
   "source": [
    "storePath = \"Segmentation_Validation\"\n",
    "os.chdir(storePath)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(imgIdx)):\n",
    "    imgPath = resolve_full_path(imgIdx[idx])\n",
    "    img = cv2.imread(imgPath)\n",
    "    hist, binImg = PreProcessing(img)\n",
    "    segments = Segments(binImg)\n",
    "    overlap = cv2.bitwise_and(hist, segments)\n",
    "    fileName = imgIdx[idx]\n",
    "    cv2.imwrite(fileName, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the segmented images names and labels in a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/group/donut/Anupama/medical_ip/NIH_code/Preprocessing_Segmentation\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "readfilename = '~/group/donut/medical_ip/Multi_Label_Dataloader_and_Classifier/valdata_paul.csv'\n",
    "writefilename = 'ValData_Segmented.csv'\n",
    "gen = GenerateAugmentedDataCSV(readfilename, writefilename)\n",
    "gen.WriteToFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to generate csv with names and labels of the augmented images\n",
    "Parameter 1: input csv file\n",
    "Parameter 2: generated csv file with new image names and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateAugmentedDataCSV:\n",
    "    def __init__(self, readfilename, writefilename):\n",
    "        self.data = pd.read_csv(readfilename)\n",
    "        self.imageNames = self.data['Image Index']\n",
    "        self.labelNames = self.data['Finding Labels']\n",
    "        self.fileName = writefilename\n",
    "        \n",
    "    def WriteToFile(self):\n",
    "        with open(self.fileName, 'a') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['Image Index', 'Finding Labels'])\n",
    "            for idx in range(len(self.imageNames)):\n",
    "                #imgName = str(idx+1)+'.png '\n",
    "                imgName = self.imageNames[idx]\n",
    "                label = self.labelNames[idx]\n",
    "                writer.writerow([imgName, label])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

Fold: 1/5 
Epoch [0/30] Batch 0/7568 Train_loss 7.412533164024353 
Epoch [0/30] Batch 100/7568 Train_loss 2.570068280738179 
Epoch [0/30] Batch 200/7568 Train_loss 2.5149836880502416 
Epoch [0/30] Batch 300/7568 Train_loss 2.452679932166968 
Epoch [0/30] Batch 400/7568 Train_loss 2.4065996879279763 
Epoch [0/30] Batch 500/7568 Train_loss 2.360806683312633 
Epoch [0/30] Batch 600/7568 Train_loss 2.3256251087006237 
Epoch [0/30] Batch 700/7568 Train_loss 2.2882325733651787 
Epoch [0/30] Batch 800/7568 Train_loss 2.266399690720919 
Epoch [0/30] Batch 900/7568 Train_loss 2.251208893929946 
Epoch [0/30] Batch 1000/7568 Train_loss 2.245588568927763 
Epoch [0/30] Batch 1100/7568 Train_loss 2.240836544606926 
Epoch [0/30] Batch 1200/7568 Train_loss 2.229876447465894 
Epoch [0/30] Batch 1300/7568 Train_loss 2.228624640601035 
Epoch [0/30] Batch 1400/7568 Train_loss 2.2116436479582604 
Epoch [0/30] Batch 1500/7568 Train_loss 2.209858505041658 
Epoch [0/30] Batch 1600/7568 Train_loss 2.200609900936866 
Epoch [0/30] Batch 1700/7568 Train_loss 2.1989721011617895 
Epoch [0/30] Batch 1800/7568 Train_loss 2.1953217159834653 
Epoch [0/30] Batch 1900/7568 Train_loss 2.1948032450324795 
Epoch [0/30] Batch 2000/7568 Train_loss 2.194579119595333 
Epoch [0/30] Batch 2100/7568 Train_loss 2.193788558755359 
Epoch [0/30] Batch 2200/7568 Train_loss 2.186189529192767 
Epoch [0/30] Batch 2300/7568 Train_loss 2.18794565063386 
Epoch [0/30] Batch 2400/7568 Train_loss 2.185356568720429 
Epoch [0/30] Batch 2500/7568 Train_loss 2.1842966620169464 
Epoch [0/30] Batch 2600/7568 Train_loss 2.1795932510033427 
Epoch [0/30] Batch 2700/7568 Train_loss 2.176430798992542 
Epoch [0/30] Batch 2800/7568 Train_loss 2.177684565461435 
Epoch [0/30] Batch 2900/7568 Train_loss 2.175348754131108 
Epoch [0/30] Batch 3000/7568 Train_loss 2.1753727383005423 
Epoch [0/30] Batch 3100/7568 Train_loss 2.17230261844979 
Epoch [0/30] Batch 3200/7568 Train_loss 2.168023929055763 
Epoch [0/30] Batch 3300/7568 Train_loss 2.165296730088559 
Epoch [0/30] Batch 3400/7568 Train_loss 2.16508724945533 
Epoch [0/30] Batch 3500/7568 Train_loss 2.16587650870824 
Epoch [0/30] Batch 3600/7568 Train_loss 2.1656834650489896 
Epoch [0/30] Batch 3700/7568 Train_loss 2.164222725506764 
Epoch [0/30] Batch 3800/7568 Train_loss 2.162477820621638 
Epoch [0/30] Batch 3900/7568 Train_loss 2.1615391083479967 
Epoch [0/30] Batch 4000/7568 Train_loss 2.1589407168554087 
Epoch [0/30] Batch 4100/7568 Train_loss 2.156825801477988 
Epoch [0/30] Batch 4200/7568 Train_loss 2.1553925278675723 
Epoch [0/30] Batch 4300/7568 Train_loss 2.1558682592289027 
Epoch [0/30] Batch 4400/7568 Train_loss 2.152834514363791 
Epoch [0/30] Batch 4500/7568 Train_loss 2.1542237452224104 
Epoch [0/30] Batch 4600/7568 Train_loss 2.1546725826765036 
Epoch [0/30] Batch 4700/7568 Train_loss 2.1560617599226624 
Epoch [0/30] Batch 4800/7568 Train_loss 2.155129951214423 
Epoch [0/30] Batch 4900/7568 Train_loss 2.1531608795157697 
Epoch [0/30] Batch 5000/7568 Train_loss 2.152031411041953 
Epoch [0/30] Batch 5100/7568 Train_loss 2.1501992672237784 
Epoch [0/30] Batch 5200/7568 Train_loss 2.150505568758384 
Epoch [0/30] Batch 5300/7568 Train_loss 2.149667828625788 
Epoch [0/30] Batch 5400/7568 Train_loss 2.1511053183308975 
Epoch [0/30] Batch 5500/7568 Train_loss 2.1509710496023686 
Epoch [0/30] Batch 5600/7568 Train_loss 2.1507254492047854 
Epoch [0/30] Batch 5700/7568 Train_loss 2.150828711005015 
Epoch [0/30] Batch 5800/7568 Train_loss 2.1504779315815776 
Epoch [0/30] Batch 5900/7568 Train_loss 2.1492423816134094 
Epoch [0/30] Batch 6000/7568 Train_loss 2.148162463549236 
Epoch [0/30] Batch 6100/7568 Train_loss 2.147842813841907 
Epoch [0/30] Batch 6200/7568 Train_loss 2.145908347742055 
Epoch [0/30] Batch 6300/7568 Train_loss 2.144278621502366 
Epoch [0/30] Batch 6400/7568 Train_loss 2.1424378390783185 
Epoch [0/30] Batch 6500/7568 Train_loss 2.1411893249057727 
Epoch [0/30] Batch 6600/7568 Train_loss 2.140339676303731 
Epoch [0/30] Batch 6700/7568 Train_loss 2.1405958749188216 
Epoch [0/30] Batch 6800/7568 Train_loss 2.1391633234906067 
Epoch [0/30] Batch 6900/7568 Train_loss 2.1393391739163015 
Epoch [0/30] Batch 7000/7568 Train_loss 2.138932483677029 
Epoch [0/30] Batch 7100/7568 Train_loss 2.1372771147812206 
Epoch [0/30] Batch 7200/7568 Train_loss 2.1376252889844247 
Epoch [0/30] Batch 7300/7568 Train_loss 2.136042166964075 
Epoch [0/30] Batch 7400/7568 Train_loss 2.1358681307271787 
Epoch [0/30] Batch 7500/7568 Train_loss 2.1339010231821653 
Epoch: 0/30 	Training Loss: 2.133135 	Validation Loss: 2.028213 Duration seconds: 984.171263217926 
Validation loss decreased (inf --> 2.028213).  Saving model ... 
best_valid_loss_fold [2.0282131190358585] Best_Epoch [0]Epoch [1/30] Batch 0/7568 Train_loss 2.5395339727401733 
Epoch [1/30] Batch 100/7568 Train_loss 2.1106476432616166 
Epoch [1/30] Batch 200/7568 Train_loss 2.1143856440758824 
Epoch [1/30] Batch 300/7568 Train_loss 2.102639907073737 
Epoch [1/30] Batch 400/7568 Train_loss 2.1025488938105075 
Epoch [1/30] Batch 500/7568 Train_loss 2.0926831525837826 
Epoch [1/30] Batch 600/7568 Train_loss 2.098227534536117 
Epoch [1/30] Batch 700/7568 Train_loss 2.106893756101373 

Fold: 1/5 
Epoch [0/5] Batch 0/14335 Train_loss 6.9013673067092896 
Epoch [0/5] Batch 100/14335 Train_loss 2.4870011070282154 
Epoch [0/5] Batch 200/14335 Train_loss 2.4219084701579603 
Epoch [0/5] Batch 300/14335 Train_loss 2.355819522740437 
Epoch [0/5] Batch 400/14335 Train_loss 2.340702936239076 
Epoch [0/5] Batch 500/14335 Train_loss 2.3256988798132436 
Epoch [0/5] Batch 600/14335 Train_loss 2.307614623483723 
Epoch [0/5] Batch 700/14335 Train_loss 2.2981903174846896 
Epoch [0/5] Batch 800/14335 Train_loss 2.279875370465712 
Epoch [0/5] Batch 900/14335 Train_loss 2.2661907683962856 
Epoch [0/5] Batch 1000/14335 Train_loss 2.25076931637603 
Epoch [0/5] Batch 1100/14335 Train_loss 2.244628836941329 
Epoch [0/5] Batch 1200/14335 Train_loss 2.2363327563330095 
Epoch [0/5] Batch 1300/14335 Train_loss 2.234532883037154 
Epoch [0/5] Batch 1400/14335 Train_loss 2.227472644312564 
Epoch [0/5] Batch 1500/14335 Train_loss 2.2322872332697465 
Epoch [0/5] Batch 1600/14335 Train_loss 2.2325075290710905 
Epoch [0/5] Batch 1700/14335 Train_loss 2.230994127283441 
Epoch [0/5] Batch 1800/14335 Train_loss 2.2338002639254353 
Epoch [0/5] Batch 1900/14335 Train_loss 2.2326950000688193 
Epoch [0/5] Batch 2000/14335 Train_loss 2.229443655453105 
Epoch [0/5] Batch 2100/14335 Train_loss 2.2284069582146158 
Epoch [0/5] Batch 2200/14335 Train_loss 2.2298729342528225 
Epoch [0/5] Batch 2300/14335 Train_loss 2.224608419551273 
Epoch [0/5] Batch 2400/14335 Train_loss 2.221531588017866 
Epoch [0/5] Batch 2500/14335 Train_loss 2.2173127889490183 
Epoch [0/5] Batch 2600/14335 Train_loss 2.210948420735058 
Epoch [0/5] Batch 2700/14335 Train_loss 2.2091077126063317 
Epoch [0/5] Batch 2800/14335 Train_loss 2.207649736341005 
Epoch [0/5] Batch 2900/14335 Train_loss 2.2050675910296254 
Epoch [0/5] Batch 3000/14335 Train_loss 2.2028468620008486 
Epoch [0/5] Batch 3100/14335 Train_loss 2.20194343298491 
Epoch [0/5] Batch 3200/14335 Train_loss 2.1985384206014364 
Epoch [0/5] Batch 3300/14335 Train_loss 2.196242102698029 
Epoch [0/5] Batch 3400/14335 Train_loss 2.194223139688079 
Epoch [0/5] Batch 3500/14335 Train_loss 2.1918505474273835 
Epoch [0/5] Batch 3600/14335 Train_loss 2.188422479867207 
Epoch [0/5] Batch 3700/14335 Train_loss 2.18748371600219 
Epoch [0/5] Batch 3800/14335 Train_loss 2.185832714170445 
Epoch [0/5] Batch 3900/14335 Train_loss 2.183806931600452 
Epoch [0/5] Batch 4000/14335 Train_loss 2.184282978012007 
Epoch [0/5] Batch 4100/14335 Train_loss 2.1835807546104813 
Epoch [0/5] Batch 4200/14335 Train_loss 2.1833930505979233 
Epoch [0/5] Batch 4300/14335 Train_loss 2.1811560256949303 
Epoch [0/5] Batch 4400/14335 Train_loss 2.1805679908166606 
Epoch [0/5] Batch 4500/14335 Train_loss 2.17931754724883 
Epoch [0/5] Batch 4600/14335 Train_loss 2.178424857046728 
Epoch [0/5] Batch 4700/14335 Train_loss 2.1783762663076645 
Epoch [0/5] Batch 4800/14335 Train_loss 2.1775882344765107 
Epoch [0/5] Batch 4900/14335 Train_loss 2.176707285496075 
Epoch [0/5] Batch 5000/14335 Train_loss 2.174767319472807 
Epoch [0/5] Batch 5100/14335 Train_loss 2.1733101048240053 
Epoch [0/5] Batch 5200/14335 Train_loss 2.1734956982696865 
Epoch [0/5] Batch 5300/14335 Train_loss 2.1713943678693846 
Epoch [0/5] Batch 5400/14335 Train_loss 2.1698183043370354 
Epoch [0/5] Batch 5500/14335 Train_loss 2.168158889047082 
Epoch [0/5] Batch 5600/14335 Train_loss 2.1667432730095957 
Epoch [0/5] Batch 5700/14335 Train_loss 2.166360835561918 
Epoch [0/5] Batch 5800/14335 Train_loss 2.1666450782456987 
Epoch [0/5] Batch 5900/14335 Train_loss 2.1650986560541297 
Epoch [0/5] Batch 6000/14335 Train_loss 2.1652785469007343 
Epoch [0/5] Batch 6100/14335 Train_loss 2.1658298939373664 
Epoch [0/5] Batch 6200/14335 Train_loss 2.1664186521771067 
Epoch [0/5] Batch 6300/14335 Train_loss 2.1665470618527003 
Epoch [0/5] Batch 6400/14335 Train_loss 2.16514660839624 
Epoch [0/5] Batch 6500/14335 Train_loss 2.1643744500884274 
Epoch [0/5] Batch 6600/14335 Train_loss 2.163994453442203 
Epoch [0/5] Batch 6700/14335 Train_loss 2.1636324552209 
Epoch [0/5] Batch 6800/14335 Train_loss 2.1632851253816474 
Epoch [0/5] Batch 6900/14335 Train_loss 2.162855122993604 
Epoch [0/5] Batch 7000/14335 Train_loss 2.1612134941827907 
Epoch [0/5] Batch 7100/14335 Train_loss 2.1614591533693526 
Epoch [0/5] Batch 7200/14335 Train_loss 2.1604504922544305 
Epoch [0/5] Batch 7300/14335 Train_loss 2.1606506096624445 
Epoch [0/5] Batch 7400/14335 Train_loss 2.1600887520847056 
Epoch [0/5] Batch 7500/14335 Train_loss 2.1595904297819772 
Epoch [0/5] Batch 7600/14335 Train_loss 2.158257142562111 
Epoch [0/5] Batch 7700/14335 Train_loss 2.1583302728391565 
Epoch [0/5] Batch 7800/14335 Train_loss 2.1570715314206397 
Epoch [0/5] Batch 7900/14335 Train_loss 2.1564290012634793 
Epoch [0/5] Batch 8000/14335 Train_loss 2.1551296035769045 
Epoch [0/5] Batch 8100/14335 Train_loss 2.154822768982642 
Epoch [0/5] Batch 8200/14335 Train_loss 2.153756683884256 
Epoch [0/5] Batch 8300/14335 Train_loss 2.1529767938463564 
Epoch [0/5] Batch 8400/14335 Train_loss 2.1521935104940666 
Epoch [0/5] Batch 8500/14335 Train_loss 2.1516737117162665 
Epoch [0/5] Batch 8600/14335 Train_loss 2.1515234711280797 
Epoch [0/5] Batch 8700/14335 Train_loss 2.1514651429007867 
Epoch [0/5] Batch 8800/14335 Train_loss 2.151278280862054 
Epoch [0/5] Batch 8900/14335 Train_loss 2.1503435583707122 
Epoch [0/5] Batch 9000/14335 Train_loss 2.1486166882181865 
Epoch [0/5] Batch 9100/14335 Train_loss 2.147885683525684 
Epoch [0/5] Batch 9200/14335 Train_loss 2.148256578144917 
Epoch [0/5] Batch 9300/14335 Train_loss 2.1475895091774335 
Epoch [0/5] Batch 9400/14335 Train_loss 2.1469722161482223 
Epoch [0/5] Batch 9500/14335 Train_loss 2.146855409439144 
Epoch [0/5] Batch 9600/14335 Train_loss 2.146883567085292 
Epoch [0/5] Batch 9700/14335 Train_loss 2.145938627500962 
Epoch [0/5] Batch 9800/14335 Train_loss 2.1447549684399085 
Epoch [0/5] Batch 9900/14335 Train_loss 2.14424422056118 
Epoch [0/5] Batch 10000/14335 Train_loss 2.143515836532778 
Epoch [0/5] Batch 10100/14335 Train_loss 2.142717268366989 
Epoch [0/5] Batch 10200/14335 Train_loss 2.1422393992360624 
Epoch [0/5] Batch 10300/14335 Train_loss 2.1398201603983087 
Epoch [0/5] Batch 10400/14335 Train_loss 2.138994972217703 
Epoch [0/5] Batch 10500/14335 Train_loss 2.1390869124976013 
Epoch [0/5] Batch 10600/14335 Train_loss 2.1390770219702864 
Epoch [0/5] Batch 10700/14335 Train_loss 2.1377121429807193 
Epoch [0/5] Batch 10800/14335 Train_loss 2.1378929629810166 
Epoch [0/5] Batch 10900/14335 Train_loss 2.1378198605238894 
Epoch [0/5] Batch 11000/14335 Train_loss 2.137358864389564 
Epoch [0/5] Batch 11100/14335 Train_loss 2.137091272220226 
Epoch [0/5] Batch 11200/14335 Train_loss 2.1370556805894454 
Epoch [0/5] Batch 11300/14335 Train_loss 2.1367031455688714 
Epoch [0/5] Batch 11400/14335 Train_loss 2.136079414021696 
Epoch [0/5] Batch 11500/14335 Train_loss 2.135647273948064 
Epoch [0/5] Batch 11600/14335 Train_loss 2.1346710543122933 
Epoch [0/5] Batch 11700/14335 Train_loss 2.1344556806739727 
Epoch [0/5] Batch 11800/14335 Train_loss 2.1335423532259403 
Epoch [0/5] Batch 11900/14335 Train_loss 2.1331769876878868 
Epoch [0/5] Batch 12000/14335 Train_loss 2.132937566902367 
Epoch [0/5] Batch 12100/14335 Train_loss 2.13241427090752 
Epoch [0/5] Batch 12200/14335 Train_loss 2.132211660566452 
Epoch [0/5] Batch 12300/14335 Train_loss 2.131418329667739 
Epoch [0/5] Batch 12400/14335 Train_loss 2.1318683610340923 
Epoch [0/5] Batch 12500/14335 Train_loss 2.1314677074950903 
Epoch [0/5] Batch 12600/14335 Train_loss 2.130519519959515 
Epoch [0/5] Batch 12700/14335 Train_loss 2.1305744551751626 
Epoch [0/5] Batch 12800/14335 Train_loss 2.1307287673267217 
Epoch [0/5] Batch 12900/14335 Train_loss 2.1302768687110714 
Epoch [0/5] Batch 13000/14335 Train_loss 2.1307164983580766 
Epoch [0/5] Batch 13100/14335 Train_loss 2.1304891182613157 
Epoch [0/5] Batch 13200/14335 Train_loss 2.129879917202461 
Epoch [0/5] Batch 13300/14335 Train_loss 2.129378097112103 
Epoch [0/5] Batch 13400/14335 Train_loss 2.128969001651931 
Epoch [0/5] Batch 13500/14335 Train_loss 2.1282632163644464 
Epoch [0/5] Batch 13600/14335 Train_loss 2.1281648751817444 
Epoch [0/5] Batch 13700/14335 Train_loss 2.127988024497631 
Epoch [0/5] Batch 13800/14335 Train_loss 2.1271837039897687 
Epoch [0/5] Batch 13900/14335 Train_loss 2.1264808722154998 
Epoch [0/5] Batch 14000/14335 Train_loss 2.126816929352002 
Epoch [0/5] Batch 14100/14335 Train_loss 2.1261221142421673 
Epoch [0/5] Batch 14200/14335 Train_loss 2.1252294281705755 
Epoch [0/5] Batch 14300/14335 Train_loss 2.1242688139294272 
Epoch: 0/5 	Training Loss: 2.123874 	Validation Loss: 2.046604 Duration seconds: 4349.932494163513 
Validation loss decreased (inf --> 2.046604).  Saving model ... 
best_valid_loss_fold [2.0466035334518113] Best_Epoch [0]Epoch [1/5] Batch 0/14335 Train_loss 2.4515043199062347 
Epoch [1/5] Batch 100/14335 Train_loss 1.9853013635861991 
Epoch [1/5] Batch 200/14335 Train_loss 2.013464150811309 
Epoch [1/5] Batch 300/14335 Train_loss 2.0115599843156695 
Epoch [1/5] Batch 400/14335 Train_loss 2.040514648332263 
Epoch [1/5] Batch 500/14335 Train_loss 2.0411545343087343 
Epoch [1/5] Batch 600/14335 Train_loss 2.0372944938858812 
Epoch [1/5] Batch 700/14335 Train_loss 2.0407349410096183 
Epoch [1/5] Batch 800/14335 Train_loss 2.052497373110197 
Epoch [1/5] Batch 900/14335 Train_loss 2.0537151586466966 
Epoch [1/5] Batch 1000/14335 Train_loss 2.0612064865115403 
Epoch [1/5] Batch 1100/14335 Train_loss 2.0526712998869634 
Epoch [1/5] Batch 1200/14335 Train_loss 2.0659223655479138 
Epoch [1/5] Batch 1300/14335 Train_loss 2.0693879555638803 
Epoch [1/5] Batch 1400/14335 Train_loss 2.0652599206232836 
Epoch [1/5] Batch 1500/14335 Train_loss 2.0639693848714282 
Epoch [1/5] Batch 1600/14335 Train_loss 2.063024761870755 
Epoch [1/5] Batch 1700/14335 Train_loss 2.058689662511036 
Epoch [1/5] Batch 1800/14335 Train_loss 2.057829083029857 
Epoch [1/5] Batch 1900/14335 Train_loss 2.0613138324364058 
Epoch [1/5] Batch 2000/14335 Train_loss 2.0587525762494714 
Epoch [1/5] Batch 2100/14335 Train_loss 2.0575562433323253 
Epoch [1/5] Batch 2200/14335 Train_loss 2.05961839921742 
Epoch [1/5] Batch 2300/14335 Train_loss 2.0595916557485565 
Epoch [1/5] Batch 2400/14335 Train_loss 2.059885183723953 
Epoch [1/5] Batch 2500/14335 Train_loss 2.0587654016176162 
Epoch [1/5] Batch 2600/14335 Train_loss 2.055763609160235 
Epoch [1/5] Batch 2700/14335 Train_loss 2.053896871039224 
Epoch [1/5] Batch 2800/14335 Train_loss 2.056940433378732 
Epoch [1/5] Batch 2900/14335 Train_loss 2.057229981971831 
Epoch [1/5] Batch 3000/14335 Train_loss 2.058242617776417 
Epoch [1/5] Batch 3100/14335 Train_loss 2.0596064391952296 
Epoch [1/5] Batch 3200/14335 Train_loss 2.0580001529195613 
Epoch [1/5] Batch 3300/14335 Train_loss 2.0579450214335284 
Epoch [1/5] Batch 3400/14335 Train_loss 2.0599922273385807 
Epoch [1/5] Batch 3500/14335 Train_loss 2.059712257492682 
Epoch [1/5] Batch 3600/14335 Train_loss 2.0599387404662775 
Epoch [1/5] Batch 3700/14335 Train_loss 2.0588545364943496 
Epoch [1/5] Batch 3800/14335 Train_loss 2.057821433839281 
Epoch [1/5] Batch 3900/14335 Train_loss 2.057810008021631 
Epoch [1/5] Batch 4000/14335 Train_loss 2.058476706861079 
Epoch [1/5] Batch 4100/14335 Train_loss 2.057576401895414 
Epoch [1/5] Batch 4200/14335 Train_loss 2.0561849760586406 
Epoch [1/5] Batch 4300/14335 Train_loss 2.05469401838668 
Epoch [1/5] Batch 4400/14335 Train_loss 2.0544354931634006 
Epoch [1/5] Batch 4500/14335 Train_loss 2.0527251236930315 
Epoch [1/5] Batch 4600/14335 Train_loss 2.052400532176354 
Epoch [1/5] Batch 4700/14335 Train_loss 2.0535525139456885 
Epoch [1/5] Batch 4800/14335 Train_loss 2.052436653160721 
Epoch [1/5] Batch 4900/14335 Train_loss 2.053763210147139 
Epoch [1/5] Batch 5000/14335 Train_loss 2.052891337497309 
Epoch [1/5] Batch 5100/14335 Train_loss 2.052209667176435 
Epoch [1/5] Batch 5200/14335 Train_loss 2.0523124223281686 
Epoch [1/5] Batch 5300/14335 Train_loss 2.052916670926133 
Epoch [1/5] Batch 5400/14335 Train_loss 2.0537637170956677 
Epoch [1/5] Batch 5500/14335 Train_loss 2.0551629894739976 
Epoch [1/5] Batch 5600/14335 Train_loss 2.0561108027312653 
Epoch [1/5] Batch 5700/14335 Train_loss 2.0558684815614607 
Epoch [1/5] Batch 5800/14335 Train_loss 2.056276497836155 
Epoch [1/5] Batch 5900/14335 Train_loss 2.0565553607728155 
Epoch [1/5] Batch 6000/14335 Train_loss 2.057179695349438 
Epoch [1/5] Batch 6100/14335 Train_loss 2.0561461282170144 
Epoch [1/5] Batch 6200/14335 Train_loss 2.0581026036346985 
Epoch [1/5] Batch 6300/14335 Train_loss 2.058358347627818 
Epoch [1/5] Batch 6400/14335 Train_loss 2.0579180447100995 
Epoch [1/5] Batch 6500/14335 Train_loss 2.0596046487339055 
Epoch [1/5] Batch 6600/14335 Train_loss 2.0587166034982087 
Epoch [1/5] Batch 6700/14335 Train_loss 2.05935693089819 
Epoch [1/5] Batch 6800/14335 Train_loss 2.0585414602938443 
Epoch [1/5] Batch 6900/14335 Train_loss 2.059328959035607 
Epoch [1/5] Batch 7000/14335 Train_loss 2.0590470421997042 
Epoch [1/5] Batch 7100/14335 Train_loss 2.057461523746138 
Epoch [1/5] Batch 7200/14335 Train_loss 2.0578998615925155 
Epoch [1/5] Batch 7300/14335 Train_loss 2.0575094522739694 
Epoch [1/5] Batch 7400/14335 Train_loss 2.057870317906355 
Epoch [1/5] Batch 7500/14335 Train_loss 2.058028637758971 
Epoch [1/5] Batch 7600/14335 Train_loss 2.0565224329906298 
Epoch [1/5] Batch 7700/14335 Train_loss 2.0562946248919047 
Epoch [1/5] Batch 7800/14335 Train_loss 2.0572499840985565 
Epoch [1/5] Batch 7900/14335 Train_loss 2.057067170350661 
Epoch [1/5] Batch 8000/14335 Train_loss 2.057411237869497 
Epoch [1/5] Batch 8100/14335 Train_loss 2.0572621720122077 
Epoch [1/5] Batch 8200/14335 Train_loss 2.0565812733152002 
Epoch [1/5] Batch 8300/14335 Train_loss 2.0556547700884886 
Epoch [1/5] Batch 8400/14335 Train_loss 2.0555132032132493 
Epoch [1/5] Batch 8500/14335 Train_loss 2.054964035439177 
Epoch [1/5] Batch 8600/14335 Train_loss 2.054525588447099 
Epoch [1/5] Batch 8700/14335 Train_loss 2.0533791724573183 
Epoch [1/5] Batch 8800/14335 Train_loss 2.053588118360552 
Epoch [1/5] Batch 8900/14335 Train_loss 2.052290333978394 
Epoch [1/5] Batch 9000/14335 Train_loss 2.051771359923561 
Epoch [1/5] Batch 9100/14335 Train_loss 2.0509723941171814 
Epoch [1/5] Batch 9200/14335 Train_loss 2.0499408159252352 
Epoch [1/5] Batch 9300/14335 Train_loss 2.0498033786874834 
Epoch [1/5] Batch 9400/14335 Train_loss 2.0493296192717825 
Epoch [1/5] Batch 9500/14335 Train_loss 2.049380558343037 
Epoch [1/5] Batch 9600/14335 Train_loss 2.048805293517179 
Epoch [1/5] Batch 9700/14335 Train_loss 2.048610256532273 
Epoch [1/5] Batch 9800/14335 Train_loss 2.048640803320592 
Epoch [1/5] Batch 9900/14335 Train_loss 2.0479255559203384 
Epoch [1/5] Batch 10000/14335 Train_loss 2.04618820573983 
Epoch [1/5] Batch 10100/14335 Train_loss 2.045710859939186 
Epoch [1/5] Batch 10200/14335 Train_loss 2.046116400397229 
Epoch [1/5] Batch 10300/14335 Train_loss 2.045885062040652 
Epoch [1/5] Batch 10400/14335 Train_loss 2.0450623763683793 
Epoch [1/5] Batch 10500/14335 Train_loss 2.0452017516022627 
Epoch [1/5] Batch 10600/14335 Train_loss 2.0459656781711035 
Epoch [1/5] Batch 10700/14335 Train_loss 2.0458163128156728 
Epoch [1/5] Batch 10800/14335 Train_loss 2.0453048745009337 
Epoch [1/5] Batch 10900/14335 Train_loss 2.043899831960709 
Epoch [1/5] Batch 11000/14335 Train_loss 2.044284131329511 
Epoch [1/5] Batch 11100/14335 Train_loss 2.0445055831698573 
Epoch [1/5] Batch 11200/14335 Train_loss 2.0440761608216884 
Epoch [1/5] Batch 11300/14335 Train_loss 2.0431932025913664 
Epoch [1/5] Batch 11400/14335 Train_loss 2.0427830553888158 
Epoch [1/5] Batch 11500/14335 Train_loss 2.0428996394198 
Epoch [1/5] Batch 11600/14335 Train_loss 2.042636734670056 
Epoch [1/5] Batch 11700/14335 Train_loss 2.04156216851932 
Epoch [1/5] Batch 11800/14335 Train_loss 2.0417970951727695 
Epoch [1/5] Batch 11900/14335 Train_loss 2.041446963294936 
Epoch [1/5] Batch 12000/14335 Train_loss 2.041198651774825 
Epoch [1/5] Batch 12100/14335 Train_loss 2.0407515928566666 
Epoch [1/5] Batch 12200/14335 Train_loss 2.0401443603825116 
Epoch [1/5] Batch 12300/14335 Train_loss 2.039988961831824 
Epoch [1/5] Batch 12400/14335 Train_loss 2.0396580499450523 
Epoch [1/5] Batch 12500/14335 Train_loss 2.0397109530211144 
Epoch [1/5] Batch 12600/14335 Train_loss 2.039318887145687 
Epoch [1/5] Batch 12700/14335 Train_loss 2.039010986702178 
Epoch [1/5] Batch 12800/14335 Train_loss 2.0383888979694653 
Epoch [1/5] Batch 12900/14335 Train_loss 2.039232733167472 
Epoch [1/5] Batch 13000/14335 Train_loss 2.0385702745383654 
Epoch [1/5] Batch 13100/14335 Train_loss 2.0380756557135626 
Epoch [1/5] Batch 13200/14335 Train_loss 2.0377798124489734 
Epoch [1/5] Batch 13300/14335 Train_loss 2.037915287687943 
Epoch [1/5] Batch 13400/14335 Train_loss 2.03810887446124 
Epoch [1/5] Batch 13500/14335 Train_loss 2.038089132633009 
Epoch [1/5] Batch 13600/14335 Train_loss 2.0382087098477157 
Epoch [1/5] Batch 13700/14335 Train_loss 2.038037157326917 
Epoch [1/5] Batch 13800/14335 Train_loss 2.0384651352319065 
Epoch [1/5] Batch 13900/14335 Train_loss 2.0381133892722083 
Epoch [1/5] Batch 14000/14335 Train_loss 2.0378794021035476 
Epoch [1/5] Batch 14100/14335 Train_loss 2.037346712638872 
Epoch [1/5] Batch 14200/14335 Train_loss 2.0372624183345804 
Epoch [1/5] Batch 14300/14335 Train_loss 2.03647833340702 
Epoch: 1/5 	Training Loss: 2.035777 	Validation Loss: 2.012615 Duration seconds: 4561.140161991119 
Validation loss decreased (2.046604 --> 2.012615).  Saving model ... 
best_valid_loss_fold [2.012615237946323] Best_Epoch [1]Epoch [2/5] Batch 0/14335 Train_loss 2.008872479200363 
Epoch [2/5] Batch 100/14335 Train_loss 2.050783872456834 
Epoch [2/5] Batch 200/14335 Train_loss 2.023873678709737 
Epoch [2/5] Batch 300/14335 Train_loss 2.0307292541693216 
Epoch [2/5] Batch 400/14335 Train_loss 2.040550237210314 
Epoch [2/5] Batch 500/14335 Train_loss 2.0308015636817185 
Epoch [2/5] Batch 600/14335 Train_loss 2.0184862906246535 
Epoch [2/5] Batch 700/14335 Train_loss 2.018143824074476 
Epoch [2/5] Batch 800/14335 Train_loss 2.013057257035996 
Epoch [2/5] Batch 900/14335 Train_loss 2.0077734175949593 
Epoch [2/5] Batch 1000/14335 Train_loss 2.0048223045114035 
Epoch [2/5] Batch 1100/14335 Train_loss 2.0124875938183173 
Epoch [2/5] Batch 1200/14335 Train_loss 2.0063018229953653 
Epoch [2/5] Batch 1300/14335 Train_loss 2.0124984233655168 
Epoch [2/5] Batch 1400/14335 Train_loss 2.0127810781913347 
Epoch [2/5] Batch 1500/14335 Train_loss 2.0084603157621634 
Epoch [2/5] Batch 1600/14335 Train_loss 2.0014341332386016 
Epoch [2/5] Batch 1700/14335 Train_loss 2.00247884024458 
Epoch [2/5] Batch 1800/14335 Train_loss 2.0000343106641565 
Epoch [2/5] Batch 1900/14335 Train_loss 2.0029926792704265 
Epoch [2/5] Batch 2000/14335 Train_loss 2.0023427209605105 
Epoch [2/5] Batch 2100/14335 Train_loss 1.9980876865499306 
Epoch [2/5] Batch 2200/14335 Train_loss 2.00184566467689 
Epoch [2/5] Batch 2300/14335 Train_loss 1.9998530840184676 
Epoch [2/5] Batch 2400/14335 Train_loss 1.999245163973348 
Epoch [2/5] Batch 2500/14335 Train_loss 1.9993654468723507 
Epoch [2/5] Batch 2600/14335 Train_loss 1.9996709346782697 
Epoch [2/5] Batch 2700/14335 Train_loss 1.997223435613192 
Epoch [2/5] Batch 2800/14335 Train_loss 1.9984323958048689 
Epoch [2/5] Batch 2900/14335 Train_loss 2.000374429824228 
Epoch [2/5] Batch 3000/14335 Train_loss 2.0015847035961443 
Epoch [2/5] Batch 3100/14335 Train_loss 2.0002055740219977 
Epoch [2/5] Batch 3200/14335 Train_loss 1.9977143340764736 
Epoch [2/5] Batch 3300/14335 Train_loss 1.9947371109123846 
Epoch [2/5] Batch 3400/14335 Train_loss 1.9950435332947358 
Epoch [2/5] Batch 3500/14335 Train_loss 1.9939234296497839 
Epoch [2/5] Batch 3600/14335 Train_loss 1.9953446813347737 
Epoch [2/5] Batch 3700/14335 Train_loss 1.9951493796529849 
Epoch [2/5] Batch 3800/14335 Train_loss 1.99715030831166 
Epoch [2/5] Batch 3900/14335 Train_loss 1.9970764363577536 
Epoch [2/5] Batch 4000/14335 Train_loss 1.9971780184171284 
Epoch [2/5] Batch 4100/14335 Train_loss 1.997670926184545 
Epoch [2/5] Batch 4200/14335 Train_loss 1.9992471222606791 
Epoch [2/5] Batch 4300/14335 Train_loss 1.9997135061624298 
Epoch [2/5] Batch 4400/14335 Train_loss 1.9990525260259553 
Epoch [2/5] Batch 4500/14335 Train_loss 2.0010894995163717 
Epoch [2/5] Batch 4600/14335 Train_loss 2.0004204195741724 
Epoch [2/5] Batch 4700/14335 Train_loss 1.9990996531611223 
Epoch [2/5] Batch 4800/14335 Train_loss 1.9997238966201252 
Epoch [2/5] Batch 4900/14335 Train_loss 2.000055451404438 
Epoch [2/5] Batch 5000/14335 Train_loss 1.9996195032796342 
Epoch [2/5] Batch 5100/14335 Train_loss 1.9968745132721633 
Epoch [2/5] Batch 5200/14335 Train_loss 1.9973157918687006 
Epoch [2/5] Batch 5300/14335 Train_loss 1.9965431209139903 
Epoch [2/5] Batch 5400/14335 Train_loss 1.995438763916967 
Epoch [2/5] Batch 5500/14335 Train_loss 1.9941340956801048 
Epoch [2/5] Batch 5600/14335 Train_loss 1.9929416783897607 
Epoch [2/5] Batch 5700/14335 Train_loss 1.9946622947050257 
Epoch [2/5] Batch 5800/14335 Train_loss 1.9971949414351216 
Epoch [2/5] Batch 5900/14335 Train_loss 1.9967987342666436 
Epoch [2/5] Batch 6000/14335 Train_loss 2.0001529581898194 
Epoch [2/5] Batch 6100/14335 Train_loss 2.000037291998688 
Epoch [2/5] Batch 6200/14335 Train_loss 2.0003094681182843 
Epoch [2/5] Batch 6300/14335 Train_loss 2.0002621102713345 
Epoch [2/5] Batch 6400/14335 Train_loss 2.000076844834328 
Epoch [2/5] Batch 6500/14335 Train_loss 2.0001715055966702 
Epoch [2/5] Batch 6600/14335 Train_loss 2.0015942947898124 
Epoch [2/5] Batch 6700/14335 Train_loss 2.0022244122584816 
Epoch [2/5] Batch 6800/14335 Train_loss 2.0005428427007335 
Epoch [2/5] Batch 6900/14335 Train_loss 2.0001435365893325 
Epoch [2/5] Batch 7000/14335 Train_loss 1.9993440080963532 
Epoch [2/5] Batch 7100/14335 Train_loss 1.9991652080793143 
Epoch [2/5] Batch 7200/14335 Train_loss 1.9998490287374082 
Epoch [2/5] Batch 7300/14335 Train_loss 1.9998420464300224 
Epoch [2/5] Batch 7400/14335 Train_loss 1.9999007613610422 
Epoch [2/5] Batch 7500/14335 Train_loss 1.9987168241033488 
Epoch [2/5] Batch 7600/14335 Train_loss 1.9981280595864015 
Epoch [2/5] Batch 7700/14335 Train_loss 1.9976686328308968 
Epoch [2/5] Batch 7800/14335 Train_loss 1.9979935556214645 
Epoch [2/5] Batch 7900/14335 Train_loss 1.997275358003961 
Epoch [2/5] Batch 8000/14335 Train_loss 1.9976117514812295 
Epoch [2/5] Batch 8100/14335 Train_loss 1.9974934133596294 
Epoch [2/5] Batch 8200/14335 Train_loss 1.9975887079356487 
Epoch [2/5] Batch 8300/14335 Train_loss 1.9984398301973096 
Epoch [2/5] Batch 8400/14335 Train_loss 1.998558050748096 
Epoch [2/5] Batch 8500/14335 Train_loss 1.9991797199671077 
Epoch [2/5] Batch 8600/14335 Train_loss 2.0000817898369405 
Epoch [2/5] Batch 8700/14335 Train_loss 2.001665346876751 
Epoch [2/5] Batch 8800/14335 Train_loss 2.001273568667562 
Epoch [2/5] Batch 8900/14335 Train_loss 2.0003427142136525 
Epoch [2/5] Batch 9000/14335 Train_loss 1.9991726322814949 
Epoch [2/5] Batch 9100/14335 Train_loss 1.999258366410856 
Epoch [2/5] Batch 9200/14335 Train_loss 1.9995463204657873 
Epoch [2/5] Batch 9300/14335 Train_loss 1.9997655125125584 
Epoch [2/5] Batch 9400/14335 Train_loss 1.9991522738859635 
Epoch [2/5] Batch 9500/14335 Train_loss 1.9992204414500825 
Epoch [2/5] Batch 9600/14335 Train_loss 1.9981586629478847 
Epoch [2/5] Batch 9700/14335 Train_loss 1.9975544730082897 
Epoch [2/5] Batch 9800/14335 Train_loss 1.995821263256845 
Epoch [2/5] Batch 9900/14335 Train_loss 1.9963484444006345 
Epoch [2/5] Batch 10000/14335 Train_loss 1.996306962501334 
Epoch [2/5] Batch 10100/14335 Train_loss 1.9954146063306546 
Epoch [2/5] Batch 10200/14335 Train_loss 1.9948131040961308 
Epoch [2/5] Batch 10300/14335 Train_loss 1.994848041502715 
Epoch [2/5] Batch 10400/14335 Train_loss 1.9954856573953708 
Epoch [2/5] Batch 10500/14335 Train_loss 1.9955588089856133 
Epoch [2/5] Batch 10600/14335 Train_loss 1.9953845154099414 
Epoch [2/5] Batch 10700/14335 Train_loss 1.9952642587819018 
Epoch [2/5] Batch 10800/14335 Train_loss 1.9946204679863353 
Epoch [2/5] Batch 10900/14335 Train_loss 1.9949340623334486 
Epoch [2/5] Batch 11000/14335 Train_loss 1.9948031982284558 
Epoch [2/5] Batch 11100/14335 Train_loss 1.994440913121181 
Epoch [2/5] Batch 11200/14335 Train_loss 1.9937973937842688 
Epoch [2/5] Batch 11300/14335 Train_loss 1.9930867130841188 
Epoch [2/5] Batch 11400/14335 Train_loss 1.9933638640212736 
Epoch [2/5] Batch 11500/14335 Train_loss 1.994036713127737 
Epoch [2/5] Batch 11600/14335 Train_loss 1.9940477395127554 
Epoch [2/5] Batch 11700/14335 Train_loss 1.9945614780180374 
Epoch [2/5] Batch 11800/14335 Train_loss 1.995563863307609 
Epoch [2/5] Batch 11900/14335 Train_loss 1.9946297686104113 
Epoch [2/5] Batch 12000/14335 Train_loss 1.9938489663984347 
Epoch [2/5] Batch 12100/14335 Train_loss 1.993336825891769 
Epoch [2/5] Batch 12200/14335 Train_loss 1.9933100390112817 
Epoch [2/5] Batch 12300/14335 Train_loss 1.992710803239222 
Epoch [2/5] Batch 12400/14335 Train_loss 1.9927929048359985 
Epoch [2/5] Batch 12500/14335 Train_loss 1.9929539810029633 
Epoch [2/5] Batch 12600/14335 Train_loss 1.9926621273435512 
Epoch [2/5] Batch 12700/14335 Train_loss 1.9925642569248962 
Epoch [2/5] Batch 12800/14335 Train_loss 1.9919282700070533 
Epoch [2/5] Batch 12900/14335 Train_loss 1.9918512425344772 
Epoch [2/5] Batch 13000/14335 Train_loss 1.9920258545736176 
Epoch [2/5] Batch 13100/14335 Train_loss 1.9928086404194951 
Epoch [2/5] Batch 13200/14335 Train_loss 1.9928879954717202 
Epoch [2/5] Batch 13300/14335 Train_loss 1.9926520922373814 
Epoch [2/5] Batch 13400/14335 Train_loss 1.992442074330002 
Epoch [2/5] Batch 13500/14335 Train_loss 1.992180691082101 
Epoch [2/5] Batch 13600/14335 Train_loss 1.9917705241895038 
Epoch [2/5] Batch 13700/14335 Train_loss 1.9911044914460028 
Epoch [2/5] Batch 13800/14335 Train_loss 1.9913513626603405 
Epoch [2/5] Batch 13900/14335 Train_loss 1.9907176694677644 
Epoch [2/5] Batch 14000/14335 Train_loss 1.991210255693916 
Epoch [2/5] Batch 14100/14335 Train_loss 1.9910603553335697 
Epoch [2/5] Batch 14200/14335 Train_loss 1.9905198036755536 
Epoch [2/5] Batch 14300/14335 Train_loss 1.9905517517511733 
Epoch: 2/5 	Training Loss: 1.990557 	Validation Loss: 1.961675 Duration seconds: 4257.313280820847 
Validation loss decreased (2.012615 --> 1.961675).  Saving model ... 
best_valid_loss_fold [1.9616750167354309] Best_Epoch [2]Epoch [3/5] Batch 0/14335 Train_loss 2.503785192966461 
Epoch [3/5] Batch 100/14335 Train_loss 2.0569229221875123 
Epoch [3/5] Batch 200/14335 Train_loss 2.029496503261784 
Epoch [3/5] Batch 300/14335 Train_loss 2.00721122398725 
Epoch [3/5] Batch 400/14335 Train_loss 1.9748401712449708 
Epoch [3/5] Batch 500/14335 Train_loss 1.978039871046167 
Epoch [3/5] Batch 600/14335 Train_loss 1.9689670071228966 
Epoch [3/5] Batch 700/14335 Train_loss 1.9511298391006133 
Epoch [3/5] Batch 800/14335 Train_loss 1.953065756257256 
Epoch [3/5] Batch 900/14335 Train_loss 1.9542969181124827 
Epoch [3/5] Batch 1000/14335 Train_loss 1.9506689072488905 
Epoch [3/5] Batch 1100/14335 Train_loss 1.9597764748345712 
Epoch [3/5] Batch 1200/14335 Train_loss 1.953542039331846 
Epoch [3/5] Batch 1300/14335 Train_loss 1.9517831286726137 
Epoch [3/5] Batch 1400/14335 Train_loss 1.9572370853022454 
Epoch [3/5] Batch 1500/14335 Train_loss 1.9616020534889924 
Epoch [3/5] Batch 1600/14335 Train_loss 1.9580868760974313 
Epoch [3/5] Batch 1700/14335 Train_loss 1.9535769930855096 
Epoch [3/5] Batch 1800/14335 Train_loss 1.9628681200269458 
Epoch [3/5] Batch 1900/14335 Train_loss 1.9654700566849415 
Epoch [3/5] Batch 2000/14335 Train_loss 1.9637755775961026 
Epoch [3/5] Batch 2100/14335 Train_loss 1.9611657127518134 
Epoch [3/5] Batch 2200/14335 Train_loss 1.9606501662909903 
Epoch [3/5] Batch 2300/14335 Train_loss 1.9598644467047224 
Epoch [3/5] Batch 2400/14335 Train_loss 1.9564781413382166 
Epoch [3/5] Batch 2500/14335 Train_loss 1.9561507726838139 
Epoch [3/5] Batch 2600/14335 Train_loss 1.9549337504965119 
Epoch [3/5] Batch 2700/14335 Train_loss 1.9583343246917908 
Epoch [3/5] Batch 2800/14335 Train_loss 1.9578034862987657 
Epoch [3/5] Batch 2900/14335 Train_loss 1.956570238023945 
Epoch [3/5] Batch 3000/14335 Train_loss 1.9552282107915135 
Epoch [3/5] Batch 3100/14335 Train_loss 1.9564326251420003 
Epoch [3/5] Batch 3200/14335 Train_loss 1.9563664009946466 
Epoch [3/5] Batch 3300/14335 Train_loss 1.958061369286635 
Epoch [3/5] Batch 3400/14335 Train_loss 1.9577141753481402 
Epoch [3/5] Batch 3500/14335 Train_loss 1.954820117854929 
Epoch [3/5] Batch 3600/14335 Train_loss 1.9529952871091032 
Epoch [3/5] Batch 3700/14335 Train_loss 1.951825907728183 
Epoch [3/5] Batch 3800/14335 Train_loss 1.9528159767318731 
Epoch [3/5] Batch 3900/14335 Train_loss 1.9529459497518216 
Epoch [3/5] Batch 4000/14335 Train_loss 1.9523388071749634 
Epoch [3/5] Batch 4100/14335 Train_loss 1.9499624944756422 
Epoch [3/5] Batch 4200/14335 Train_loss 1.9495101918623126 
Epoch [3/5] Batch 4300/14335 Train_loss 1.9508005255628424 
Epoch [3/5] Batch 4400/14335 Train_loss 1.9516667789679931 
Epoch [3/5] Batch 4500/14335 Train_loss 1.949940790537926 
Epoch [3/5] Batch 4600/14335 Train_loss 1.9510121805396217 
Epoch [3/5] Batch 4700/14335 Train_loss 1.9503448998257977 
Epoch [3/5] Batch 4800/14335 Train_loss 1.9501366811965286 
Epoch [3/5] Batch 4900/14335 Train_loss 1.9519746081986808 
Epoch [3/5] Batch 5000/14335 Train_loss 1.9516497091430232 
Epoch [3/5] Batch 5100/14335 Train_loss 1.9527840344324763 
Epoch [3/5] Batch 5200/14335 Train_loss 1.9525118921596003 
Epoch [3/5] Batch 5300/14335 Train_loss 1.951661004560654 
Epoch [3/5] Batch 5400/14335 Train_loss 1.9532379676246285 
Epoch [3/5] Batch 5500/14335 Train_loss 1.9528322850879356 
Epoch [3/5] Batch 5600/14335 Train_loss 1.9513361699316485 
Epoch [3/5] Batch 5700/14335 Train_loss 1.951436945432436 
Epoch [3/5] Batch 5800/14335 Train_loss 1.952331057635541 
Epoch [3/5] Batch 5900/14335 Train_loss 1.9515966859306346 
Epoch [3/5] Batch 6000/14335 Train_loss 1.9522449987589905 
Epoch [3/5] Batch 6100/14335 Train_loss 1.9521530846753896 
Epoch [3/5] Batch 6200/14335 Train_loss 1.951383578842916 
Epoch [3/5] Batch 6300/14335 Train_loss 1.9523335009555536 
Epoch [3/5] Batch 6400/14335 Train_loss 1.9519212684094898 
Epoch [3/5] Batch 6500/14335 Train_loss 1.9511189067344026 
Epoch [3/5] Batch 6600/14335 Train_loss 1.950503189487496 
Epoch [3/5] Batch 6700/14335 Train_loss 1.9513474756660274 
Epoch [3/5] Batch 6800/14335 Train_loss 1.9508762166907534 
Epoch [3/5] Batch 6900/14335 Train_loss 1.9513630791051875 
Epoch [3/5] Batch 7000/14335 Train_loss 1.9515826798567872 
Epoch [3/5] Batch 7100/14335 Train_loss 1.951295229123816 
Epoch [3/5] Batch 7200/14335 Train_loss 1.9525002248387604 
Epoch [3/5] Batch 7300/14335 Train_loss 1.953625185401117 
Epoch [3/5] Batch 7400/14335 Train_loss 1.953561343041252 
Epoch [3/5] Batch 7500/14335 Train_loss 1.953440952557887 
Epoch [3/5] Batch 7600/14335 Train_loss 1.951592052515918 
Epoch [3/5] Batch 7700/14335 Train_loss 1.9521733987609637 
Epoch [3/5] Batch 7800/14335 Train_loss 1.953047724762317 
Epoch [3/5] Batch 7900/14335 Train_loss 1.9526042435080126 
Epoch [3/5] Batch 8000/14335 Train_loss 1.9531882072346924 
Epoch [3/5] Batch 8100/14335 Train_loss 1.953241981725982 
Epoch [3/5] Batch 8200/14335 Train_loss 1.953610028313429 
Epoch [3/5] Batch 8300/14335 Train_loss 1.9544576677144716 
Epoch [3/5] Batch 8400/14335 Train_loss 1.954374858867184 
Epoch [3/5] Batch 8500/14335 Train_loss 1.954478251688299 
Epoch [3/5] Batch 8600/14335 Train_loss 1.9554819051709484 
Epoch [3/5] Batch 8700/14335 Train_loss 1.9548289014486564 
Epoch [3/5] Batch 8800/14335 Train_loss 1.9543532330198676 
Epoch [3/5] Batch 8900/14335 Train_loss 1.9538374863914019 
Epoch [3/5] Batch 9000/14335 Train_loss 1.9542812720833453 
Epoch [3/5] Batch 9100/14335 Train_loss 1.954297073805166 
Epoch [3/5] Batch 9200/14335 Train_loss 1.9543127742390596 
Epoch [3/5] Batch 9300/14335 Train_loss 1.9550123150221008 
Epoch [3/5] Batch 9400/14335 Train_loss 1.9551312069241866 
Epoch [3/5] Batch 9500/14335 Train_loss 1.9551794138952576 
Epoch [3/5] Batch 9600/14335 Train_loss 1.9550630407101934 
Epoch [3/5] Batch 9700/14335 Train_loss 1.9551850843522958 
Epoch [3/5] Batch 9800/14335 Train_loss 1.9555337604299856 
Epoch [3/5] Batch 9900/14335 Train_loss 1.955749969276656 
Epoch [3/5] Batch 10000/14335 Train_loss 1.955257556418421 
Epoch [3/5] Batch 10100/14335 Train_loss 1.9559585680502285 
Epoch [3/5] Batch 10200/14335 Train_loss 1.9572002832246358 
Epoch [3/5] Batch 10300/14335 Train_loss 1.9561582513760392 
Epoch [3/5] Batch 10400/14335 Train_loss 1.9552535257403316 
Epoch [3/5] Batch 10500/14335 Train_loss 1.955658223981256 
Epoch [3/5] Batch 10600/14335 Train_loss 1.9555388058444125 
Epoch [3/5] Batch 10700/14335 Train_loss 1.955099714135424 
Epoch [3/5] Batch 10800/14335 Train_loss 1.9550990225272469 
Epoch [3/5] Batch 10900/14335 Train_loss 1.9546035562438842 
Epoch [3/5] Batch 11000/14335 Train_loss 1.9554505458274503 
Epoch [3/5] Batch 11100/14335 Train_loss 1.9557692987412958 
Epoch [3/5] Batch 11200/14335 Train_loss 1.9560107409737226 
Epoch [3/5] Batch 11300/14335 Train_loss 1.9555673897681738 
Epoch [3/5] Batch 11400/14335 Train_loss 1.9553727382752688 
Epoch [3/5] Batch 11500/14335 Train_loss 1.9552926676983202 
Epoch [3/5] Batch 11600/14335 Train_loss 1.9552185231158727 
Epoch [3/5] Batch 11700/14335 Train_loss 1.955625635554506 
Epoch [3/5] Batch 11800/14335 Train_loss 1.9550945836999853 
Epoch [3/5] Batch 11900/14335 Train_loss 1.9554304944033754 
Epoch [3/5] Batch 12000/14335 Train_loss 1.9553642857839353 
Epoch [3/5] Batch 12100/14335 Train_loss 1.9547956567862568 
Epoch [3/5] Batch 12200/14335 Train_loss 1.9548291827283104 
Epoch [3/5] Batch 12300/14335 Train_loss 1.9545542288584619 
Epoch [3/5] Batch 12400/14335 Train_loss 1.9538225665022824 
Epoch [3/5] Batch 12500/14335 Train_loss 1.9533598507963774 
Epoch [3/5] Batch 12600/14335 Train_loss 1.9532415455695173 
Epoch [3/5] Batch 12700/14335 Train_loss 1.952841691851719 
Epoch [3/5] Batch 12800/14335 Train_loss 1.9535621091678044 
Epoch [3/5] Batch 12900/14335 Train_loss 1.9537977116111267 
Epoch [3/5] Batch 13000/14335 Train_loss 1.9543036587955254 
Epoch [3/5] Batch 13100/14335 Train_loss 1.9543241538063605 
Epoch [3/5] Batch 13200/14335 Train_loss 1.953694591129804 
Epoch [3/5] Batch 13300/14335 Train_loss 1.9532677114657393 
Epoch [3/5] Batch 13400/14335 Train_loss 1.9541555791970964 
Epoch [3/5] Batch 13500/14335 Train_loss 1.9543454855400124 
Epoch [3/5] Batch 13600/14335 Train_loss 1.954242769965932 
Epoch [3/5] Batch 13700/14335 Train_loss 1.9540881494472222 
Epoch [3/5] Batch 13800/14335 Train_loss 1.9540687677596982 
Epoch [3/5] Batch 13900/14335 Train_loss 1.9536616314414526 
Epoch [3/5] Batch 14000/14335 Train_loss 1.9536591080912658 
Epoch [3/5] Batch 14100/14335 Train_loss 1.9528855846303295 
Epoch [3/5] Batch 14200/14335 Train_loss 1.9525455701622725 
Epoch [3/5] Batch 14300/14335 Train_loss 1.9525068761758326 
Epoch: 3/5 	Training Loss: 1.952411 	Validation Loss: 1.945854 Duration seconds: 4690.955976724625 
Validation loss decreased (1.961675 --> 1.945854).  Saving model ... 
best_valid_loss_fold [1.9458535437297542] Best_Epoch [3]Epoch [4/5] Batch 0/14335 Train_loss 1.5086980164051056 
Epoch [4/5] Batch 100/14335 Train_loss 1.9608942124218043 
Epoch [4/5] Batch 200/14335 Train_loss 1.9421690806227536 
Epoch [4/5] Batch 300/14335 Train_loss 1.9265700349479022 
Epoch [4/5] Batch 400/14335 Train_loss 1.9378616272511329 
Epoch [4/5] Batch 500/14335 Train_loss 1.9333833064921127 
Epoch [4/5] Batch 600/14335 Train_loss 1.9274083904289763 
Epoch [4/5] Batch 700/14335 Train_loss 1.9341025698116945 
Epoch [4/5] Batch 800/14335 Train_loss 1.9315550400039527 
Epoch [4/5] Batch 900/14335 Train_loss 1.9350382492988143 
Epoch [4/5] Batch 1000/14335 Train_loss 1.9343911716481903 
Epoch [4/5] Batch 1100/14335 Train_loss 1.9384257316751765 
Epoch [4/5] Batch 1200/14335 Train_loss 1.935950929948829 
Epoch [4/5] Batch 1300/14335 Train_loss 1.9434796507934897 
Epoch [4/5] Batch 1400/14335 Train_loss 1.9394995340762353 
Epoch [4/5] Batch 1500/14335 Train_loss 1.9494594821705173 
Epoch [4/5] Batch 1600/14335 Train_loss 1.949470650351174 
Epoch [4/5] Batch 1700/14335 Train_loss 1.9480085560393852 
Epoch [4/5] Batch 1800/14335 Train_loss 1.9479070825172358 
Epoch [4/5] Batch 1900/14335 Train_loss 1.9433506623278913 
Epoch [4/5] Batch 2000/14335 Train_loss 1.9465298497903234 
Epoch [4/5] Batch 2100/14335 Train_loss 1.9453574105678768 
Epoch [4/5] Batch 2200/14335 Train_loss 1.947142287465942 
Epoch [4/5] Batch 2300/14335 Train_loss 1.9484101905479787 
Epoch [4/5] Batch 2400/14335 Train_loss 1.9452361882614226 
Epoch [4/5] Batch 2500/14335 Train_loss 1.948886041949149 
Epoch [4/5] Batch 2600/14335 Train_loss 1.9471132572237595 
Epoch [4/5] Batch 2700/14335 Train_loss 1.9472086632066372 
Epoch [4/5] Batch 2800/14335 Train_loss 1.9486622069721262 
Epoch [4/5] Batch 2900/14335 Train_loss 1.9474827790467832 
Epoch [4/5] Batch 3000/14335 Train_loss 1.9480699327579143 
Epoch [4/5] Batch 3100/14335 Train_loss 1.9492961796434876 
Epoch [4/5] Batch 3200/14335 Train_loss 1.9462269647713193 
Epoch [4/5] Batch 3300/14335 Train_loss 1.9448406766830375 
Epoch [4/5] Batch 3400/14335 Train_loss 1.945354606308891 
Epoch [4/5] Batch 3500/14335 Train_loss 1.9449374942660707 
Epoch [4/5] Batch 3600/14335 Train_loss 1.9441664245593087 
Epoch [4/5] Batch 3700/14335 Train_loss 1.94491449778739 
Epoch [4/5] Batch 3800/14335 Train_loss 1.9473891477503609 
Epoch [4/5] Batch 3900/14335 Train_loss 1.9495338556958113 
Epoch [4/5] Batch 4000/14335 Train_loss 1.9494798866823833 
Epoch [4/5] Batch 4100/14335 Train_loss 1.9482076219838296 
Epoch [4/5] Batch 4200/14335 Train_loss 1.9491086615228677 
Epoch [4/5] Batch 4300/14335 Train_loss 1.949231398712616 
Epoch [4/5] Batch 4400/14335 Train_loss 1.9496903533124024 
Epoch [4/5] Batch 4500/14335 Train_loss 1.9481064881272805 
Epoch [4/5] Batch 4600/14335 Train_loss 1.9471214822428922 
Epoch [4/5] Batch 4700/14335 Train_loss 1.9464495738144505 
Epoch [4/5] Batch 4800/14335 Train_loss 1.9453292876991026 
Epoch [4/5] Batch 4900/14335 Train_loss 1.9445354018988985 
Epoch [4/5] Batch 5000/14335 Train_loss 1.9466684288923513 
Epoch [4/5] Batch 5100/14335 Train_loss 1.9452345042024446 
Epoch [4/5] Batch 5200/14335 Train_loss 1.9434720022223175 
Epoch [4/5] Batch 5300/14335 Train_loss 1.9435448959326433 
Epoch [4/5] Batch 5400/14335 Train_loss 1.9434610915788786 
Epoch [4/5] Batch 5500/14335 Train_loss 1.9431640229437963 
Epoch [4/5] Batch 5600/14335 Train_loss 1.9445596402951637 
Epoch [4/5] Batch 5700/14335 Train_loss 1.9436869626269175 
Epoch [4/5] Batch 5800/14335 Train_loss 1.9428092983776568 
Epoch [4/5] Batch 5900/14335 Train_loss 1.944033489227194 
Epoch [4/5] Batch 6000/14335 Train_loss 1.9437371772183039 
Epoch [4/5] Batch 6100/14335 Train_loss 1.9432515063098836 
Epoch [4/5] Batch 6200/14335 Train_loss 1.9445508913135667 
Epoch [4/5] Batch 6300/14335 Train_loss 1.9440671370329696 
Epoch [4/5] Batch 6400/14335 Train_loss 1.9444184944701741 
Epoch [4/5] Batch 6500/14335 Train_loss 1.9443433759070747 
Epoch [4/5] Batch 6600/14335 Train_loss 1.9444971275526437 
Epoch [4/5] Batch 6700/14335 Train_loss 1.9426846593382678 
Epoch [4/5] Batch 6800/14335 Train_loss 1.9417841809626064 
Epoch [4/5] Batch 6900/14335 Train_loss 1.9420986454904192 
Epoch [4/5] Batch 7000/14335 Train_loss 1.9414516521460532 
Epoch [4/5] Batch 7100/14335 Train_loss 1.942313923181119 
Epoch [4/5] Batch 7200/14335 Train_loss 1.942343624134624 
Epoch [4/5] Batch 7300/14335 Train_loss 1.940850163415154 
Epoch [4/5] Batch 7400/14335 Train_loss 1.940718596699737 
Epoch [4/5] Batch 7500/14335 Train_loss 1.9395601601421697 
Epoch [4/5] Batch 7600/14335 Train_loss 1.9401641388838737 
Epoch [4/5] Batch 7700/14335 Train_loss 1.9387733450246747 
Epoch [4/5] Batch 7800/14335 Train_loss 1.939491569315863 
Epoch [4/5] Batch 7900/14335 Train_loss 1.9389997911730863 
Epoch [4/5] Batch 8000/14335 Train_loss 1.9381911527431097 
Epoch [4/5] Batch 8100/14335 Train_loss 1.9377661038660559 
Epoch [4/5] Batch 8200/14335 Train_loss 1.9370525610031202 
Epoch [4/5] Batch 8300/14335 Train_loss 1.9352239185270812 
Epoch [4/5] Batch 8400/14335 Train_loss 1.935616243759687 
Epoch [4/5] Batch 8500/14335 Train_loss 1.934954199829097 
Epoch [4/5] Batch 8600/14335 Train_loss 1.9337047433114416 
Epoch [4/5] Batch 8700/14335 Train_loss 1.9336865201494828 
Epoch [4/5] Batch 8800/14335 Train_loss 1.9339747608737394 
Epoch [4/5] Batch 8900/14335 Train_loss 1.9326024981559415 
Epoch [4/5] Batch 9000/14335 Train_loss 1.9323704267803687 
Epoch [4/5] Batch 9100/14335 Train_loss 1.9313825229660728 
Epoch [4/5] Batch 9200/14335 Train_loss 1.9305284202597657 
Epoch [4/5] Batch 9300/14335 Train_loss 1.930273988747479 
Epoch [4/5] Batch 9400/14335 Train_loss 1.929697230547023 
Epoch [4/5] Batch 9500/14335 Train_loss 1.929250791325417 
Epoch [4/5] Batch 9600/14335 Train_loss 1.9291211410064075 
Epoch [4/5] Batch 9700/14335 Train_loss 1.9285803043913587 
Epoch [4/5] Batch 9800/14335 Train_loss 1.9289824462885055 
Epoch [4/5] Batch 9900/14335 Train_loss 1.929099463470451 
Epoch [4/5] Batch 10000/14335 Train_loss 1.9289265135942895 
Epoch [4/5] Batch 10100/14335 Train_loss 1.9299388557905586 
Epoch [4/5] Batch 10200/14335 Train_loss 1.9309209720426512 
Epoch [4/5] Batch 10300/14335 Train_loss 1.9310001089102828 
Epoch [4/5] Batch 10400/14335 Train_loss 1.930149186733147 
Epoch [4/5] Batch 10500/14335 Train_loss 1.930654087382298 
Epoch [4/5] Batch 10600/14335 Train_loss 1.9305886895746434 
Epoch [4/5] Batch 10700/14335 Train_loss 1.930829480815386 
Epoch [4/5] Batch 10800/14335 Train_loss 1.9310246817177836 
Epoch [4/5] Batch 10900/14335 Train_loss 1.9311605438039168 
Epoch [4/5] Batch 11000/14335 Train_loss 1.931813665058773 
Epoch [4/5] Batch 11100/14335 Train_loss 1.930775257939423 
Epoch [4/5] Batch 11200/14335 Train_loss 1.9310565797433972 
Epoch [4/5] Batch 11300/14335 Train_loss 1.931045521952264 
Epoch [4/5] Batch 11400/14335 Train_loss 1.9310803215079282 
Epoch [4/5] Batch 11500/14335 Train_loss 1.9303804456944071 
Epoch [4/5] Batch 11600/14335 Train_loss 1.929624031475521 
Epoch [4/5] Batch 11700/14335 Train_loss 1.9290818220216 
Epoch [4/5] Batch 11800/14335 Train_loss 1.929097927474802 
Epoch [4/5] Batch 11900/14335 Train_loss 1.9286612464095774 
Epoch [4/5] Batch 12000/14335 Train_loss 1.9280475433166202 
Epoch [4/5] Batch 12100/14335 Train_loss 1.9291474197499172 
Epoch [4/5] Batch 12200/14335 Train_loss 1.9296401642820462 
Epoch [4/5] Batch 12300/14335 Train_loss 1.9295811133153187 
Epoch [4/5] Batch 12400/14335 Train_loss 1.9292276333418212 
Epoch [4/5] Batch 12500/14335 Train_loss 1.9296435931688996 
Epoch [4/5] Batch 12600/14335 Train_loss 1.9293215699093595 
Epoch [4/5] Batch 12700/14335 Train_loss 1.929545866462032 
Epoch [4/5] Batch 12800/14335 Train_loss 1.9287932966288324 
Epoch [4/5] Batch 12900/14335 Train_loss 1.9284399429652526 
Epoch [4/5] Batch 13000/14335 Train_loss 1.928315839976125 
Epoch [4/5] Batch 13100/14335 Train_loss 1.9282606716025568 
Epoch [4/5] Batch 13200/14335 Train_loss 1.9280265344950378 
Epoch [4/5] Batch 13300/14335 Train_loss 1.9283213790145666 
Epoch [4/5] Batch 13400/14335 Train_loss 1.9274104112779664 
Epoch [4/5] Batch 13500/14335 Train_loss 1.9272469541085675 
Epoch [4/5] Batch 13600/14335 Train_loss 1.9279503549441819 
Epoch [4/5] Batch 13700/14335 Train_loss 1.928621198769647 
Epoch [4/5] Batch 13800/14335 Train_loss 1.9286822840845652 
Epoch [4/5] Batch 13900/14335 Train_loss 1.9284782540965626 
Epoch [4/5] Batch 14000/14335 Train_loss 1.9282543200313829 
Epoch [4/5] Batch 14100/14335 Train_loss 1.9282843803400547 
Epoch [4/5] Batch 14200/14335 Train_loss 1.9282618089492545 
Epoch [4/5] Batch 14300/14335 Train_loss 1.9282523434720926 
Epoch: 4/5 	Training Loss: 1.927937 	Validation Loss: 1.909040 Duration seconds: 4792.823208093643 
Validation loss decreased (1.945854 --> 1.909040).  Saving model ... 
best_valid_loss_fold [1.9090397769177798] Best_Epoch [4]Fold: 1/5 
Epoch [0/5] Batch 0/14335 Train_loss 2.8844335675239563 
Epoch [0/5] Batch 100/14335 Train_loss 2.048373425213417 
Epoch [0/5] Batch 200/14335 Train_loss 1.942758397454053 
Epoch [0/5] Batch 300/14335 Train_loss 1.9301653460311732 
Epoch [0/5] Batch 400/14335 Train_loss 1.9307966651093038 
Epoch [0/5] Batch 500/14335 Train_loss 1.932307392537237 
Epoch [0/5] Batch 600/14335 Train_loss 1.9370504064538119 
Epoch [0/5] Batch 700/14335 Train_loss 1.9469569286546762 
Epoch [0/5] Batch 800/14335 Train_loss 1.934488724903221 
Epoch [0/5] Batch 900/14335 Train_loss 1.923957605506154 
Epoch [0/5] Batch 1000/14335 Train_loss 1.9297448684136709 
Epoch [0/5] Batch 1100/14335 Train_loss 1.9317289510171702 
Epoch [0/5] Batch 1200/14335 Train_loss 1.9360638733063014 
Epoch [0/5] Batch 1300/14335 Train_loss 1.9518525670529512 
Epoch [0/5] Batch 1400/14335 Train_loss 1.9450788618963502 
Epoch [0/5] Batch 1500/14335 Train_loss 1.9440386082473236 
Epoch [0/5] Batch 1600/14335 Train_loss 1.9414862746059858 
Epoch [0/5] Batch 1700/14335 Train_loss 1.9445045759298043 
Epoch [0/5] Batch 1800/14335 Train_loss 1.9463732527948499 
Epoch [0/5] Batch 1900/14335 Train_loss 1.9429862701080776 
Epoch [0/5] Batch 2000/14335 Train_loss 1.9419641873572602 
Epoch [0/5] Batch 2100/14335 Train_loss 1.9433887202872486 
Epoch [0/5] Batch 2200/14335 Train_loss 1.9450609574178195 
Epoch [0/5] Batch 2300/14335 Train_loss 1.9452533741740234 
Epoch [0/5] Batch 2400/14335 Train_loss 1.9414536836171141 
Epoch [0/5] Batch 2500/14335 Train_loss 1.93932601600373 
Epoch [0/5] Batch 2600/14335 Train_loss 1.9382724714755828 
Epoch [0/5] Batch 2700/14335 Train_loss 1.9384850602168058 
Epoch [0/5] Batch 2800/14335 Train_loss 1.9370023911816867 
Epoch [0/5] Batch 2900/14335 Train_loss 1.93328402353459 
Epoch [0/5] Batch 3000/14335 Train_loss 1.9336130830773668 
Epoch [0/5] Batch 3100/14335 Train_loss 1.9340211455522527 
Epoch [0/5] Batch 3200/14335 Train_loss 1.934266127238643 
Epoch [0/5] Batch 3300/14335 Train_loss 1.9324211924320205 
Epoch [0/5] Batch 3400/14335 Train_loss 1.9299779914514488 
Epoch [0/5] Batch 3500/14335 Train_loss 1.9303860998867035 
Epoch [0/5] Batch 3600/14335 Train_loss 1.9308077851845735 
Epoch [0/5] Batch 3700/14335 Train_loss 1.9280963961786917 
Epoch [0/5] Batch 3800/14335 Train_loss 1.9286132558603972 
Epoch [0/5] Batch 3900/14335 Train_loss 1.9287156753702306 
Epoch [0/5] Batch 4000/14335 Train_loss 1.9280213860422932 
Epoch [0/5] Batch 4100/14335 Train_loss 1.9280994178623259 
Epoch [0/5] Batch 4200/14335 Train_loss 1.9276398855202312 
Epoch [0/5] Batch 4300/14335 Train_loss 1.9280509538454833 
Epoch [0/5] Batch 4400/14335 Train_loss 1.928698137483795 
Epoch [0/5] Batch 4500/14335 Train_loss 1.9277688421737722 
Epoch [0/5] Batch 4600/14335 Train_loss 1.9264204836564074 
Epoch [0/5] Batch 4700/14335 Train_loss 1.9263047099405084 
Epoch [0/5] Batch 4800/14335 Train_loss 1.9286081259591061 
Epoch [0/5] Batch 4900/14335 Train_loss 1.9287969965249805 
Epoch [0/5] Batch 5000/14335 Train_loss 1.9299541969784162 
Epoch [0/5] Batch 5100/14335 Train_loss 1.9314609598561938 
Epoch [0/5] Batch 5200/14335 Train_loss 1.9314706626934997 
Epoch [0/5] Batch 5300/14335 Train_loss 1.9327461592595863 
Epoch [0/5] Batch 5400/14335 Train_loss 1.9316650455559963 
Epoch [0/5] Batch 5500/14335 Train_loss 1.9331561603360428 
Epoch [0/5] Batch 5600/14335 Train_loss 1.934200213399663 
Epoch [0/5] Batch 5700/14335 Train_loss 1.9345256911126423 
Epoch [0/5] Batch 5800/14335 Train_loss 1.9327837974089956 
Epoch [0/5] Batch 5900/14335 Train_loss 1.9327965580524176 
Epoch [0/5] Batch 6000/14335 Train_loss 1.9325012410358475 
Epoch [0/5] Batch 6100/14335 Train_loss 1.9336708390239887 
Epoch [0/5] Batch 6200/14335 Train_loss 1.9322247921199764 
Epoch [0/5] Batch 6300/14335 Train_loss 1.931685415977354 
Epoch [0/5] Batch 6400/14335 Train_loss 1.9325319181855927 
Epoch [0/5] Batch 6500/14335 Train_loss 1.9314722098505253 
Epoch [0/5] Batch 6600/14335 Train_loss 1.931327770486273 
Epoch [0/5] Batch 6700/14335 Train_loss 1.9294592661544328 
Epoch [0/5] Batch 6800/14335 Train_loss 1.930175085448374 
Epoch [0/5] Batch 6900/14335 Train_loss 1.929126198162913 
Epoch [0/5] Batch 7000/14335 Train_loss 1.9306454579883976 
Epoch [0/5] Batch 7100/14335 Train_loss 1.9304846769201136 
Epoch [0/5] Batch 7200/14335 Train_loss 1.9305210440022436 
Epoch [0/5] Batch 7300/14335 Train_loss 1.9289717277101974 
Epoch [0/5] Batch 7400/14335 Train_loss 1.9298577157347898 
Epoch [0/5] Batch 7500/14335 Train_loss 1.929851621806566 
Epoch [0/5] Batch 7600/14335 Train_loss 1.930253833940101 
Epoch [0/5] Batch 7700/14335 Train_loss 1.9302208075166105 
Epoch [0/5] Batch 7800/14335 Train_loss 1.9306795541548054 
Epoch [0/5] Batch 7900/14335 Train_loss 1.930031821276927 
Epoch [0/5] Batch 8000/14335 Train_loss 1.9297080066107672 
Epoch [0/5] Batch 8100/14335 Train_loss 1.9296525567199783 
Epoch [0/5] Batch 8200/14335 Train_loss 1.9298087511610917 
Epoch [0/5] Batch 8300/14335 Train_loss 1.929525750684833 
Epoch [0/5] Batch 8400/14335 Train_loss 1.9300239623912585 
Epoch [0/5] Batch 8500/14335 Train_loss 1.9301281042231375 
Epoch [0/5] Batch 8600/14335 Train_loss 1.9298503434428669 
Epoch [0/5] Batch 8700/14335 Train_loss 1.9288534079714215 
Epoch [0/5] Batch 8800/14335 Train_loss 1.9286669882935241 
Epoch [0/5] Batch 8900/14335 Train_loss 1.9282899860913345 
Epoch [0/5] Batch 9000/14335 Train_loss 1.9281849540325553 
Epoch [0/5] Batch 9100/14335 Train_loss 1.9279011132156911 
Epoch [0/5] Batch 9200/14335 Train_loss 1.928787846812579 
Epoch [0/5] Batch 9300/14335 Train_loss 1.9288033509017986 
Epoch [0/5] Batch 9400/14335 Train_loss 1.9288612195702641 
Epoch [0/5] Batch 9500/14335 Train_loss 1.929040244740193 
Epoch [0/5] Batch 9600/14335 Train_loss 1.929890372742962 
Epoch [0/5] Batch 9700/14335 Train_loss 1.9295515039387148 
Epoch [0/5] Batch 9800/14335 Train_loss 1.9287526286334946 
Epoch [0/5] Batch 9900/14335 Train_loss 1.9286376616681733 
Epoch [0/5] Batch 10000/14335 Train_loss 1.928234267925849 
Epoch [0/5] Batch 10100/14335 Train_loss 1.9290073498760447 
Epoch [0/5] Batch 10200/14335 Train_loss 1.9291605141078498 
Epoch [0/5] Batch 10300/14335 Train_loss 1.9285737127340508 
Epoch [0/5] Batch 10400/14335 Train_loss 1.928860339398866 
Epoch [0/5] Batch 10500/14335 Train_loss 1.928609349731093 
Epoch [0/5] Batch 10600/14335 Train_loss 1.9283380699645751 
Epoch [0/5] Batch 10700/14335 Train_loss 1.9277601346266335 
Epoch [0/5] Batch 10800/14335 Train_loss 1.9285450879139168 
Epoch [0/5] Batch 10900/14335 Train_loss 1.9287986744326109 
Epoch [0/5] Batch 11000/14335 Train_loss 1.9288442099449818 
Epoch [0/5] Batch 11100/14335 Train_loss 1.9277443492689623 
Epoch [0/5] Batch 11200/14335 Train_loss 1.928087357767894 
Epoch [0/5] Batch 11300/14335 Train_loss 1.9276714262978376 
Epoch [0/5] Batch 11400/14335 Train_loss 1.9272893341515485 
Epoch [0/5] Batch 11500/14335 Train_loss 1.9271854223318592 
Epoch [0/5] Batch 11600/14335 Train_loss 1.9274870108059383 
Epoch [0/5] Batch 11700/14335 Train_loss 1.928260163989457 
Epoch [0/5] Batch 11800/14335 Train_loss 1.928480001561531 
Epoch [0/5] Batch 11900/14335 Train_loss 1.9292861345925958 
Epoch [0/5] Batch 12000/14335 Train_loss 1.9293493411968812 
Epoch [0/5] Batch 12100/14335 Train_loss 1.929246070337989 
Epoch [0/5] Batch 12200/14335 Train_loss 1.9298303047781762 
Epoch [0/5] Batch 12300/14335 Train_loss 1.9299262805073623 
Epoch [0/5] Batch 12400/14335 Train_loss 1.9295550675718893 
Epoch [0/5] Batch 12500/14335 Train_loss 1.9296554777776898 
Epoch [0/5] Batch 12600/14335 Train_loss 1.930039452654806 
Epoch [0/5] Batch 12700/14335 Train_loss 1.9301218510732323 
Epoch [0/5] Batch 12800/14335 Train_loss 1.9296092404994487 
Epoch [0/5] Batch 12900/14335 Train_loss 1.9294845991823601 
Epoch [0/5] Batch 13000/14335 Train_loss 1.9299668706446351 
Epoch [0/5] Batch 13100/14335 Train_loss 1.929856866334251 
Epoch [0/5] Batch 13200/14335 Train_loss 1.9298340807382506 
Epoch [0/5] Batch 13300/14335 Train_loss 1.9302873461531138 
Epoch [0/5] Batch 13400/14335 Train_loss 1.9300602297290619 
Epoch [0/5] Batch 13500/14335 Train_loss 1.9300206395789223 
Epoch [0/5] Batch 13600/14335 Train_loss 1.929896251539449 
Epoch [0/5] Batch 13700/14335 Train_loss 1.9301235273020363 
Epoch [0/5] Batch 13800/14335 Train_loss 1.9306842033698606 
Epoch [0/5] Batch 13900/14335 Train_loss 1.930676872817426 
Epoch [0/5] Batch 14000/14335 Train_loss 1.9305393912797995 
Epoch [0/5] Batch 14100/14335 Train_loss 1.9307473081503344 
Epoch [0/5] Batch 14200/14335 Train_loss 1.930143545588241 
Epoch [0/5] Batch 14300/14335 Train_loss 1.9296408527010462 
Epoch: 0/5 	Training Loss: 1.929901 	Validation Loss: 1.881731 Duration seconds: 4288.445266723633 
Validation loss decreased (inf --> 1.881731).  Saving model ... 
best_valid_loss_fold [1.881730613652118] Best_Epoch [0]Epoch [1/5] Batch 0/14335 Train_loss 1.442733258008957 
Epoch [1/5] Batch 100/14335 Train_loss 1.8627971086171593 
Epoch [1/5] Batch 200/14335 Train_loss 1.8973104915215602 
Epoch [1/5] Batch 300/14335 Train_loss 1.896579077721038 
Epoch [1/5] Batch 400/14335 Train_loss 1.8835499826958055 
Epoch [1/5] Batch 500/14335 Train_loss 1.8887373510591998 
Epoch [1/5] Batch 600/14335 Train_loss 1.8868269091983405 
Epoch [1/5] Batch 700/14335 Train_loss 1.885517841037602 
Epoch [1/5] Batch 800/14335 Train_loss 1.88495111069206 
Epoch [1/5] Batch 900/14335 Train_loss 1.881078421060703 
Epoch [1/5] Batch 1000/14335 Train_loss 1.879314665089954 
Epoch [1/5] Batch 1100/14335 Train_loss 1.8897735133943072 
Epoch [1/5] Batch 1200/14335 Train_loss 1.8891571473320954 
Epoch [1/5] Batch 1300/14335 Train_loss 1.8932279108878194 
Epoch [1/5] Batch 1400/14335 Train_loss 1.888178956324632 
Epoch [1/5] Batch 1500/14335 Train_loss 1.8895940112569267 
Epoch [1/5] Batch 1600/14335 Train_loss 1.8834887174825456 
Epoch [1/5] Batch 1700/14335 Train_loss 1.8875551681696212 
Epoch [1/5] Batch 1800/14335 Train_loss 1.8916046886039337 
Epoch [1/5] Batch 1900/14335 Train_loss 1.9019549715282227 
Epoch [1/5] Batch 2000/14335 Train_loss 1.9003140155797538 
Epoch [1/5] Batch 2100/14335 Train_loss 1.9015044840792994 
Epoch [1/5] Batch 2200/14335 Train_loss 1.903991503848346 
Epoch [1/5] Batch 2300/14335 Train_loss 1.9045070116317102 
Epoch [1/5] Batch 2400/14335 Train_loss 1.9088905381472445 
Epoch [1/5] Batch 2500/14335 Train_loss 1.9081158518809074 
Epoch [1/5] Batch 2600/14335 Train_loss 1.9085208804807448 
Epoch [1/5] Batch 2700/14335 Train_loss 1.9095852049615858 
Epoch [1/5] Batch 2800/14335 Train_loss 1.9107681970480763 
Epoch [1/5] Batch 2900/14335 Train_loss 1.9109176611030196 
Epoch [1/5] Batch 3000/14335 Train_loss 1.912119264060539 
Epoch [1/5] Batch 3100/14335 Train_loss 1.9125971596078963 
Epoch [1/5] Batch 3200/14335 Train_loss 1.9133492491112878 
Epoch [1/5] Batch 3300/14335 Train_loss 1.9117732360615978 
Epoch [1/5] Batch 3400/14335 Train_loss 1.9148146876694525 
Epoch [1/5] Batch 3500/14335 Train_loss 1.9158661144502809 
Epoch [1/5] Batch 3600/14335 Train_loss 1.9179406891334094 
Epoch [1/5] Batch 3700/14335 Train_loss 1.9180646836375166 
Epoch [1/5] Batch 3800/14335 Train_loss 1.9161222838757226 
Epoch [1/5] Batch 3900/14335 Train_loss 1.9141519909366007 
Epoch [1/5] Batch 4000/14335 Train_loss 1.9132739150283546 
Epoch [1/5] Batch 4100/14335 Train_loss 1.912142142473605 
Epoch [1/5] Batch 4200/14335 Train_loss 1.9107114603369186 
Epoch [1/5] Batch 4300/14335 Train_loss 1.9117484007951437 
Epoch [1/5] Batch 4400/14335 Train_loss 1.9116474236802903 
Epoch [1/5] Batch 4500/14335 Train_loss 1.912227543192992 
Epoch [1/5] Batch 4600/14335 Train_loss 1.91164269033715 
Epoch [1/5] Batch 4700/14335 Train_loss 1.9115436657426383 
Epoch [1/5] Batch 4800/14335 Train_loss 1.9104881854283637 
Epoch [1/5] Batch 4900/14335 Train_loss 1.9122361217946016 
Epoch [1/5] Batch 5000/14335 Train_loss 1.9116412341621514 
Epoch [1/5] Batch 5100/14335 Train_loss 1.9086466438175884 
Epoch [1/5] Batch 5200/14335 Train_loss 1.9087435652578342 
Epoch [1/5] Batch 5300/14335 Train_loss 1.9079626911056085 
Epoch [1/5] Batch 5400/14335 Train_loss 1.906782734254194 
Epoch [1/5] Batch 5500/14335 Train_loss 1.9054938311092833 
Epoch [1/5] Batch 5600/14335 Train_loss 1.9047399040612871 
Epoch [1/5] Batch 5700/14335 Train_loss 1.9048228679485246 
Epoch [1/5] Batch 5800/14335 Train_loss 1.9044883687218044 
Epoch [1/5] Batch 5900/14335 Train_loss 1.9045873333972565 
Epoch [1/5] Batch 6000/14335 Train_loss 1.9052446299660724 
Epoch [1/5] Batch 6100/14335 Train_loss 1.9053624314221667 
Epoch [1/5] Batch 6200/14335 Train_loss 1.9049927205330344 
Epoch [1/5] Batch 6300/14335 Train_loss 1.904269600453509 
Epoch [1/5] Batch 6400/14335 Train_loss 1.9043622508998905 
Epoch [1/5] Batch 6500/14335 Train_loss 1.9050358598852704 
Epoch [1/5] Batch 6600/14335 Train_loss 1.9039084480215052 
Epoch [1/5] Batch 6700/14335 Train_loss 1.904230109531165 
Epoch [1/5] Batch 6800/14335 Train_loss 1.9050359134868373 
Epoch [1/5] Batch 6900/14335 Train_loss 1.9043819129698052 
Epoch [1/5] Batch 7000/14335 Train_loss 1.9035760040354122 
Epoch [1/5] Batch 7100/14335 Train_loss 1.9038960396762952 
Epoch [1/5] Batch 7200/14335 Train_loss 1.9033991956043252 
Epoch [1/5] Batch 7300/14335 Train_loss 1.903547556582803 
Epoch [1/5] Batch 7400/14335 Train_loss 1.9037089417170727 
Epoch [1/5] Batch 7500/14335 Train_loss 1.9045231930803275 
Epoch [1/5] Batch 7600/14335 Train_loss 1.9057765915017506 
Epoch [1/5] Batch 7700/14335 Train_loss 1.9059486041630866 
Epoch [1/5] Batch 7800/14335 Train_loss 1.9052998555463379 
Epoch [1/5] Batch 7900/14335 Train_loss 1.9050451021496744 
Epoch [1/5] Batch 8000/14335 Train_loss 1.9048851797022666 
Epoch [1/5] Batch 8100/14335 Train_loss 1.9038852876510506 
Epoch [1/5] Batch 8200/14335 Train_loss 1.9042635367588872 
Epoch [1/5] Batch 8300/14335 Train_loss 1.9036638793136007 
Epoch [1/5] Batch 8400/14335 Train_loss 1.9036170189346378 
Epoch [1/5] Batch 8500/14335 Train_loss 1.9047768732298194 
Epoch [1/5] Batch 8600/14335 Train_loss 1.904063745462545 
Epoch [1/5] Batch 8700/14335 Train_loss 1.9058804540803838 
Epoch [1/5] Batch 8800/14335 Train_loss 1.9052744162875392 
Epoch [1/5] Batch 8900/14335 Train_loss 1.9048727266662056 
Epoch [1/5] Batch 9000/14335 Train_loss 1.9039683635053257 
Epoch [1/5] Batch 9100/14335 Train_loss 1.9040499130011574 
Epoch [1/5] Batch 9200/14335 Train_loss 1.904618726299711 
Epoch [1/5] Batch 9300/14335 Train_loss 1.9040312440103644 
Epoch [1/5] Batch 9400/14335 Train_loss 1.9035689444785904 
Epoch [1/5] Batch 9500/14335 Train_loss 1.9035377398755924 
Epoch [1/5] Batch 9600/14335 Train_loss 1.903735957578028 
Epoch [1/5] Batch 9700/14335 Train_loss 1.9036614569763266 
Epoch [1/5] Batch 9800/14335 Train_loss 1.9034884131455856 
Epoch [1/5] Batch 9900/14335 Train_loss 1.9036053804442348 
Epoch [1/5] Batch 10000/14335 Train_loss 1.9029569217826996 
Epoch [1/5] Batch 10100/14335 Train_loss 1.9026451576388645 
Epoch [1/5] Batch 10200/14335 Train_loss 1.902562452400038 
Epoch [1/5] Batch 10300/14335 Train_loss 1.9019914096885486 
Epoch [1/5] Batch 10400/14335 Train_loss 1.9013117468250496 
Epoch [1/5] Batch 10500/14335 Train_loss 1.9016905453415465 
Epoch [1/5] Batch 10600/14335 Train_loss 1.9016608862567765 
Epoch [1/5] Batch 10700/14335 Train_loss 1.9022833704099 
Epoch [1/5] Batch 10800/14335 Train_loss 1.9021605815037943 
Epoch [1/5] Batch 10900/14335 Train_loss 1.9023012424070849 
Epoch [1/5] Batch 11000/14335 Train_loss 1.901734173866784 
Epoch [1/5] Batch 11100/14335 Train_loss 1.902387444513487 
Epoch [1/5] Batch 11200/14335 Train_loss 1.9026224198828061 
Epoch [1/5] Batch 11300/14335 Train_loss 1.9028696952950226 
Epoch [1/5] Batch 11400/14335 Train_loss 1.9031565425903292 
Epoch [1/5] Batch 11500/14335 Train_loss 1.9030070234258198 
Epoch [1/5] Batch 11600/14335 Train_loss 1.9025564126547694 
Epoch [1/5] Batch 11700/14335 Train_loss 1.9022127426826447 
Epoch [1/5] Batch 11800/14335 Train_loss 1.9031427041076219 
Epoch [1/5] Batch 11900/14335 Train_loss 1.903039244478685 
Epoch [1/5] Batch 12000/14335 Train_loss 1.902852825228795 
Epoch [1/5] Batch 12100/14335 Train_loss 1.9029957965864799 
Epoch [1/5] Batch 12200/14335 Train_loss 1.9025728630500294 
Epoch [1/5] Batch 12300/14335 Train_loss 1.902000839510746 
Epoch [1/5] Batch 12400/14335 Train_loss 1.9013572777087107 
Epoch [1/5] Batch 12500/14335 Train_loss 1.901535522927285 
Epoch [1/5] Batch 12600/14335 Train_loss 1.9014749105118938 
Epoch [1/5] Batch 12700/14335 Train_loss 1.9016676844363043 
Epoch [1/5] Batch 12800/14335 Train_loss 1.9014643749232198 
Epoch [1/5] Batch 12900/14335 Train_loss 1.9013527805720103 
Epoch [1/5] Batch 13000/14335 Train_loss 1.9009973874973083 
Epoch [1/5] Batch 13100/14335 Train_loss 1.9005643045897247 
Epoch [1/5] Batch 13200/14335 Train_loss 1.8999477513216316 
Epoch [1/5] Batch 13300/14335 Train_loss 1.8995122826873077 
Epoch [1/5] Batch 13400/14335 Train_loss 1.8993825325308011 
Epoch [1/5] Batch 13500/14335 Train_loss 1.8995060951304599 
Epoch [1/5] Batch 13600/14335 Train_loss 1.8994932872635653 
Epoch [1/5] Batch 13700/14335 Train_loss 1.8991673279315195 
Epoch [1/5] Batch 13800/14335 Train_loss 1.8987215668611936 
Epoch [1/5] Batch 13900/14335 Train_loss 1.8986574866740011 
Epoch [1/5] Batch 14000/14335 Train_loss 1.899017905420652 
Epoch [1/5] Batch 14100/14335 Train_loss 1.8984683241218838 
Epoch [1/5] Batch 14200/14335 Train_loss 1.8980363386801016 
Epoch [1/5] Batch 14300/14335 Train_loss 1.89792050178043 
Epoch: 1/5 	Training Loss: 1.897749 	Validation Loss: 1.837026 Duration seconds: 3909.8105032444 
Validation loss decreased (1.881731 --> 1.837026).  Saving model ... 
best_valid_loss_fold [1.837025858191607] Best_Epoch [1]Epoch [2/5] Batch 0/14335 Train_loss 1.61685511469841 
Epoch [2/5] Batch 100/14335 Train_loss 1.8850391704847318 
Epoch [2/5] Batch 200/14335 Train_loss 1.9724600928932874 
Epoch [2/5] Batch 300/14335 Train_loss 1.9570310111853768 
Epoch [2/5] Batch 400/14335 Train_loss 1.952250773769959 
Epoch [2/5] Batch 500/14335 Train_loss 1.930826610463584 
Epoch [2/5] Batch 600/14335 Train_loss 1.9392720802056413 
Epoch [2/5] Batch 700/14335 Train_loss 1.930359650759316 
Epoch [2/5] Batch 800/14335 Train_loss 1.9094431963045797 
Epoch [2/5] Batch 900/14335 Train_loss 1.9050279015739273 
Epoch [2/5] Batch 1000/14335 Train_loss 1.9005134479923325 
Epoch [2/5] Batch 1100/14335 Train_loss 1.8958491505166815 
Epoch [2/5] Batch 1200/14335 Train_loss 1.8908745631712065 
Epoch [2/5] Batch 1300/14335 Train_loss 1.8865942565021288 
Epoch [2/5] Batch 1400/14335 Train_loss 1.890050924670943 
Epoch [2/5] Batch 1500/14335 Train_loss 1.894401570286932 
Epoch [2/5] Batch 1600/14335 Train_loss 1.8972182871400378 
Epoch [2/5] Batch 1700/14335 Train_loss 1.893672968169509 
Epoch [2/5] Batch 1800/14335 Train_loss 1.8959545777249112 
Epoch [2/5] Batch 1900/14335 Train_loss 1.8989959408552128 
Epoch [2/5] Batch 2000/14335 Train_loss 1.8990931435041818 
Epoch [2/5] Batch 2100/14335 Train_loss 1.8956408158533349 
Epoch [2/5] Batch 2200/14335 Train_loss 1.8928290385311162 
Epoch [2/5] Batch 2300/14335 Train_loss 1.8935853714970907 
Epoch [2/5] Batch 2400/14335 Train_loss 1.8951552927258213 
Epoch [2/5] Batch 2500/14335 Train_loss 1.8934011606068337 
Epoch [2/5] Batch 2600/14335 Train_loss 1.8900640244835252 
Epoch [2/5] Batch 2700/14335 Train_loss 1.8884448410983838 
Epoch [2/5] Batch 2800/14335 Train_loss 1.8865926944780715 
Epoch [2/5] Batch 2900/14335 Train_loss 1.8849712531783793 
Epoch [2/5] Batch 3000/14335 Train_loss 1.8834913202854087 
Epoch [2/5] Batch 3100/14335 Train_loss 1.885191500871672 
Epoch [2/5] Batch 3200/14335 Train_loss 1.8860403463123403 
Epoch [2/5] Batch 3300/14335 Train_loss 1.884997791715894 
Epoch [2/5] Batch 3400/14335 Train_loss 1.8869723410829486 
Epoch [2/5] Batch 3500/14335 Train_loss 1.886264470460942 
Epoch [2/5] Batch 3600/14335 Train_loss 1.8855355980722515 
Epoch [2/5] Batch 3700/14335 Train_loss 1.884379337831901 
Epoch [2/5] Batch 3800/14335 Train_loss 1.8854262336296679 
Epoch [2/5] Batch 3900/14335 Train_loss 1.8854898693442528 
Epoch [2/5] Batch 4000/14335 Train_loss 1.8837777312991173 
Epoch [2/5] Batch 4100/14335 Train_loss 1.8813756419406145 
Epoch [2/5] Batch 4200/14335 Train_loss 1.8821726956929488 
Epoch [2/5] Batch 4300/14335 Train_loss 1.8822743410105567 
Epoch [2/5] Batch 4400/14335 Train_loss 1.8813360369789873 
Epoch [2/5] Batch 4500/14335 Train_loss 1.8800768747402679 
Epoch [2/5] Batch 4600/14335 Train_loss 1.880842195028288 
Epoch [2/5] Batch 4700/14335 Train_loss 1.8816218010001906 
Epoch [2/5] Batch 4800/14335 Train_loss 1.8823054246410458 
Epoch [2/5] Batch 4900/14335 Train_loss 1.883913462533498 
Epoch [2/5] Batch 5000/14335 Train_loss 1.8843075276461037 
Epoch [2/5] Batch 5100/14335 Train_loss 1.883585447914003 
Epoch [2/5] Batch 5200/14335 Train_loss 1.883959325911093 
Epoch [2/5] Batch 5300/14335 Train_loss 1.8833852889691967 
Epoch [2/5] Batch 5400/14335 Train_loss 1.8838685284489571 
Epoch [2/5] Batch 5500/14335 Train_loss 1.8827341403016458 
Epoch [2/5] Batch 5600/14335 Train_loss 1.8804478538308245 
Epoch [2/5] Batch 5700/14335 Train_loss 1.8801830420745944 
Epoch [2/5] Batch 5800/14335 Train_loss 1.8810356388899545 
Epoch [2/5] Batch 5900/14335 Train_loss 1.8816531846832267 
Epoch [2/5] Batch 6000/14335 Train_loss 1.8815673219834321 
Epoch [2/5] Batch 6100/14335 Train_loss 1.882039230506775 
Epoch [2/5] Batch 6200/14335 Train_loss 1.8813850085385153 
Epoch [2/5] Batch 6300/14335 Train_loss 1.8811353432199933 
Epoch [2/5] Batch 6400/14335 Train_loss 1.881072765672799 
Epoch [2/5] Batch 6500/14335 Train_loss 1.8809304412335748 
Epoch [2/5] Batch 6600/14335 Train_loss 1.881261857455336 
Epoch [2/5] Batch 6700/14335 Train_loss 1.8820387951628323 
Epoch [2/5] Batch 6800/14335 Train_loss 1.8815928676606994 
Epoch [2/5] Batch 6900/14335 Train_loss 1.8826015149196618 
Epoch [2/5] Batch 7000/14335 Train_loss 1.8834494695348358 
Epoch [2/5] Batch 7100/14335 Train_loss 1.882760024671109 
Epoch [2/5] Batch 7200/14335 Train_loss 1.8812708697572647 
Epoch [2/5] Batch 7300/14335 Train_loss 1.8819924530497545 
Epoch [2/5] Batch 7400/14335 Train_loss 1.8817155257042575 
Epoch [2/5] Batch 7500/14335 Train_loss 1.8816473233415323 
Epoch [2/5] Batch 7600/14335 Train_loss 1.8811584939405082 
Epoch [2/5] Batch 7700/14335 Train_loss 1.880317109929263 
Epoch [2/5] Batch 7800/14335 Train_loss 1.8800617642906015 
Epoch [2/5] Batch 7900/14335 Train_loss 1.8789357117060965 
Epoch [2/5] Batch 8000/14335 Train_loss 1.878782332589769 
Epoch [2/5] Batch 8100/14335 Train_loss 1.87856925438288 
Epoch [2/5] Batch 8200/14335 Train_loss 1.8780089372517117 
Epoch [2/5] Batch 8300/14335 Train_loss 1.877563636412952 
Epoch [2/5] Batch 8400/14335 Train_loss 1.8779852879468124 
Epoch [2/5] Batch 8500/14335 Train_loss 1.8769004557765088 
Epoch [2/5] Batch 8600/14335 Train_loss 1.8772415752378526 
Epoch [2/5] Batch 8700/14335 Train_loss 1.8762983446098405 
Epoch [2/5] Batch 8800/14335 Train_loss 1.8766696072387676 
Epoch [2/5] Batch 8900/14335 Train_loss 1.8768026150529498 
Epoch [2/5] Batch 9000/14335 Train_loss 1.8773987183591323 
Epoch [2/5] Batch 9100/14335 Train_loss 1.8776823877232205 
Epoch [2/5] Batch 9200/14335 Train_loss 1.8772699869703553 
Epoch [2/5] Batch 9300/14335 Train_loss 1.8771974049783333 
Epoch [2/5] Batch 9400/14335 Train_loss 1.8771350821116581 
Epoch [2/5] Batch 9500/14335 Train_loss 1.8769568460329358 
Epoch [2/5] Batch 9600/14335 Train_loss 1.8776858753547323 
Epoch [2/5] Batch 9700/14335 Train_loss 1.877295333293434 
Epoch [2/5] Batch 9800/14335 Train_loss 1.8776242500620526 
Epoch [2/5] Batch 9900/14335 Train_loss 1.8778643004596987 
Epoch [2/5] Batch 10000/14335 Train_loss 1.8773538388856446 
Epoch [2/5] Batch 10100/14335 Train_loss 1.8772344969219648 
Epoch [2/5] Batch 10200/14335 Train_loss 1.8777082790864845 
Epoch [2/5] Batch 10300/14335 Train_loss 1.87777796587155 
Epoch [2/5] Batch 10400/14335 Train_loss 1.8768255258566966 
Epoch [2/5] Batch 10500/14335 Train_loss 1.8768813889042648 
Epoch [2/5] Batch 10600/14335 Train_loss 1.876836544024518 
Epoch [2/5] Batch 10700/14335 Train_loss 1.8764745590898682 
Epoch [2/5] Batch 10800/14335 Train_loss 1.8769677311289632 
Epoch [2/5] Batch 10900/14335 Train_loss 1.876881198249993 
Epoch [2/5] Batch 11000/14335 Train_loss 1.8761483550480784 
Epoch [2/5] Batch 11100/14335 Train_loss 1.8758830295300315 
Epoch [2/5] Batch 11200/14335 Train_loss 1.8752009836720225 
Epoch [2/5] Batch 11300/14335 Train_loss 1.8758113600914272 
Epoch [2/5] Batch 11400/14335 Train_loss 1.8759039625735903 
Epoch [2/5] Batch 11500/14335 Train_loss 1.8757888481232117 
Epoch [2/5] Batch 11600/14335 Train_loss 1.8759377337603638 
Epoch [2/5] Batch 11700/14335 Train_loss 1.8759253509033849 
Epoch [2/5] Batch 11800/14335 Train_loss 1.8750670937630758 
Epoch [2/5] Batch 11900/14335 Train_loss 1.874158307202533 
Epoch [2/5] Batch 12000/14335 Train_loss 1.874584980081165 
Epoch [2/5] Batch 12100/14335 Train_loss 1.8748435811527149 
Epoch [2/5] Batch 12200/14335 Train_loss 1.8746923534056856 
Epoch [2/5] Batch 12300/14335 Train_loss 1.8738629057750247 
Epoch [2/5] Batch 12400/14335 Train_loss 1.8738931262457565 
Epoch [2/5] Batch 12500/14335 Train_loss 1.873959774355127 
Epoch [2/5] Batch 12600/14335 Train_loss 1.8732931201677552 
Epoch [2/5] Batch 12700/14335 Train_loss 1.8727234424447583 
Epoch [2/5] Batch 12800/14335 Train_loss 1.8724649298420157 
Epoch [2/5] Batch 12900/14335 Train_loss 1.8723583859305966 
Epoch [2/5] Batch 13000/14335 Train_loss 1.8720729230605733 
Epoch [2/5] Batch 13100/14335 Train_loss 1.872210110202244 
Epoch [2/5] Batch 13200/14335 Train_loss 1.8724418131205793 
Epoch [2/5] Batch 13300/14335 Train_loss 1.8729049512669338 
Epoch [2/5] Batch 13400/14335 Train_loss 1.8728214286117089 
Epoch [2/5] Batch 13500/14335 Train_loss 1.8727954857271563 
Epoch [2/5] Batch 13600/14335 Train_loss 1.8721164189896446 
Epoch [2/5] Batch 13700/14335 Train_loss 1.871930594717066 
Epoch [2/5] Batch 13800/14335 Train_loss 1.871999948242399 
Epoch [2/5] Batch 13900/14335 Train_loss 1.8717624757455782 
Epoch [2/5] Batch 14000/14335 Train_loss 1.8718167676995945 
Epoch [2/5] Batch 14100/14335 Train_loss 1.8723222673754052 
Epoch [2/5] Batch 14200/14335 Train_loss 1.8717808204091617 
Epoch [2/5] Batch 14300/14335 Train_loss 1.87152293368181 
Epoch: 2/5 	Training Loss: 1.871191 	Validation Loss: 1.844318 Duration seconds: 3914.949384212494 
best_valid_loss_fold [1.837025858191607] Best_Epoch [2]Epoch [3/5] Batch 0/14335 Train_loss 1.0205788910388947 
Epoch [3/5] Batch 100/14335 Train_loss 1.8407422263580975 
Epoch [3/5] Batch 200/14335 Train_loss 1.8499546488793335 
Epoch [3/5] Batch 300/14335 Train_loss 1.838934330325388 
Epoch [3/5] Batch 400/14335 Train_loss 1.8440197728704335 
Epoch [3/5] Batch 500/14335 Train_loss 1.8450650249323446 
Epoch [3/5] Batch 600/14335 Train_loss 1.85692132033792 
Epoch [3/5] Batch 700/14335 Train_loss 1.8569933518384731 
Epoch [3/5] Batch 800/14335 Train_loss 1.8568957600272848 
Epoch [3/5] Batch 900/14335 Train_loss 1.8549633759190716 
Epoch [3/5] Batch 1000/14335 Train_loss 1.8439874358542196 
Epoch [3/5] Batch 1100/14335 Train_loss 1.8411241419322375 
Epoch [3/5] Batch 1200/14335 Train_loss 1.841423381073439 
Epoch [3/5] Batch 1300/14335 Train_loss 1.8422351797883736 
Epoch [3/5] Batch 1400/14335 Train_loss 1.8409455600304319 
Epoch [3/5] Batch 1500/14335 Train_loss 1.8416719247576476 
Epoch [3/5] Batch 1600/14335 Train_loss 1.8429886256295172 
Epoch [3/5] Batch 1700/14335 Train_loss 1.8426072909149054 
Epoch [3/5] Batch 1800/14335 Train_loss 1.8486582743275966 
Epoch [3/5] Batch 1900/14335 Train_loss 1.8495099087574494 
Epoch [3/5] Batch 2000/14335 Train_loss 1.8477215617708955 
Epoch [3/5] Batch 2100/14335 Train_loss 1.8479902586096926 
Epoch [3/5] Batch 2200/14335 Train_loss 1.8527375113918043 
Epoch [3/5] Batch 2300/14335 Train_loss 1.8549738410230514 
Epoch [3/5] Batch 2400/14335 Train_loss 1.8524804142230453 
Epoch [3/5] Batch 2500/14335 Train_loss 1.8516293923552634 
Epoch [3/5] Batch 2600/14335 Train_loss 1.8498933473254615 
Epoch [3/5] Batch 2700/14335 Train_loss 1.850372244573244 
Epoch [3/5] Batch 2800/14335 Train_loss 1.8487632394725406 
Epoch [3/5] Batch 2900/14335 Train_loss 1.8469304910782944 
Epoch [3/5] Batch 3000/14335 Train_loss 1.8469467356066154 
Epoch [3/5] Batch 3100/14335 Train_loss 1.847334673957973 
Epoch [3/5] Batch 3200/14335 Train_loss 1.8446269000262738 
Epoch [3/5] Batch 3300/14335 Train_loss 1.8439468087205848 
Epoch [3/5] Batch 3400/14335 Train_loss 1.8429574147261125 
Epoch [3/5] Batch 3500/14335 Train_loss 1.8409972778241894 
Epoch [3/5] Batch 3600/14335 Train_loss 1.8414475287651393 
Epoch [3/5] Batch 3700/14335 Train_loss 1.8412213330352123 
Epoch [3/5] Batch 3800/14335 Train_loss 1.8416306929909314 
Epoch [3/5] Batch 3900/14335 Train_loss 1.8415149601433742 
Epoch [3/5] Batch 4000/14335 Train_loss 1.842227585379093 
Epoch [3/5] Batch 4100/14335 Train_loss 1.8442514592632233 
Epoch [3/5] Batch 4200/14335 Train_loss 1.8461638445092705 
Epoch [3/5] Batch 4300/14335 Train_loss 1.8440219473680128 
Epoch [3/5] Batch 4400/14335 Train_loss 1.8423297320647256 
Epoch [3/5] Batch 4500/14335 Train_loss 1.8437699948505173 
Epoch [3/5] Batch 4600/14335 Train_loss 1.843128423693322 
Epoch [3/5] Batch 4700/14335 Train_loss 1.843723175103006 
Epoch [3/5] Batch 4800/14335 Train_loss 1.8429955245042016 
Epoch [3/5] Batch 4900/14335 Train_loss 1.841568852881404 
Epoch [3/5] Batch 5000/14335 Train_loss 1.8400501683831119 
Epoch [3/5] Batch 5100/14335 Train_loss 1.8412330025619699 
Epoch [3/5] Batch 5200/14335 Train_loss 1.8442981376659524 
Epoch [3/5] Batch 5300/14335 Train_loss 1.845281402046524 
Epoch [3/5] Batch 5400/14335 Train_loss 1.8466545452640202 
Epoch [3/5] Batch 5500/14335 Train_loss 1.8453486536055062 
Epoch [3/5] Batch 5600/14335 Train_loss 1.8467561396261536 
Epoch [3/5] Batch 5700/14335 Train_loss 1.8466314920099278 
Epoch [3/5] Batch 5800/14335 Train_loss 1.8468565138375075 
Epoch [3/5] Batch 5900/14335 Train_loss 1.8475307824386518 
Epoch [3/5] Batch 6000/14335 Train_loss 1.8481149846572138 
Epoch [3/5] Batch 6100/14335 Train_loss 1.8477711045662413 
Epoch [3/5] Batch 6200/14335 Train_loss 1.8472575293509945 
Epoch [3/5] Batch 6300/14335 Train_loss 1.846451761188904 
Epoch [3/5] Batch 6400/14335 Train_loss 1.8459952110679256 
Epoch [3/5] Batch 6500/14335 Train_loss 1.846273125124526 
Epoch [3/5] Batch 6600/14335 Train_loss 1.8458388942461577 
Epoch [3/5] Batch 6700/14335 Train_loss 1.8468792105938334 
Epoch [3/5] Batch 6800/14335 Train_loss 1.8452828287160268 
Epoch [3/5] Batch 6900/14335 Train_loss 1.8457198811463127 
Epoch [3/5] Batch 7000/14335 Train_loss 1.845870690691379 
Epoch [3/5] Batch 7100/14335 Train_loss 1.845773103185404 
Epoch [3/5] Batch 7200/14335 Train_loss 1.847029687191915 
Epoch [3/5] Batch 7300/14335 Train_loss 1.847171569966344 
Epoch [3/5] Batch 7400/14335 Train_loss 1.847458865970208 
Epoch [3/5] Batch 7500/14335 Train_loss 1.8477300306343345 
Epoch [3/5] Batch 7600/14335 Train_loss 1.8471541945437682 
Epoch [3/5] Batch 7700/14335 Train_loss 1.8480960699929043 
Epoch [3/5] Batch 7800/14335 Train_loss 1.8489412198896409 
Epoch [3/5] Batch 7900/14335 Train_loss 1.8479509697348886 
Epoch [3/5] Batch 8000/14335 Train_loss 1.8484869018316255 
Epoch [3/5] Batch 8100/14335 Train_loss 1.8468882233767123 
Epoch [3/5] Batch 8200/14335 Train_loss 1.846985493308196 
Epoch [3/5] Batch 8300/14335 Train_loss 1.8466585955741088 
Epoch [3/5] Batch 8400/14335 Train_loss 1.8454373042878403 
Epoch [3/5] Batch 8500/14335 Train_loss 1.8451629218238619 
Epoch [3/5] Batch 8600/14335 Train_loss 1.8450067652119355 
Epoch [3/5] Batch 8700/14335 Train_loss 1.843757897516103 
Epoch [3/5] Batch 8800/14335 Train_loss 1.8438964108962415 
Epoch [3/5] Batch 8900/14335 Train_loss 1.8433399981021907 
Epoch [3/5] Batch 9000/14335 Train_loss 1.8432984328744424 
Epoch [3/5] Batch 9100/14335 Train_loss 1.8435426229244076 
Epoch [3/5] Batch 9200/14335 Train_loss 1.8437187549477037 
Epoch [3/5] Batch 9300/14335 Train_loss 1.8436986274409264 
Epoch [3/5] Batch 9400/14335 Train_loss 1.8431317462959247 
Epoch [3/5] Batch 9500/14335 Train_loss 1.8424922179906333 
Epoch [3/5] Batch 9600/14335 Train_loss 1.842436687895692 
Epoch [3/5] Batch 9700/14335 Train_loss 1.8414271823925932 
Epoch [3/5] Batch 9800/14335 Train_loss 1.8411935798716648 
Epoch [3/5] Batch 9900/14335 Train_loss 1.8400835631169365 
Epoch [3/5] Batch 10000/14335 Train_loss 1.8403774342291916 
Epoch [3/5] Batch 10100/14335 Train_loss 1.841087915127218 
Epoch [3/5] Batch 10200/14335 Train_loss 1.8417418504449892 
Epoch [3/5] Batch 10300/14335 Train_loss 1.8427525528094257 
Epoch [3/5] Batch 10400/14335 Train_loss 1.8431710759972038 
Epoch [3/5] Batch 10500/14335 Train_loss 1.8435313740390253 
Epoch [3/5] Batch 10600/14335 Train_loss 1.84284128679168 
Epoch [3/5] Batch 10700/14335 Train_loss 1.8422980376270963 
Epoch [3/5] Batch 10800/14335 Train_loss 1.8427414514014715 
Epoch [3/5] Batch 10900/14335 Train_loss 1.842407699940582 
Epoch [3/5] Batch 11000/14335 Train_loss 1.8424842751240982 
Epoch [3/5] Batch 11100/14335 Train_loss 1.8415337509929774 
Epoch [3/5] Batch 11200/14335 Train_loss 1.8420903211242172 
Epoch [3/5] Batch 11300/14335 Train_loss 1.8420004257671063 
Epoch [3/5] Batch 11400/14335 Train_loss 1.8419027697164576 
Epoch [3/5] Batch 11500/14335 Train_loss 1.8418403994526855 
Epoch [3/5] Batch 11600/14335 Train_loss 1.8417774771671185 
Epoch [3/5] Batch 11700/14335 Train_loss 1.8414769861673648 
Epoch [3/5] Batch 11800/14335 Train_loss 1.8412888658923292 
Epoch [3/5] Batch 11900/14335 Train_loss 1.8405522384189597 
Epoch [3/5] Batch 12000/14335 Train_loss 1.8399136681902777 
Epoch [3/5] Batch 12100/14335 Train_loss 1.840409647481578 
Epoch [3/5] Batch 12200/14335 Train_loss 1.8406539916401075 
Epoch [3/5] Batch 12300/14335 Train_loss 1.840494903695311 
Epoch [3/5] Batch 12400/14335 Train_loss 1.8402279752710156 
Epoch [3/5] Batch 12500/14335 Train_loss 1.8401342987806815 
Epoch [3/5] Batch 12600/14335 Train_loss 1.8400666428025247 
Epoch [3/5] Batch 12700/14335 Train_loss 1.840307808783043 
Epoch [3/5] Batch 12800/14335 Train_loss 1.8408362309177557 
Epoch [3/5] Batch 12900/14335 Train_loss 1.8407860552779038 
Epoch [3/5] Batch 13000/14335 Train_loss 1.8407356026823471 
Epoch [3/5] Batch 13100/14335 Train_loss 1.8411845939799616 
Epoch [3/5] Batch 13200/14335 Train_loss 1.8415578050569517 
Epoch [3/5] Batch 13300/14335 Train_loss 1.8419746070782068 
Epoch [3/5] Batch 13400/14335 Train_loss 1.8428377193458472 
Epoch [3/5] Batch 13500/14335 Train_loss 1.8429658466694965 
Epoch [3/5] Batch 13600/14335 Train_loss 1.84310870420257 
Epoch [3/5] Batch 13700/14335 Train_loss 1.8428934155713554 
Epoch [3/5] Batch 13800/14335 Train_loss 1.8425468246042016 
Epoch [3/5] Batch 13900/14335 Train_loss 1.8421903109871631 
Epoch [3/5] Batch 14000/14335 Train_loss 1.8416369494571447 
Epoch [3/5] Batch 14100/14335 Train_loss 1.8413884647660295 
Epoch [3/5] Batch 14200/14335 Train_loss 1.8410208599395201 
Epoch [3/5] Batch 14300/14335 Train_loss 1.8415701178184307 
Epoch: 3/5 	Training Loss: 1.841400 	Validation Loss: 1.801328 Duration seconds: 4587.798720836639 
Validation loss decreased (1.837026 --> 1.801328).  Saving model ... 
best_valid_loss_fold [1.801327900231367] Best_Epoch [3]Epoch [4/5] Batch 0/14335 Train_loss 1.0486330837011337 
Epoch [4/5] Batch 100/14335 Train_loss 1.981738456109963 
Epoch [4/5] Batch 200/14335 Train_loss 1.9285947065893096 
Epoch [4/5] Batch 300/14335 Train_loss 1.890722967164461 
Epoch [4/5] Batch 400/14335 Train_loss 1.8802586121675082 
Epoch [4/5] Batch 500/14335 Train_loss 1.8668260875933185 
Epoch [4/5] Batch 600/14335 Train_loss 1.8726967118940814 
Epoch [4/5] Batch 700/14335 Train_loss 1.871994208549807 
Epoch [4/5] Batch 800/14335 Train_loss 1.8708733759457699 
Epoch [4/5] Batch 900/14335 Train_loss 1.8732742942894471 
Epoch [4/5] Batch 1000/14335 Train_loss 1.861393435836791 
Epoch [4/5] Batch 1100/14335 Train_loss 1.8592546407224697 
Epoch [4/5] Batch 1200/14335 Train_loss 1.8638740061199932 
Epoch [4/5] Batch 1300/14335 Train_loss 1.860989694706208 
Epoch [4/5] Batch 1400/14335 Train_loss 1.8621296410599748 
Epoch [4/5] Batch 1500/14335 Train_loss 1.8589041017735506 
Epoch [4/5] Batch 1600/14335 Train_loss 1.8574966874199312 
Epoch [4/5] Batch 1700/14335 Train_loss 1.862549641460338 
Epoch [4/5] Batch 1800/14335 Train_loss 1.8640861598188383 
Epoch [4/5] Batch 1900/14335 Train_loss 1.8624461291339258 
Epoch [4/5] Batch 2000/14335 Train_loss 1.8613789677024186 
Epoch [4/5] Batch 2100/14335 Train_loss 1.8575615175547115 
Epoch [4/5] Batch 2200/14335 Train_loss 1.857574200024934 
Epoch [4/5] Batch 2300/14335 Train_loss 1.8563215528938213 
Epoch [4/5] Batch 2400/14335 Train_loss 1.8554952320662552 
Epoch [4/5] Batch 2500/14335 Train_loss 1.8553106489031612 
Epoch [4/5] Batch 2600/14335 Train_loss 1.8530969182083077 
Epoch [4/5] Batch 2700/14335 Train_loss 1.8507719445823299 
Epoch [4/5] Batch 2800/14335 Train_loss 1.8488678827573257 
Epoch [4/5] Batch 2900/14335 Train_loss 1.846040056832841 
Epoch [4/5] Batch 3000/14335 Train_loss 1.8450881003891575 
Epoch [4/5] Batch 3100/14335 Train_loss 1.842175056267096 
Epoch [4/5] Batch 3200/14335 Train_loss 1.8408602634278992 
Epoch [4/5] Batch 3300/14335 Train_loss 1.839886381466058 
Epoch [4/5] Batch 3400/14335 Train_loss 1.8395789168825467 
Epoch [4/5] Batch 3500/14335 Train_loss 1.836177228900219 
Epoch [4/5] Batch 3600/14335 Train_loss 1.8368021472336782 
Epoch [4/5] Batch 3700/14335 Train_loss 1.8353719029035063 
Epoch [4/5] Batch 3800/14335 Train_loss 1.8340270892099249 
Epoch [4/5] Batch 3900/14335 Train_loss 1.833101790565477 
Epoch [4/5] Batch 4000/14335 Train_loss 1.8327056160031394 
Epoch [4/5] Batch 4100/14335 Train_loss 1.8329044615759469 
Epoch [4/5] Batch 4200/14335 Train_loss 1.83211865175362 
Epoch [4/5] Batch 4300/14335 Train_loss 1.8334449750324289 
Epoch [4/5] Batch 4400/14335 Train_loss 1.8334621331114656 
Epoch [4/5] Batch 4500/14335 Train_loss 1.83370752567564 
Epoch [4/5] Batch 4600/14335 Train_loss 1.8327565726894344 
Epoch [4/5] Batch 4700/14335 Train_loss 1.833317754895186 
Epoch [4/5] Batch 4800/14335 Train_loss 1.8323204952620562 
Epoch [4/5] Batch 4900/14335 Train_loss 1.8318140682177357 
Epoch [4/5] Batch 5000/14335 Train_loss 1.83221079978233 
Epoch [4/5] Batch 5100/14335 Train_loss 1.8325250516934994 
Epoch [4/5] Batch 5200/14335 Train_loss 1.832618160623469 
Epoch [4/5] Batch 5300/14335 Train_loss 1.8335626094302149 
Epoch [4/5] Batch 5400/14335 Train_loss 1.8326424242826198 
Epoch [4/5] Batch 5500/14335 Train_loss 1.8310875807636717 
Epoch [4/5] Batch 5600/14335 Train_loss 1.832898584003428 
Epoch [4/5] Batch 5700/14335 Train_loss 1.8310728935510772 
Epoch [4/5] Batch 5800/14335 Train_loss 1.8309861917605463 
Epoch [4/5] Batch 5900/14335 Train_loss 1.8330165243587178 
Epoch [4/5] Batch 6000/14335 Train_loss 1.8322099752598773 
Epoch [4/5] Batch 6100/14335 Train_loss 1.8316034643064072 
Epoch [4/5] Batch 6200/14335 Train_loss 1.8309577794406438 
Epoch [4/5] Batch 6300/14335 Train_loss 1.8299683509608844 
Epoch [4/5] Batch 6400/14335 Train_loss 1.831274227074926 
Epoch [4/5] Batch 6500/14335 Train_loss 1.831538942730614 
Epoch [4/5] Batch 6600/14335 Train_loss 1.8305425469321548 
Epoch [4/5] Batch 6700/14335 Train_loss 1.8310032387059352 
Epoch [4/5] Batch 6800/14335 Train_loss 1.8321761952371058 
Epoch [4/5] Batch 6900/14335 Train_loss 1.8315786248783654 
Epoch [4/5] Batch 7000/14335 Train_loss 1.8305465306008122 
Epoch [4/5] Batch 7100/14335 Train_loss 1.830269891725151 
Epoch [4/5] Batch 7200/14335 Train_loss 1.8300133045680522 
Epoch [4/5] Batch 7300/14335 Train_loss 1.8315025335827064 
Epoch [4/5] Batch 7400/14335 Train_loss 1.8304627395963977 
Epoch [4/5] Batch 7500/14335 Train_loss 1.8302922704218705 
Epoch [4/5] Batch 7600/14335 Train_loss 1.8309182075176125 
Epoch [4/5] Batch 7700/14335 Train_loss 1.8313364901201026 
Epoch [4/5] Batch 7800/14335 Train_loss 1.8304805152443888 
Epoch [4/5] Batch 7900/14335 Train_loss 1.8310189636492786 
Epoch [4/5] Batch 8000/14335 Train_loss 1.832673061942178 
Epoch [4/5] Batch 8100/14335 Train_loss 1.8323010922401661 
Epoch [4/5] Batch 8200/14335 Train_loss 1.8319628581653613 
Epoch [4/5] Batch 8300/14335 Train_loss 1.8309091963659294 
Epoch [4/5] Batch 8400/14335 Train_loss 1.8300538099641503 
Epoch [4/5] Batch 8500/14335 Train_loss 1.8301441387760122 
Epoch [4/5] Batch 8600/14335 Train_loss 1.8292438572407144 
Epoch [4/5] Batch 8700/14335 Train_loss 1.8295517876922378 
Epoch [4/5] Batch 8800/14335 Train_loss 1.8292179041236398 
Epoch [4/5] Batch 8900/14335 Train_loss 1.8285070270937744 
Epoch [4/5] Batch 9000/14335 Train_loss 1.8286541795777937 
Epoch [4/5] Batch 9100/14335 Train_loss 1.82816412165612 
Epoch [4/5] Batch 9200/14335 Train_loss 1.8275918871765162 
Epoch [4/5] Batch 9300/14335 Train_loss 1.8277535395737412 
Epoch [4/5] Batch 9400/14335 Train_loss 1.827466260979035 
Epoch [4/5] Batch 9500/14335 Train_loss 1.8278024546035891 
Epoch [4/5] Batch 9600/14335 Train_loss 1.8279229002666093 
Epoch [4/5] Batch 9700/14335 Train_loss 1.827938491600486 
Epoch [4/5] Batch 9800/14335 Train_loss 1.8267428664968168 
Epoch [4/5] Batch 9900/14335 Train_loss 1.8276065592173856 
Epoch [4/5] Batch 10000/14335 Train_loss 1.826963156224066 
Epoch [4/5] Batch 10100/14335 Train_loss 1.8264269728666072 
Epoch [4/5] Batch 10200/14335 Train_loss 1.826156109349422 
Epoch [4/5] Batch 10300/14335 Train_loss 1.8258238729690188 
Epoch [4/5] Batch 10400/14335 Train_loss 1.8252415634937418 
Epoch [4/5] Batch 10500/14335 Train_loss 1.825851863935702 
Epoch [4/5] Batch 10600/14335 Train_loss 1.8254425609286646 
Epoch [4/5] Batch 10700/14335 Train_loss 1.824571816906028 
Epoch [4/5] Batch 10800/14335 Train_loss 1.8239491385998476 
Epoch [4/5] Batch 10900/14335 Train_loss 1.8246912265242747 
Epoch [4/5] Batch 11000/14335 Train_loss 1.8241345263735163 
Epoch [4/5] Batch 11100/14335 Train_loss 1.824192204646469 
Epoch [4/5] Batch 11200/14335 Train_loss 1.8242275433340633 
Epoch [4/5] Batch 11300/14335 Train_loss 1.8238715329012578 
Epoch [4/5] Batch 11400/14335 Train_loss 1.8236831583245399 
Epoch [4/5] Batch 11500/14335 Train_loss 1.823095213199152 
Epoch [4/5] Batch 11600/14335 Train_loss 1.8233788105715463 
Epoch [4/5] Batch 11700/14335 Train_loss 1.8231090032689368 
Epoch [4/5] Batch 11800/14335 Train_loss 1.8233823280413113 
Epoch [4/5] Batch 11900/14335 Train_loss 1.8230898875695258 
Epoch [4/5] Batch 12000/14335 Train_loss 1.823177235302662 
Epoch [4/5] Batch 12100/14335 Train_loss 1.82189425567602 
Epoch [4/5] Batch 12200/14335 Train_loss 1.8221340342683192 
Epoch [4/5] Batch 12300/14335 Train_loss 1.8215687063935035 
Epoch [4/5] Batch 12400/14335 Train_loss 1.8212947539060542 
Epoch [4/5] Batch 12500/14335 Train_loss 1.821055595317742 
Epoch [4/5] Batch 12600/14335 Train_loss 1.8219560499042662 
Epoch [4/5] Batch 12700/14335 Train_loss 1.8217980471976338 
Epoch [4/5] Batch 12800/14335 Train_loss 1.8218240157990855 
Epoch [4/5] Batch 12900/14335 Train_loss 1.8221394327694331 
Epoch [4/5] Batch 13000/14335 Train_loss 1.8225612459706715 
Epoch [4/5] Batch 13100/14335 Train_loss 1.8216829527413725 
Epoch [4/5] Batch 13200/14335 Train_loss 1.8222388387562813 
Epoch [4/5] Batch 13300/14335 Train_loss 1.8221596980230914 
Epoch [4/5] Batch 13400/14335 Train_loss 1.8219033292116722 
Epoch [4/5] Batch 13500/14335 Train_loss 1.8214040890895618 
Epoch [4/5] Batch 13600/14335 Train_loss 1.821753298152318 
Epoch [4/5] Batch 13700/14335 Train_loss 1.8210557740162379 
Epoch [4/5] Batch 13800/14335 Train_loss 1.820570186032099 
Epoch [4/5] Batch 13900/14335 Train_loss 1.82032091447273 
Epoch [4/5] Batch 14000/14335 Train_loss 1.8200269917144698 
Epoch [4/5] Batch 14100/14335 Train_loss 1.820365709938417 
Epoch [4/5] Batch 14200/14335 Train_loss 1.8201624337287614 
Epoch [4/5] Batch 14300/14335 Train_loss 1.8202141869903594 
Epoch: 4/5 	Training Loss: 1.820030 	Validation Loss: 1.787814 Duration seconds: 4849.46018743515 
Validation loss decreased (1.801328 --> 1.787814).  Saving model ... 
best_valid_loss_fold [1.78781443799796] Best_Epoch [4]Fold: 1/5 
Epoch [0/5] Batch 0/14335 Train_loss 1.5498436987400055 
Epoch [0/5] Batch 100/14335 Train_loss 1.812483976678093 
Epoch [0/5] Batch 200/14335 Train_loss 1.8544868016569176 
Epoch [0/5] Batch 300/14335 Train_loss 1.8532485472799536 
Epoch [0/5] Batch 400/14335 Train_loss 1.8627069777161105 
Epoch [0/5] Batch 500/14335 Train_loss 1.8683559996282268 
Epoch [0/5] Batch 600/14335 Train_loss 1.8537335643256563 
Epoch [0/5] Batch 700/14335 Train_loss 1.8481466992520401 
Epoch [0/5] Batch 800/14335 Train_loss 1.8471153620886296 
Epoch [0/5] Batch 900/14335 Train_loss 1.8548585749029716 
Epoch [0/5] Batch 1000/14335 Train_loss 1.8456575412909826 
Epoch [0/5] Batch 1100/14335 Train_loss 1.8419404733218896 
Epoch [0/5] Batch 1200/14335 Train_loss 1.841829160257839 
Epoch [0/5] Batch 1300/14335 Train_loss 1.8396405363133281 
Epoch [0/5] Batch 1400/14335 Train_loss 1.841096845239422 
Epoch [0/5] Batch 1500/14335 Train_loss 1.8376267903908183 
Epoch [0/5] Batch 1600/14335 Train_loss 1.835891611962524 
Epoch [0/5] Batch 1700/14335 Train_loss 1.8302974277895945 
Epoch [0/5] Batch 1800/14335 Train_loss 1.8315828015313156 
Epoch [0/5] Batch 1900/14335 Train_loss 1.8320869922104914 
Epoch [0/5] Batch 2000/14335 Train_loss 1.8305782512805868 
Epoch [0/5] Batch 2100/14335 Train_loss 1.832211075199042 
Epoch [0/5] Batch 2200/14335 Train_loss 1.831824497092534 
Epoch [0/5] Batch 2300/14335 Train_loss 1.8305564507589502 
Epoch [0/5] Batch 2400/14335 Train_loss 1.8321582045978628 
Epoch [0/5] Batch 2500/14335 Train_loss 1.8304583600691346 
Epoch [0/5] Batch 2600/14335 Train_loss 1.829857137834783 
Epoch [0/5] Batch 2700/14335 Train_loss 1.8315161357474123 
Epoch [0/5] Batch 2800/14335 Train_loss 1.8318759199392791 
Epoch [0/5] Batch 2900/14335 Train_loss 1.8314819662006343 
Epoch [0/5] Batch 3000/14335 Train_loss 1.8335652770955575 
Epoch [0/5] Batch 3100/14335 Train_loss 1.834073146791352 
Epoch [0/5] Batch 3200/14335 Train_loss 1.8329216964410193 
Epoch [0/5] Batch 3300/14335 Train_loss 1.8331264779400516 
Epoch [0/5] Batch 3400/14335 Train_loss 1.832912834654202 
Epoch [0/5] Batch 3500/14335 Train_loss 1.8331292762147873 
Epoch [0/5] Batch 3600/14335 Train_loss 1.8323211700046966 
Epoch [0/5] Batch 3700/14335 Train_loss 1.8322277155857543 
Epoch [0/5] Batch 3800/14335 Train_loss 1.8328102536340727 
Epoch [0/5] Batch 3900/14335 Train_loss 1.8336582452944994 
Epoch [0/5] Batch 4000/14335 Train_loss 1.83341619147789 
Epoch [0/5] Batch 4100/14335 Train_loss 1.8332170529558554 
Epoch [0/5] Batch 4200/14335 Train_loss 1.831875863571276 
Epoch [0/5] Batch 4300/14335 Train_loss 1.8331599880812806 
Epoch [0/5] Batch 4400/14335 Train_loss 1.831533688577 
Epoch [0/5] Batch 4500/14335 Train_loss 1.8316547535533667 
Epoch [0/5] Batch 4600/14335 Train_loss 1.831677473645914 
Epoch [0/5] Batch 4700/14335 Train_loss 1.8325266044074184 
Epoch [0/5] Batch 4800/14335 Train_loss 1.8323303172952605 
Epoch [0/5] Batch 4900/14335 Train_loss 1.833176531674448 
Epoch [0/5] Batch 5000/14335 Train_loss 1.8333633323295955 
Epoch [0/5] Batch 5100/14335 Train_loss 1.8341806358308144 
Epoch [0/5] Batch 5200/14335 Train_loss 1.833874899861767 
Epoch [0/5] Batch 5300/14335 Train_loss 1.8322272727347122 
Epoch [0/5] Batch 5400/14335 Train_loss 1.8320097524994856 
Epoch [0/5] Batch 5500/14335 Train_loss 1.8323915673074798 
Epoch [0/5] Batch 5600/14335 Train_loss 1.8307979435388413 
Epoch [0/5] Batch 5700/14335 Train_loss 1.8311263782515732 
Epoch [0/5] Batch 5800/14335 Train_loss 1.8303658438718353 
Epoch [0/5] Batch 5900/14335 Train_loss 1.829092105431711 
Epoch [0/5] Batch 6000/14335 Train_loss 1.8272938462862907 
Epoch [0/5] Batch 6100/14335 Train_loss 1.8275157527696146 
Epoch [0/5] Batch 6200/14335 Train_loss 1.8275957721468903 
Epoch [0/5] Batch 6300/14335 Train_loss 1.8270070131804863 
Epoch [0/5] Batch 6400/14335 Train_loss 1.8275054532919912 
Epoch [0/5] Batch 6500/14335 Train_loss 1.8280271315020866 
Epoch [0/5] Batch 6600/14335 Train_loss 1.8281217022134288 
Epoch [0/5] Batch 6700/14335 Train_loss 1.8283700355374624 
Epoch [0/5] Batch 6800/14335 Train_loss 1.8278025880230295 
Epoch [0/5] Batch 6900/14335 Train_loss 1.8282922844993188 
Epoch [0/5] Batch 7000/14335 Train_loss 1.827348284279682 
Epoch [0/5] Batch 7100/14335 Train_loss 1.8272370146292396 
Epoch [0/5] Batch 7200/14335 Train_loss 1.8267275959898939 
Epoch [0/5] Batch 7300/14335 Train_loss 1.8279518977617861 
Epoch [0/5] Batch 7400/14335 Train_loss 1.8286804068335776 
Epoch [0/5] Batch 7500/14335 Train_loss 1.8283055950670843 
Epoch [0/5] Batch 7600/14335 Train_loss 1.8281221083062618 
Epoch [0/5] Batch 7700/14335 Train_loss 1.8276915269004201 
Epoch [0/5] Batch 7800/14335 Train_loss 1.8276609185452248 
Epoch [0/5] Batch 7900/14335 Train_loss 1.827213132928186 
Epoch [0/5] Batch 8000/14335 Train_loss 1.8268740040220672 
Epoch [0/5] Batch 8100/14335 Train_loss 1.8269241939176601 
Epoch [0/5] Batch 8200/14335 Train_loss 1.826388453834196 
Epoch [0/5] Batch 8300/14335 Train_loss 1.8261033990796811 
Epoch [0/5] Batch 8400/14335 Train_loss 1.825533613723107 
Epoch [0/5] Batch 8500/14335 Train_loss 1.826106024694161 
Epoch [0/5] Batch 8600/14335 Train_loss 1.826140017565628 
Epoch [0/5] Batch 8700/14335 Train_loss 1.8265892351135045 
Epoch [0/5] Batch 8800/14335 Train_loss 1.8255199854601962 
Epoch [0/5] Batch 8900/14335 Train_loss 1.824293136433455 
Epoch [0/5] Batch 9000/14335 Train_loss 1.822754315425192 
Epoch [0/5] Batch 9100/14335 Train_loss 1.8223610707671154 
Epoch [0/5] Batch 9200/14335 Train_loss 1.822664943072164 
Epoch [0/5] Batch 9300/14335 Train_loss 1.8218347423179932 
Epoch [0/5] Batch 9400/14335 Train_loss 1.8218948922868283 
Epoch [0/5] Batch 9500/14335 Train_loss 1.8217690618772053 
Epoch [0/5] Batch 9600/14335 Train_loss 1.8208743300245847 
Epoch [0/5] Batch 9700/14335 Train_loss 1.8208693249102916 
Epoch [0/5] Batch 9800/14335 Train_loss 1.8210384710701846 
Epoch [0/5] Batch 9900/14335 Train_loss 1.8210155118297067 
Epoch [0/5] Batch 10000/14335 Train_loss 1.8205207060106563 
Epoch [0/5] Batch 10100/14335 Train_loss 1.8204244225922226 
Epoch [0/5] Batch 10200/14335 Train_loss 1.8197738839889108 
Epoch [0/5] Batch 10300/14335 Train_loss 1.8197818063998752 
Epoch [0/5] Batch 10400/14335 Train_loss 1.8205100793845264 
Epoch [0/5] Batch 10500/14335 Train_loss 1.819784919656909 
Epoch [0/5] Batch 10600/14335 Train_loss 1.8199375390573533 
Epoch [0/5] Batch 10700/14335 Train_loss 1.8199810192215924 
Epoch [0/5] Batch 10800/14335 Train_loss 1.8204035178349753 
Epoch [0/5] Batch 10900/14335 Train_loss 1.8197556456989918 
Epoch [0/5] Batch 11000/14335 Train_loss 1.8194301834529925 
Epoch [0/5] Batch 11100/14335 Train_loss 1.819920099901891 
Epoch [0/5] Batch 11200/14335 Train_loss 1.8196322681589665 
Epoch [0/5] Batch 11300/14335 Train_loss 1.819644053273365 
Epoch [0/5] Batch 11400/14335 Train_loss 1.8196934119615835 
Epoch [0/5] Batch 11500/14335 Train_loss 1.8196670115305003 
Epoch [0/5] Batch 11600/14335 Train_loss 1.8199319506503828 
Epoch [0/5] Batch 11700/14335 Train_loss 1.8198212057176324 
Epoch [0/5] Batch 11800/14335 Train_loss 1.8193651276600582 
Epoch [0/5] Batch 11900/14335 Train_loss 1.8196096546611769 
Epoch [0/5] Batch 12000/14335 Train_loss 1.8191824840972617 
Epoch [0/5] Batch 12100/14335 Train_loss 1.818602978749129 
Epoch [0/5] Batch 12200/14335 Train_loss 1.8186019279222128 
Epoch [0/5] Batch 12300/14335 Train_loss 1.8181977625919614 
Epoch [0/5] Batch 12400/14335 Train_loss 1.8181979243196207 
Epoch [0/5] Batch 12500/14335 Train_loss 1.8178214380214686 
Epoch [0/5] Batch 12600/14335 Train_loss 1.8182763444083416 
Epoch [0/5] Batch 12700/14335 Train_loss 1.818776135958726 
Epoch [0/5] Batch 12800/14335 Train_loss 1.8193439103307347 
Epoch [0/5] Batch 12900/14335 Train_loss 1.8192729306981255 
Epoch [0/5] Batch 13000/14335 Train_loss 1.8190412113852623 
Epoch [0/5] Batch 13100/14335 Train_loss 1.8193475919397548 
Epoch [0/5] Batch 13200/14335 Train_loss 1.8190371054859966 
Epoch [0/5] Batch 13300/14335 Train_loss 1.8192514124410502 
Epoch [0/5] Batch 13400/14335 Train_loss 1.818942354099558 
Epoch [0/5] Batch 13500/14335 Train_loss 1.818497672908267 
Epoch [0/5] Batch 13600/14335 Train_loss 1.8186674777079563 
Epoch [0/5] Batch 13700/14335 Train_loss 1.8188606218726007 
Epoch [0/5] Batch 13800/14335 Train_loss 1.8187752292510324 
Epoch [0/5] Batch 13900/14335 Train_loss 1.8190867636286048 
Epoch [0/5] Batch 14000/14335 Train_loss 1.8190874028507917 
Epoch [0/5] Batch 14100/14335 Train_loss 1.8190543750074728 
Epoch [0/5] Batch 14200/14335 Train_loss 1.8186986363879116 
Epoch [0/5] Batch 14300/14335 Train_loss 1.818290257030776 
Epoch: 0/5 	Training Loss: 1.818518 	Validation Loss: 1.808104 Duration seconds: 4056.74463057518 
Validation loss decreased (inf --> 1.808104).  Saving model ... 
best_valid_loss_fold [1.808104307355409] Best_Epoch [0]Epoch [1/5] Batch 0/14335 Train_loss 1.232626885175705 
Epoch [1/5] Batch 100/14335 Train_loss 1.786808585471446 
Epoch [1/5] Batch 200/14335 Train_loss 1.8051863847235543 
Epoch [1/5] Batch 300/14335 Train_loss 1.7919961454662374 
Epoch [1/5] Batch 400/14335 Train_loss 1.79519447398156 
Epoch [1/5] Batch 500/14335 Train_loss 1.7943854624788442 
Epoch [1/5] Batch 600/14335 Train_loss 1.7755510481368881 
Epoch [1/5] Batch 700/14335 Train_loss 1.77202894268677 
Epoch [1/5] Batch 800/14335 Train_loss 1.786980660174149 
Epoch [1/5] Batch 900/14335 Train_loss 1.7847172589714202 
Epoch [1/5] Batch 1000/14335 Train_loss 1.7841417269853803 
Epoch [1/5] Batch 1100/14335 Train_loss 1.789358115766018 
Epoch [1/5] Batch 1200/14335 Train_loss 1.7922451454125574 
Epoch [1/5] Batch 1300/14335 Train_loss 1.7908994972900552 
Epoch [1/5] Batch 1400/14335 Train_loss 1.79281869984307 
Epoch [1/5] Batch 1500/14335 Train_loss 1.7944754996423242 
Epoch [1/5] Batch 1600/14335 Train_loss 1.7935114958644063 
Epoch [1/5] Batch 1700/14335 Train_loss 1.795041699735541 
Epoch [1/5] Batch 1800/14335 Train_loss 1.794863148245429 
Epoch [1/5] Batch 1900/14335 Train_loss 1.7999045551019177 
Epoch [1/5] Batch 2000/14335 Train_loss 1.7962069711882969 
Epoch [1/5] Batch 2100/14335 Train_loss 1.7927634308220148 
Epoch [1/5] Batch 2200/14335 Train_loss 1.7931261683379667 
Epoch [1/5] Batch 2300/14335 Train_loss 1.7913896043901079 
Epoch [1/5] Batch 2400/14335 Train_loss 1.789139762787658 
Epoch [1/5] Batch 2500/14335 Train_loss 1.793928105311125 
Epoch [1/5] Batch 2600/14335 Train_loss 1.7933859013848834 
Epoch [1/5] Batch 2700/14335 Train_loss 1.7979410707244428 
Epoch [1/5] Batch 2800/14335 Train_loss 1.7993837161410582 
Epoch [1/5] Batch 2900/14335 Train_loss 1.7973800613880362 
Epoch [1/5] Batch 3000/14335 Train_loss 1.7980781259739531 
Epoch [1/5] Batch 3100/14335 Train_loss 1.7996483953277436 
Epoch [1/5] Batch 3200/14335 Train_loss 1.7979917704118709 
Epoch [1/5] Batch 3300/14335 Train_loss 1.797603810128751 
Epoch [1/5] Batch 3400/14335 Train_loss 1.7987778423131127 
Epoch [1/5] Batch 3500/14335 Train_loss 1.7990466966795193 
Epoch [1/5] Batch 3600/14335 Train_loss 1.8027335420039852 
Epoch [1/5] Batch 3700/14335 Train_loss 1.8021988989903586 
Epoch [1/5] Batch 3800/14335 Train_loss 1.8036851653438655 
Epoch [1/5] Batch 3900/14335 Train_loss 1.8033382633280308 
Epoch [1/5] Batch 4000/14335 Train_loss 1.8039653534979798 
Epoch [1/5] Batch 4100/14335 Train_loss 1.8063850549518174 
Epoch [1/5] Batch 4200/14335 Train_loss 1.8059310977145677 
Epoch [1/5] Batch 4300/14335 Train_loss 1.8054657480559275 
Epoch [1/5] Batch 4400/14335 Train_loss 1.8036378006150549 
Epoch [1/5] Batch 4500/14335 Train_loss 1.8035203443831456 
Epoch [1/5] Batch 4600/14335 Train_loss 1.8033390823841562 
Epoch [1/5] Batch 4700/14335 Train_loss 1.802941623586235 
Epoch [1/5] Batch 4800/14335 Train_loss 1.803117622015154 
Epoch [1/5] Batch 4900/14335 Train_loss 1.8045363163545505 
Epoch [1/5] Batch 5000/14335 Train_loss 1.8043184118452273 
Epoch [1/5] Batch 5100/14335 Train_loss 1.8039879728516885 
Epoch [1/5] Batch 5200/14335 Train_loss 1.8042462007847229 
Epoch [1/5] Batch 5300/14335 Train_loss 1.8041423616983197 
Epoch [1/5] Batch 5400/14335 Train_loss 1.8030940135915043 
Epoch [1/5] Batch 5500/14335 Train_loss 1.803344113041522 
Epoch [1/5] Batch 5600/14335 Train_loss 1.8030418126902565 
Epoch [1/5] Batch 5700/14335 Train_loss 1.8045173331094069 
Epoch [1/5] Batch 5800/14335 Train_loss 1.8043680546345782 
Epoch [1/5] Batch 5900/14335 Train_loss 1.8046659172033277 
Epoch [1/5] Batch 6000/14335 Train_loss 1.804937898400048 
Epoch [1/5] Batch 6100/14335 Train_loss 1.8042086198415508 
Epoch [1/5] Batch 6200/14335 Train_loss 1.803562356313185 
Epoch [1/5] Batch 6300/14335 Train_loss 1.8045962850331616 
Epoch [1/5] Batch 6400/14335 Train_loss 1.8051697784844758 
Epoch [1/5] Batch 6500/14335 Train_loss 1.8054437689818963 
Epoch [1/5] Batch 6600/14335 Train_loss 1.8055187436626312 
Epoch [1/5] Batch 6700/14335 Train_loss 1.8052821364234302 
Epoch [1/5] Batch 6800/14335 Train_loss 1.8053772696071364 
Epoch [1/5] Batch 6900/14335 Train_loss 1.8043845601314012 
Epoch [1/5] Batch 7000/14335 Train_loss 1.8049328191768033 
Epoch [1/5] Batch 7100/14335 Train_loss 1.8048871533415078 
Epoch [1/5] Batch 7200/14335 Train_loss 1.8059972668791657 
Epoch [1/5] Batch 7300/14335 Train_loss 1.8062069528330402 
Epoch [1/5] Batch 7400/14335 Train_loss 1.8069499170986756 
Epoch [1/5] Batch 7500/14335 Train_loss 1.8067223957378837 
Epoch [1/5] Batch 7600/14335 Train_loss 1.8072863289106913 
Epoch [1/5] Batch 7700/14335 Train_loss 1.8071602442559522 
Epoch [1/5] Batch 7800/14335 Train_loss 1.806287972148856 
Epoch [1/5] Batch 7900/14335 Train_loss 1.8056993577532672 
Epoch [1/5] Batch 8000/14335 Train_loss 1.8065529537266485 
Epoch [1/5] Batch 8100/14335 Train_loss 1.8062898435352497 
Epoch [1/5] Batch 8200/14335 Train_loss 1.806243658283835 
Epoch [1/5] Batch 8300/14335 Train_loss 1.807421274889795 
Epoch [1/5] Batch 8400/14335 Train_loss 1.807648544686988 
Epoch [1/5] Batch 8500/14335 Train_loss 1.8076660765192323 
Epoch [1/5] Batch 8600/14335 Train_loss 1.8086029938663069 
Epoch [1/5] Batch 8700/14335 Train_loss 1.807889901641052 
Epoch [1/5] Batch 8800/14335 Train_loss 1.8086282619096423 
Epoch [1/5] Batch 8900/14335 Train_loss 1.8080763609337211 
Epoch [1/5] Batch 9000/14335 Train_loss 1.8078449477201872 
Epoch [1/5] Batch 9100/14335 Train_loss 1.8078896997206069 
Epoch [1/5] Batch 9200/14335 Train_loss 1.8066894431499188 
Epoch [1/5] Batch 9300/14335 Train_loss 1.805743898388526 
Epoch [1/5] Batch 9400/14335 Train_loss 1.8056498894501831 
Epoch [1/5] Batch 9500/14335 Train_loss 1.8059079344688735 
Epoch [1/5] Batch 9600/14335 Train_loss 1.8062472755473338 
Epoch [1/5] Batch 9700/14335 Train_loss 1.8062420680031446 
Epoch [1/5] Batch 9800/14335 Train_loss 1.8063340804624857 
Epoch [1/5] Batch 9900/14335 Train_loss 1.8064687301687623 
Epoch [1/5] Batch 10000/14335 Train_loss 1.8061305751746362 
Epoch [1/5] Batch 10100/14335 Train_loss 1.8054977314097316 
Epoch [1/5] Batch 10200/14335 Train_loss 1.805802566125228 
Epoch [1/5] Batch 10300/14335 Train_loss 1.805463919448437 
Epoch [1/5] Batch 10400/14335 Train_loss 1.8059355442049285 
Epoch [1/5] Batch 10500/14335 Train_loss 1.8050981561638504 
Epoch [1/5] Batch 10600/14335 Train_loss 1.8054813095953102 
Epoch [1/5] Batch 10700/14335 Train_loss 1.8055610727971707 
Epoch [1/5] Batch 10800/14335 Train_loss 1.8059720625810662 
Epoch [1/5] Batch 10900/14335 Train_loss 1.8054408911516848 
Epoch [1/5] Batch 11000/14335 Train_loss 1.8051287603067026 
Epoch [1/5] Batch 11100/14335 Train_loss 1.8056249391912083 
Epoch [1/5] Batch 11200/14335 Train_loss 1.8055904941308574 
Epoch [1/5] Batch 11300/14335 Train_loss 1.8061962656386024 
Epoch [1/5] Batch 11400/14335 Train_loss 1.8063204944082785 
Epoch [1/5] Batch 11500/14335 Train_loss 1.805955798458057 
Epoch [1/5] Batch 11600/14335 Train_loss 1.8055456540544181 
Epoch [1/5] Batch 11700/14335 Train_loss 1.80490774414754 
Epoch [1/5] Batch 11800/14335 Train_loss 1.8051049404800237 
Epoch [1/5] Batch 11900/14335 Train_loss 1.8048491250604966 
Epoch [1/5] Batch 12000/14335 Train_loss 1.8045983878767904 
Epoch [1/5] Batch 12100/14335 Train_loss 1.804384349783549 
Epoch [1/5] Batch 12200/14335 Train_loss 1.8044204022968933 
Epoch [1/5] Batch 12300/14335 Train_loss 1.8049087411895215 
Epoch [1/5] Batch 12400/14335 Train_loss 1.8047082527472207 
Epoch [1/5] Batch 12500/14335 Train_loss 1.804410857116806 
Epoch [1/5] Batch 12600/14335 Train_loss 1.8044315244975606 
Epoch [1/5] Batch 12700/14335 Train_loss 1.8041296045778163 
Epoch [1/5] Batch 12800/14335 Train_loss 1.8040328617341936 
Epoch [1/5] Batch 12900/14335 Train_loss 1.8040805952992378 
Epoch [1/5] Batch 13000/14335 Train_loss 1.8040875992215135 
Epoch [1/5] Batch 13100/14335 Train_loss 1.8039100135165937 
Epoch [1/5] Batch 13200/14335 Train_loss 1.8038139769701775 
Epoch [1/5] Batch 13300/14335 Train_loss 1.8033007091602637 
Epoch [1/5] Batch 13400/14335 Train_loss 1.803469651195707 
Epoch [1/5] Batch 13500/14335 Train_loss 1.8035710760580639 
Epoch [1/5] Batch 13600/14335 Train_loss 1.80333039163831 
Epoch [1/5] Batch 13700/14335 Train_loss 1.8035938305733117 
Epoch [1/5] Batch 13800/14335 Train_loss 1.8037817578523343 
Epoch [1/5] Batch 13900/14335 Train_loss 1.8037907180774513 
Epoch [1/5] Batch 14000/14335 Train_loss 1.803145271544158 
Epoch [1/5] Batch 14100/14335 Train_loss 1.8028867920059768 
Epoch [1/5] Batch 14200/14335 Train_loss 1.8023152392874107 
Epoch [1/5] Batch 14300/14335 Train_loss 1.8023082246469515 
Epoch: 1/5 	Training Loss: 1.801981 	Validation Loss: 1.805294 Duration seconds: 4043.6471059322357 
Validation loss decreased (1.808104 --> 1.805294).  Saving model ... 
best_valid_loss_fold [1.805294431694035] Best_Epoch [1]Epoch [2/5] Batch 0/14335 Train_loss 1.8007904291152954 
Epoch [2/5] Batch 100/14335 Train_loss 1.7597584994417605 
Epoch [2/5] Batch 200/14335 Train_loss 1.798705307776062 
Epoch [2/5] Batch 300/14335 Train_loss 1.8070950586831451 
Epoch [2/5] Batch 400/14335 Train_loss 1.8098848528621203 
Epoch [2/5] Batch 500/14335 Train_loss 1.8064762510641845 
Epoch [2/5] Batch 600/14335 Train_loss 1.8035389733393854 
Epoch [2/5] Batch 700/14335 Train_loss 1.788522726862815 
Epoch [2/5] Batch 800/14335 Train_loss 1.7921945326188382 
Epoch [2/5] Batch 900/14335 Train_loss 1.8001244069964983 
Epoch [2/5] Batch 1000/14335 Train_loss 1.798383936687902 
Epoch [2/5] Batch 1100/14335 Train_loss 1.793667071826289 
Epoch [2/5] Batch 1200/14335 Train_loss 1.7952415307085778 
Epoch [2/5] Batch 1300/14335 Train_loss 1.7989693052614313 
Epoch [2/5] Batch 1400/14335 Train_loss 1.7976370231540266 
Epoch [2/5] Batch 1500/14335 Train_loss 1.800904972931689 
Epoch [2/5] Batch 1600/14335 Train_loss 1.8037995237212565 
Epoch [2/5] Batch 1700/14335 Train_loss 1.8035251712059708 
Epoch [2/5] Batch 1800/14335 Train_loss 1.8052227669361893 
Epoch [2/5] Batch 1900/14335 Train_loss 1.8039742919926516 
Epoch [2/5] Batch 2000/14335 Train_loss 1.803929337441385 
Epoch [2/5] Batch 2100/14335 Train_loss 1.802234929507117 
Epoch [2/5] Batch 2200/14335 Train_loss 1.8031357214707833 
Epoch [2/5] Batch 2300/14335 Train_loss 1.8041429258251593 
Epoch [2/5] Batch 2400/14335 Train_loss 1.8019135579504058 
Epoch [2/5] Batch 2500/14335 Train_loss 1.8049945800704081 
Epoch [2/5] Batch 2600/14335 Train_loss 1.803558737666893 
Epoch [2/5] Batch 2700/14335 Train_loss 1.8035402602865405 
Epoch [2/5] Batch 2800/14335 Train_loss 1.8013343464893046 
Epoch [2/5] Batch 2900/14335 Train_loss 1.7983319051371118 
Epoch [2/5] Batch 3000/14335 Train_loss 1.7974888644454599 
Epoch [2/5] Batch 3100/14335 Train_loss 1.7992072112639654 
Epoch [2/5] Batch 3200/14335 Train_loss 1.798490399517461 
Epoch [2/5] Batch 3300/14335 Train_loss 1.7991325358632513 
Epoch [2/5] Batch 3400/14335 Train_loss 1.7988293744038744 
Epoch [2/5] Batch 3500/14335 Train_loss 1.797342637010606 
Epoch [2/5] Batch 3600/14335 Train_loss 1.794312391031851 
Epoch [2/5] Batch 3700/14335 Train_loss 1.7947908525119374 
Epoch [2/5] Batch 3800/14335 Train_loss 1.7955200600721308 
Epoch [2/5] Batch 3900/14335 Train_loss 1.7940228487613477 
Epoch [2/5] Batch 4000/14335 Train_loss 1.795560389485278 
Epoch [2/5] Batch 4100/14335 Train_loss 1.7947958699742983 
Epoch [2/5] Batch 4200/14335 Train_loss 1.7938741759951982 
Epoch [2/5] Batch 4300/14335 Train_loss 1.7936654073454508 
Epoch [2/5] Batch 4400/14335 Train_loss 1.795103330460564 
Epoch [2/5] Batch 4500/14335 Train_loss 1.7959336356699163 
Epoch [2/5] Batch 4600/14335 Train_loss 1.7956912995171765 
Epoch [2/5] Batch 4700/14335 Train_loss 1.7948072127184824 
Epoch [2/5] Batch 4800/14335 Train_loss 1.7932285246154314 
Epoch [2/5] Batch 4900/14335 Train_loss 1.792356132171855 
Epoch [2/5] Batch 5000/14335 Train_loss 1.7929139320038958 
Epoch [2/5] Batch 5100/14335 Train_loss 1.7919062815315931 
Epoch [2/5] Batch 5200/14335 Train_loss 1.7938839285345267 
Epoch [2/5] Batch 5300/14335 Train_loss 1.7949722665949737 
Epoch [2/5] Batch 5400/14335 Train_loss 1.7946394017682519 
Epoch [2/5] Batch 5500/14335 Train_loss 1.794408811962273 
Epoch [2/5] Batch 5600/14335 Train_loss 1.7943588031565285 
Epoch [2/5] Batch 5700/14335 Train_loss 1.7931888232370612 
Epoch [2/5] Batch 5800/14335 Train_loss 1.7937250678289287 
Epoch [2/5] Batch 5900/14335 Train_loss 1.7926538156664609 
Epoch [2/5] Batch 6000/14335 Train_loss 1.792568510289322 
Epoch [2/5] Batch 6100/14335 Train_loss 1.7912704440301177 
Epoch [2/5] Batch 6200/14335 Train_loss 1.7908953566154036 
Epoch [2/5] Batch 6300/14335 Train_loss 1.7892653881732556 
Epoch [2/5] Batch 6400/14335 Train_loss 1.7888799977791885 
Epoch [2/5] Batch 6500/14335 Train_loss 1.7885298684922444 
Epoch [2/5] Batch 6600/14335 Train_loss 1.78873611586737 
Epoch [2/5] Batch 6700/14335 Train_loss 1.7888615867285618 
Epoch [2/5] Batch 6800/14335 Train_loss 1.7883761080277438 
Epoch [2/5] Batch 6900/14335 Train_loss 1.7885180566243426 
Epoch [2/5] Batch 7000/14335 Train_loss 1.7880896515127949 
Epoch [2/5] Batch 7100/14335 Train_loss 1.7894750153453076 
Epoch [2/5] Batch 7200/14335 Train_loss 1.7884209045462354 
Epoch [2/5] Batch 7300/14335 Train_loss 1.787607762710009 
Epoch [2/5] Batch 7400/14335 Train_loss 1.786837072139728 
Epoch [2/5] Batch 7500/14335 Train_loss 1.7858887475826728 
Epoch [2/5] Batch 7600/14335 Train_loss 1.7850309034493108 
Epoch [2/5] Batch 7700/14335 Train_loss 1.785768536327644 
Epoch [2/5] Batch 7800/14335 Train_loss 1.7862995101933814 
Epoch [2/5] Batch 7900/14335 Train_loss 1.7853931714886127 
Epoch [2/5] Batch 8000/14335 Train_loss 1.7856818935399115 
Epoch [2/5] Batch 8100/14335 Train_loss 1.7865841842635062 
Epoch [2/5] Batch 8200/14335 Train_loss 1.7863990619475196 
Epoch [2/5] Batch 8300/14335 Train_loss 1.7870754733683474 
Epoch [2/5] Batch 8400/14335 Train_loss 1.7875460498128075 
Epoch [2/5] Batch 8500/14335 Train_loss 1.7875862780924672 
Epoch [2/5] Batch 8600/14335 Train_loss 1.7871226040641452 
Epoch [2/5] Batch 8700/14335 Train_loss 1.7863576704932278 
Epoch [2/5] Batch 8800/14335 Train_loss 1.786276953710323 
Epoch [2/5] Batch 8900/14335 Train_loss 1.7859499224652777 
Epoch [2/5] Batch 9000/14335 Train_loss 1.786139664349755 
Epoch [2/5] Batch 9100/14335 Train_loss 1.7857773531481678 
Epoch [2/5] Batch 9200/14335 Train_loss 1.7868252635632127 
Epoch [2/5] Batch 9300/14335 Train_loss 1.7873175203705678 
Epoch [2/5] Batch 9400/14335 Train_loss 1.7872658847721128 
Epoch [2/5] Batch 9500/14335 Train_loss 1.7869529003192532 
Epoch [2/5] Batch 9600/14335 Train_loss 1.7870445233841399 
Epoch [2/5] Batch 9700/14335 Train_loss 1.7876877215033389 
Epoch [2/5] Batch 9800/14335 Train_loss 1.7872317896241947 
Epoch [2/5] Batch 9900/14335 Train_loss 1.7876502159076524 
Epoch [2/5] Batch 10000/14335 Train_loss 1.7878898099264482 
Epoch [2/5] Batch 10100/14335 Train_loss 1.788019942677165 
Epoch [2/5] Batch 10200/14335 Train_loss 1.788722783405253 
Epoch [2/5] Batch 10300/14335 Train_loss 1.7881322525707093 
Epoch [2/5] Batch 10400/14335 Train_loss 1.7879725115350629 
Epoch [2/5] Batch 10500/14335 Train_loss 1.788434011400677 
Epoch [2/5] Batch 10600/14335 Train_loss 1.788708417332096 
Epoch [2/5] Batch 10700/14335 Train_loss 1.7892265889148558 
Epoch [2/5] Batch 10800/14335 Train_loss 1.7894331159227237 
Epoch [2/5] Batch 10900/14335 Train_loss 1.7885847326203035 
Epoch [2/5] Batch 11000/14335 Train_loss 1.7879892035854177 
Epoch [2/5] Batch 11100/14335 Train_loss 1.7879934685985823 
Epoch [2/5] Batch 11200/14335 Train_loss 1.7870347482393325 
Epoch [2/5] Batch 11300/14335 Train_loss 1.7870631469460612 
Epoch [2/5] Batch 11400/14335 Train_loss 1.7878782889744387 
Epoch [2/5] Batch 11500/14335 Train_loss 1.7869669100326846 
Epoch [2/5] Batch 11600/14335 Train_loss 1.7858116513102253 
Epoch [2/5] Batch 11700/14335 Train_loss 1.78630634389691 
Epoch [2/5] Batch 11800/14335 Train_loss 1.7868484009798176 
Epoch [2/5] Batch 11900/14335 Train_loss 1.7866715175565997 
Epoch [2/5] Batch 12000/14335 Train_loss 1.786005584348163 
Epoch [2/5] Batch 12100/14335 Train_loss 1.7857750858189538 
Epoch [2/5] Batch 12200/14335 Train_loss 1.7860846889257411 
Epoch [2/5] Batch 12300/14335 Train_loss 1.7858128452127071 
Epoch [2/5] Batch 12400/14335 Train_loss 1.7860956210965986 
Epoch [2/5] Batch 12500/14335 Train_loss 1.7864265305458493 
Epoch [2/5] Batch 12600/14335 Train_loss 1.786708985517048 
Epoch [2/5] Batch 12700/14335 Train_loss 1.7871993676716114 
Epoch [2/5] Batch 12800/14335 Train_loss 1.787088049143383 
Epoch [2/5] Batch 12900/14335 Train_loss 1.7872749490747295 
Epoch [2/5] Batch 13000/14335 Train_loss 1.787515553619213 
Epoch [2/5] Batch 13100/14335 Train_loss 1.7879127398583692 
Epoch [2/5] Batch 13200/14335 Train_loss 1.787348712659945 
Epoch [2/5] Batch 13300/14335 Train_loss 1.7873571914466027 
Epoch [2/5] Batch 13400/14335 Train_loss 1.787499712182309 
Epoch [2/5] Batch 13500/14335 Train_loss 1.7869589142167484 
Epoch [2/5] Batch 13600/14335 Train_loss 1.7867482919786908 
Epoch [2/5] Batch 13700/14335 Train_loss 1.7865631640534942 
Epoch [2/5] Batch 13800/14335 Train_loss 1.7863760356951317 
Epoch [2/5] Batch 13900/14335 Train_loss 1.7868084333176175 
Epoch [2/5] Batch 14000/14335 Train_loss 1.7872803031830955 
Epoch [2/5] Batch 14100/14335 Train_loss 1.7868785774835239 
Epoch [2/5] Batch 14200/14335 Train_loss 1.7873497390693975 
Epoch [2/5] Batch 14300/14335 Train_loss 1.7871439841086652 
Epoch: 2/5 	Training Loss: 1.787228 	Validation Loss: 1.780498 Duration seconds: 4120.060263633728 
Validation loss decreased (1.805294 --> 1.780498).  Saving model ... 
best_valid_loss_fold [1.780497815227136] Best_Epoch [2]Epoch [3/5] Batch 0/14335 Train_loss 1.0396061092615128 
Epoch [3/5] Batch 100/14335 Train_loss 1.7224853323532803 
Epoch [3/5] Batch 200/14335 Train_loss 1.7598752388313634 
Epoch [3/5] Batch 300/14335 Train_loss 1.7534152821844995 
Epoch [3/5] Batch 400/14335 Train_loss 1.7589603692404647 
Epoch [3/5] Batch 500/14335 Train_loss 1.7793398583214917 
Epoch [3/5] Batch 600/14335 Train_loss 1.7742071670794646 
Epoch [3/5] Batch 700/14335 Train_loss 1.7665287420238647 
Epoch [3/5] Batch 800/14335 Train_loss 1.7703334368142147 
Epoch [3/5] Batch 900/14335 Train_loss 1.7705807516911582 
Epoch [3/5] Batch 1000/14335 Train_loss 1.7728767257098195 
Epoch [3/5] Batch 1100/14335 Train_loss 1.7793767443510426 
Epoch [3/5] Batch 1200/14335 Train_loss 1.7797000927355864 
Epoch [3/5] Batch 1300/14335 Train_loss 1.7842559437686256 
Epoch [3/5] Batch 1400/14335 Train_loss 1.788126776536008 
Epoch [3/5] Batch 1500/14335 Train_loss 1.7897105076257822 
Epoch [3/5] Batch 1600/14335 Train_loss 1.7851845523822985 
Epoch [3/5] Batch 1700/14335 Train_loss 1.7898411694684147 
Epoch [3/5] Batch 1800/14335 Train_loss 1.7908498492383547 
Epoch [3/5] Batch 1900/14335 Train_loss 1.7888127994585952 
Epoch [3/5] Batch 2000/14335 Train_loss 1.7867453733849143 
Epoch [3/5] Batch 2100/14335 Train_loss 1.786849206239907 
Epoch [3/5] Batch 2200/14335 Train_loss 1.784615707361579 
Epoch [3/5] Batch 2300/14335 Train_loss 1.7878755262815293 
Epoch [3/5] Batch 2400/14335 Train_loss 1.78950223237003 
Epoch [3/5] Batch 2500/14335 Train_loss 1.786758624201939 
Epoch [3/5] Batch 2600/14335 Train_loss 1.7835098044550772 
Epoch [3/5] Batch 2700/14335 Train_loss 1.7825479822296073 
Epoch [3/5] Batch 2800/14335 Train_loss 1.7851647012725722 
Epoch [3/5] Batch 2900/14335 Train_loss 1.7867832304701152 
Epoch [3/5] Batch 3000/14335 Train_loss 1.7861713503537993 
Epoch [3/5] Batch 3100/14335 Train_loss 1.7847228360893033 
Epoch [3/5] Batch 3200/14335 Train_loss 1.7849628025853832 
Epoch [3/5] Batch 3300/14335 Train_loss 1.7869175788408986 
Epoch [3/5] Batch 3400/14335 Train_loss 1.786140127458561 
Epoch [3/5] Batch 3500/14335 Train_loss 1.783970979086776 
Epoch [3/5] Batch 3600/14335 Train_loss 1.7815091840196602 
Epoch [3/5] Batch 3700/14335 Train_loss 1.7807443460695682 
Epoch [3/5] Batch 3800/14335 Train_loss 1.7806615792185467 
Epoch [3/5] Batch 3900/14335 Train_loss 1.7801476609925373 
Epoch [3/5] Batch 4000/14335 Train_loss 1.7778260092013807 
Epoch [3/5] Batch 4100/14335 Train_loss 1.7770437070074765 
Epoch [3/5] Batch 4200/14335 Train_loss 1.7752641421081878 
Epoch [3/5] Batch 4300/14335 Train_loss 1.7765228661031425 
Epoch [3/5] Batch 4400/14335 Train_loss 1.7767509174679414 
Epoch [3/5] Batch 4500/14335 Train_loss 1.774855171245645 
Epoch [3/5] Batch 4600/14335 Train_loss 1.7744299982182747 
Epoch [3/5] Batch 4700/14335 Train_loss 1.7729322868721253 
Epoch [3/5] Batch 4800/14335 Train_loss 1.774750724000326 
Epoch [3/5] Batch 4900/14335 Train_loss 1.7736903893943954 
Epoch [3/5] Batch 5000/14335 Train_loss 1.775401977748066 
Epoch [3/5] Batch 5100/14335 Train_loss 1.7757698299516254 
Epoch [3/5] Batch 5200/14335 Train_loss 1.776091187556325 
Epoch [3/5] Batch 5300/14335 Train_loss 1.775760858255925 
Epoch [3/5] Batch 5400/14335 Train_loss 1.7745399627392435 
Epoch [3/5] Batch 5500/14335 Train_loss 1.7752819637930668 
Epoch [3/5] Batch 5600/14335 Train_loss 1.7743819810741397 
Epoch [3/5] Batch 5700/14335 Train_loss 1.7748911807977135 
Epoch [3/5] Batch 5800/14335 Train_loss 1.7745422995415685 
Epoch [3/5] Batch 5900/14335 Train_loss 1.7738227242876303 
Epoch [3/5] Batch 6000/14335 Train_loss 1.7731727987038675 
Epoch [3/5] Batch 6100/14335 Train_loss 1.7742685653016501 
Epoch [3/5] Batch 6200/14335 Train_loss 1.7738734938863918 
Epoch [3/5] Batch 6300/14335 Train_loss 1.7731131864701295 
Epoch [3/5] Batch 6400/14335 Train_loss 1.7722494159300632 
Epoch [3/5] Batch 6500/14335 Train_loss 1.7723957599275224 
Epoch [3/5] Batch 6600/14335 Train_loss 1.7716862943766696 
Epoch [3/5] Batch 6700/14335 Train_loss 1.7708615956522515 
Epoch [3/5] Batch 6800/14335 Train_loss 1.7708845997475435 
Epoch [3/5] Batch 6900/14335 Train_loss 1.770971500386433 
Epoch [3/5] Batch 7000/14335 Train_loss 1.7707632892839467 
Epoch [3/5] Batch 7100/14335 Train_loss 1.7706018689022553 
Epoch [3/5] Batch 7200/14335 Train_loss 1.7716441637272637 
Epoch [3/5] Batch 7300/14335 Train_loss 1.7722836307545522 
Epoch [3/5] Batch 7400/14335 Train_loss 1.7728599716506928 
Epoch [3/5] Batch 7500/14335 Train_loss 1.7728122168104739 
Epoch [3/5] Batch 7600/14335 Train_loss 1.772431494267955 
Epoch [3/5] Batch 7700/14335 Train_loss 1.7728224121940677 
Epoch [3/5] Batch 7800/14335 Train_loss 1.7727691713620755 
Epoch [3/5] Batch 7900/14335 Train_loss 1.7730522315976076 
Epoch [3/5] Batch 8000/14335 Train_loss 1.7726973075186396 
Epoch [3/5] Batch 8100/14335 Train_loss 1.7725798190044717 
Epoch [3/5] Batch 8200/14335 Train_loss 1.7728430514505849 
Epoch [3/5] Batch 8300/14335 Train_loss 1.7736671022454193 
Epoch [3/5] Batch 8400/14335 Train_loss 1.7735631028809955 
Epoch [3/5] Batch 8500/14335 Train_loss 1.7723706272255322 
Epoch [3/5] Batch 8600/14335 Train_loss 1.7721991715421095 
Epoch [3/5] Batch 8700/14335 Train_loss 1.772454689938561 
Epoch [3/5] Batch 8800/14335 Train_loss 1.7720319609972661 
Epoch [3/5] Batch 8900/14335 Train_loss 1.7706477517422605 
Epoch [3/5] Batch 9000/14335 Train_loss 1.7708177756074865 
Epoch [3/5] Batch 9100/14335 Train_loss 1.7713370045026688 
Epoch [3/5] Batch 9200/14335 Train_loss 1.7713157070923948 
Epoch [3/5] Batch 9300/14335 Train_loss 1.7711251798234964 
Epoch [3/5] Batch 9400/14335 Train_loss 1.7717204221229377 
Epoch [3/5] Batch 9500/14335 Train_loss 1.7718942309147985 
Epoch [3/5] Batch 9600/14335 Train_loss 1.7715171653784734 
Epoch [3/5] Batch 9700/14335 Train_loss 1.7716332344529728 
Epoch [3/5] Batch 9800/14335 Train_loss 1.7721710323758326 
Epoch [3/5] Batch 9900/14335 Train_loss 1.772660643641918 
Epoch [3/5] Batch 10000/14335 Train_loss 1.7720484497645248 
Epoch [3/5] Batch 10100/14335 Train_loss 1.7713965328258874 
Epoch [3/5] Batch 10200/14335 Train_loss 1.772252343556318 
Epoch [3/5] Batch 10300/14335 Train_loss 1.771650445643831 
Epoch [3/5] Batch 10400/14335 Train_loss 1.7715142009771394 
Epoch [3/5] Batch 10500/14335 Train_loss 1.771239445128562 
Epoch [3/5] Batch 10600/14335 Train_loss 1.7710322576481243 
Epoch [3/5] Batch 10700/14335 Train_loss 1.7717168382473856 
Epoch [3/5] Batch 10800/14335 Train_loss 1.7718539006905294 
Epoch [3/5] Batch 10900/14335 Train_loss 1.7713871649709516 
Epoch [3/5] Batch 11000/14335 Train_loss 1.7718675002725262 
Epoch [3/5] Batch 11100/14335 Train_loss 1.771194847540086 
Epoch [3/5] Batch 11200/14335 Train_loss 1.7710308447571996 
Epoch [3/5] Batch 11300/14335 Train_loss 1.7705542211149785 
Epoch [3/5] Batch 11400/14335 Train_loss 1.769559194236071 
Epoch [3/5] Batch 11500/14335 Train_loss 1.7695243851953086 
Epoch [3/5] Batch 11600/14335 Train_loss 1.7702227659345589 
Epoch [3/5] Batch 11700/14335 Train_loss 1.769740353149386 
Epoch [3/5] Batch 11800/14335 Train_loss 1.7696950509834872 
Epoch [3/5] Batch 11900/14335 Train_loss 1.7699902062881454 
Epoch [3/5] Batch 12000/14335 Train_loss 1.7699102026496307 
Epoch [3/5] Batch 12100/14335 Train_loss 1.769672309125975 
Epoch [3/5] Batch 12200/14335 Train_loss 1.7697545343688028 
Epoch [3/5] Batch 12300/14335 Train_loss 1.768917910401564 
Epoch [3/5] Batch 12400/14335 Train_loss 1.768343358656378 
Epoch [3/5] Batch 12500/14335 Train_loss 1.7687025090263668 
Epoch [3/5] Batch 12600/14335 Train_loss 1.7684555575742333 
Epoch [3/5] Batch 12700/14335 Train_loss 1.768291940107917 
Epoch [3/5] Batch 12800/14335 Train_loss 1.7677422226029404 
Epoch [3/5] Batch 12900/14335 Train_loss 1.768029868965435 
Epoch [3/5] Batch 13000/14335 Train_loss 1.768128028611258 
Epoch [3/5] Batch 13100/14335 Train_loss 1.7681824056217392 
Epoch [3/5] Batch 13200/14335 Train_loss 1.7679276577036234 
Epoch [3/5] Batch 13300/14335 Train_loss 1.7678328531414538 
Epoch [3/5] Batch 13400/14335 Train_loss 1.7682174119188505 
Epoch [3/5] Batch 13500/14335 Train_loss 1.7684864917624201 
Epoch [3/5] Batch 13600/14335 Train_loss 1.767935939639879 
Epoch [3/5] Batch 13700/14335 Train_loss 1.7681452530749513 
Epoch [3/5] Batch 13800/14335 Train_loss 1.7676103104878471 
Epoch [3/5] Batch 13900/14335 Train_loss 1.7672793089091439 
Epoch [3/5] Batch 14000/14335 Train_loss 1.7674599029270124 
Epoch [3/5] Batch 14100/14335 Train_loss 1.7675177410850456 
Epoch [3/5] Batch 14200/14335 Train_loss 1.767234447261421 
Epoch [3/5] Batch 14300/14335 Train_loss 1.7674711716446199 
Epoch: 3/5 	Training Loss: 1.767134 	Validation Loss: 1.757591 Duration seconds: 4651.533916711807 
Validation loss decreased (1.780498 --> 1.757591).  Saving model ... 
best_valid_loss_fold [1.7575905842573516] Best_Epoch [3]Epoch [4/5] Batch 0/14335 Train_loss 1.9685658812522888 
Epoch [4/5] Batch 100/14335 Train_loss 1.776792244008272 
Epoch [4/5] Batch 200/14335 Train_loss 1.7637056490378593 
Epoch [4/5] Batch 300/14335 Train_loss 1.7651142938638051 
Epoch [4/5] Batch 400/14335 Train_loss 1.7474710401565654 
Epoch [4/5] Batch 500/14335 Train_loss 1.7585738793669823 
Epoch [4/5] Batch 600/14335 Train_loss 1.7481693008700743 
Epoch [4/5] Batch 700/14335 Train_loss 1.7517563844692179 
Epoch [4/5] Batch 800/14335 Train_loss 1.7541590534364537 
Epoch [4/5] Batch 900/14335 Train_loss 1.754916696938439 
Epoch [4/5] Batch 1000/14335 Train_loss 1.7491394047300657 
Epoch [4/5] Batch 1100/14335 Train_loss 1.748477175906233 
Epoch [4/5] Batch 1200/14335 Train_loss 1.7504563591102578 
Epoch [4/5] Batch 1300/14335 Train_loss 1.7496254637287636 
Epoch [4/5] Batch 1400/14335 Train_loss 1.751875974354916 
Epoch [4/5] Batch 1500/14335 Train_loss 1.7544372733446616 
Epoch [4/5] Batch 1600/14335 Train_loss 1.753979610496763 
Epoch [4/5] Batch 1700/14335 Train_loss 1.7599731238930103 
Epoch [4/5] Batch 1800/14335 Train_loss 1.7624770314006062 
Epoch [4/5] Batch 1900/14335 Train_loss 1.7652458113778395 
Epoch [4/5] Batch 2000/14335 Train_loss 1.7625445900657128 
Epoch [4/5] Batch 2100/14335 Train_loss 1.7636737059526986 
Epoch [4/5] Batch 2200/14335 Train_loss 1.7625601583078794 
Epoch [4/5] Batch 2300/14335 Train_loss 1.767017346608903 
Epoch [4/5] Batch 2400/14335 Train_loss 1.7659984910701623 
Epoch [4/5] Batch 2500/14335 Train_loss 1.7673863566181556 
Epoch [4/5] Batch 2600/14335 Train_loss 1.7652232021448568 
Epoch [4/5] Batch 2700/14335 Train_loss 1.7659531681709093 
Epoch [4/5] Batch 2800/14335 Train_loss 1.7680611137815434 
Epoch [4/5] Batch 2900/14335 Train_loss 1.7667773843289285 
Epoch [4/5] Batch 3000/14335 Train_loss 1.7644030195733817 
Epoch [4/5] Batch 3100/14335 Train_loss 1.7641525779619827 
Epoch [4/5] Batch 3200/14335 Train_loss 1.7642029133817063 
Epoch [4/5] Batch 3300/14335 Train_loss 1.7626336607737854 
Epoch [4/5] Batch 3400/14335 Train_loss 1.759044484576822 
Epoch [4/5] Batch 3500/14335 Train_loss 1.7576687299385476 
Epoch [4/5] Batch 3600/14335 Train_loss 1.7576361611853768 
Epoch [4/5] Batch 3700/14335 Train_loss 1.755316338585667 
Epoch [4/5] Batch 3800/14335 Train_loss 1.7559425680614151 
Epoch [4/5] Batch 3900/14335 Train_loss 1.75711907501772 
Epoch [4/5] Batch 4000/14335 Train_loss 1.7571705122592598 
Epoch [4/5] Batch 4100/14335 Train_loss 1.756178146272251 
Epoch [4/5] Batch 4200/14335 Train_loss 1.7545337168071078 
Epoch [4/5] Batch 4300/14335 Train_loss 1.753933558652385 
Epoch [4/5] Batch 4400/14335 Train_loss 1.7529703802993097 
Epoch [4/5] Batch 4500/14335 Train_loss 1.752948137552665 
Epoch [4/5] Batch 4600/14335 Train_loss 1.751414481651664 
Epoch [4/5] Batch 4700/14335 Train_loss 1.7515388391618778 
Epoch [4/5] Batch 4800/14335 Train_loss 1.75041842702105 
Epoch [4/5] Batch 4900/14335 Train_loss 1.7495977801495586 
Epoch [4/5] Batch 5000/14335 Train_loss 1.7493074965584852 
Epoch [4/5] Batch 5100/14335 Train_loss 1.751190486793669 
Epoch [4/5] Batch 5200/14335 Train_loss 1.7511188628005536 
Epoch [4/5] Batch 5300/14335 Train_loss 1.7527632423797952 
Epoch [4/5] Batch 5400/14335 Train_loss 1.7522176812352726 
Epoch [4/5] Batch 5500/14335 Train_loss 1.7517068538218168 
Epoch [4/5] Batch 5600/14335 Train_loss 1.7514212412164054 
Epoch [4/5] Batch 5700/14335 Train_loss 1.752491889443393 
Epoch [4/5] Batch 5800/14335 Train_loss 1.753158177522221 
Epoch [4/5] Batch 5900/14335 Train_loss 1.7520610395540546 
Epoch [4/5] Batch 6000/14335 Train_loss 1.7513829051586634 
Epoch [4/5] Batch 6100/14335 Train_loss 1.7508751003554348 
Epoch [4/5] Batch 6200/14335 Train_loss 1.7504957070013358 
Epoch [4/5] Batch 6300/14335 Train_loss 1.7501770276526027 
Epoch [4/5] Batch 6400/14335 Train_loss 1.7499448607287693 
Epoch [4/5] Batch 6500/14335 Train_loss 1.7490016782495577 
Epoch [4/5] Batch 6600/14335 Train_loss 1.749097196326854 
Epoch [4/5] Batch 6700/14335 Train_loss 1.7486593048530912 
Epoch [4/5] Batch 6800/14335 Train_loss 1.7476764939305818 
Epoch [4/5] Batch 6900/14335 Train_loss 1.748621348081646 
Epoch [4/5] Batch 7000/14335 Train_loss 1.748147937437923 
Epoch [4/5] Batch 7100/14335 Train_loss 1.7481419770709394 
Epoch [4/5] Batch 7200/14335 Train_loss 1.7492251791584543 
Epoch [4/5] Batch 7300/14335 Train_loss 1.7493848036885375 
Epoch [4/5] Batch 7400/14335 Train_loss 1.7504047051649967 
Epoch [4/5] Batch 7500/14335 Train_loss 1.7500185807964481 
Epoch [4/5] Batch 7600/14335 Train_loss 1.7502975202445026 
Epoch [4/5] Batch 7700/14335 Train_loss 1.7506473900869037 
Epoch [4/5] Batch 7800/14335 Train_loss 1.7509686791668364 
Epoch [4/5] Batch 7900/14335 Train_loss 1.750803078077908 
Epoch [4/5] Batch 8000/14335 Train_loss 1.7495015175977493 
Epoch [4/5] Batch 8100/14335 Train_loss 1.750165508923678 
Epoch [4/5] Batch 8200/14335 Train_loss 1.7489457218420024 
Epoch [4/5] Batch 8300/14335 Train_loss 1.747329486615901 
Epoch [4/5] Batch 8400/14335 Train_loss 1.7473792220251771 
Epoch [4/5] Batch 8500/14335 Train_loss 1.74798611516904 
Epoch [4/5] Batch 8600/14335 Train_loss 1.7474062668990984 
Epoch [4/5] Batch 8700/14335 Train_loss 1.747698294136486 
Epoch [4/5] Batch 8800/14335 Train_loss 1.7469098721596479 
Epoch [4/5] Batch 8900/14335 Train_loss 1.7471503647296043 
Epoch [4/5] Batch 9000/14335 Train_loss 1.7468079040587485 
Epoch [4/5] Batch 9100/14335 Train_loss 1.7465000707071217 
Epoch [4/5] Batch 9200/14335 Train_loss 1.74681717307412 
Epoch [4/5] Batch 9300/14335 Train_loss 1.7461597277381231 
Epoch [4/5] Batch 9400/14335 Train_loss 1.746445791351042 
Epoch [4/5] Batch 9500/14335 Train_loss 1.746944160605591 
Epoch [4/5] Batch 9600/14335 Train_loss 1.747364481755277 
Epoch [4/5] Batch 9700/14335 Train_loss 1.7475905856882747 
Epoch [4/5] Batch 9800/14335 Train_loss 1.7481855105134725 
Epoch [4/5] Batch 9900/14335 Train_loss 1.747947584485125 
Epoch [4/5] Batch 10000/14335 Train_loss 1.7478564423951741 
Epoch [4/5] Batch 10100/14335 Train_loss 1.7480620166546648 
Epoch [4/5] Batch 10200/14335 Train_loss 1.7477914105975538 
Epoch [4/5] Batch 10300/14335 Train_loss 1.7473973087375516 
Epoch [4/5] Batch 10400/14335 Train_loss 1.7476213172668391 
Epoch [4/5] Batch 10500/14335 Train_loss 1.7479479880967137 
Epoch [4/5] Batch 10600/14335 Train_loss 1.7473626523365189 
Epoch [4/5] Batch 10700/14335 Train_loss 1.7479421411943028 
Epoch [4/5] Batch 10800/14335 Train_loss 1.7480021544540991 
Epoch [4/5] Batch 10900/14335 Train_loss 1.747600990322361 
Epoch [4/5] Batch 11000/14335 Train_loss 1.7481398293368384 
Epoch [4/5] Batch 11100/14335 Train_loss 1.7483748114056152 
Epoch [4/5] Batch 11200/14335 Train_loss 1.7486958284356393 
Epoch [4/5] Batch 11300/14335 Train_loss 1.7484209523311696 
Epoch [4/5] Batch 11400/14335 Train_loss 1.7488364278113473 
Epoch [4/5] Batch 11500/14335 Train_loss 1.7492055933918966 
Epoch [4/5] Batch 11600/14335 Train_loss 1.74959819630956 
Epoch [4/5] Batch 11700/14335 Train_loss 1.7492307127496287 
Epoch [4/5] Batch 11800/14335 Train_loss 1.749413442723696 
Epoch [4/5] Batch 11900/14335 Train_loss 1.7489525064658231 
Epoch [4/5] Batch 12000/14335 Train_loss 1.748971809578676 
Epoch [4/5] Batch 12100/14335 Train_loss 1.7487886583229528 
Epoch [4/5] Batch 12200/14335 Train_loss 1.7483435735428894 
Epoch [4/5] Batch 12300/14335 Train_loss 1.749103372086331 
Epoch [4/5] Batch 12400/14335 Train_loss 1.7494230240291428 
Epoch [4/5] Batch 12500/14335 Train_loss 1.7501430758283658 
Epoch [4/5] Batch 12600/14335 Train_loss 1.7501920831286475 
Epoch [4/5] Batch 12700/14335 Train_loss 1.7504546147066584 
Epoch [4/5] Batch 12800/14335 Train_loss 1.7501907328500355 
Epoch [4/5] Batch 12900/14335 Train_loss 1.7502523464672732 
Epoch [4/5] Batch 13000/14335 Train_loss 1.7502372755737325 
Epoch [4/5] Batch 13100/14335 Train_loss 1.7498621842579736 
Epoch [4/5] Batch 13200/14335 Train_loss 1.7501646208384751 
Epoch [4/5] Batch 13300/14335 Train_loss 1.7495760928149617 
Epoch [4/5] Batch 13400/14335 Train_loss 1.7495041176383197 
Epoch [4/5] Batch 13500/14335 Train_loss 1.7494060488375114 
Epoch [4/5] Batch 13600/14335 Train_loss 1.7495678498755964 
Epoch [4/5] Batch 13700/14335 Train_loss 1.7487493917045824 
Epoch [4/5] Batch 13800/14335 Train_loss 1.7484020242805878 
Epoch [4/5] Batch 13900/14335 Train_loss 1.7484856595090075 
Epoch [4/5] Batch 14000/14335 Train_loss 1.7484719567168492 
Epoch [4/5] Batch 14100/14335 Train_loss 1.748426696671978 
Epoch [4/5] Batch 14200/14335 Train_loss 1.7482366253541277 
Epoch [4/5] Batch 14300/14335 Train_loss 1.7478996748414026 
Epoch: 4/5 	Training Loss: 1.747846 	Validation Loss: 1.746352 Duration seconds: 4862.641197919846 
Validation loss decreased (1.757591 --> 1.746352).  Saving model ... 
best_valid_loss_fold [1.7463520771104544] Best_Epoch [4]Fold: 1/5 
Epoch [0/5] Batch 0/14335 Train_loss 1.3505634665489197 
Epoch [0/5] Batch 100/14335 Train_loss 1.8085718966356599 
Epoch [0/5] Batch 200/14335 Train_loss 1.7901463758441347 
Epoch [0/5] Batch 300/14335 Train_loss 1.8045910695363516 
Epoch [0/5] Batch 400/14335 Train_loss 1.800264349193347 
Epoch [0/5] Batch 500/14335 Train_loss 1.8020202817317255 
Epoch [0/5] Batch 600/14335 Train_loss 1.7820341329705498 
Epoch [0/5] Batch 700/14335 Train_loss 1.7848515907002243 
Epoch [0/5] Batch 800/14335 Train_loss 1.7918810702292958 
Epoch [0/5] Batch 900/14335 Train_loss 1.7902197599510241 
Epoch [0/5] Batch 1000/14335 Train_loss 1.7852624676206132 
Epoch [0/5] Batch 1100/14335 Train_loss 1.7827654074366583 
Epoch [0/5] Batch 1200/14335 Train_loss 1.78266912394767 
Epoch [0/5] Batch 1300/14335 Train_loss 1.7882578571446577 
Epoch [0/5] Batch 1400/14335 Train_loss 1.7877050203608242 
Epoch [0/5] Batch 1500/14335 Train_loss 1.787129842653265 
Epoch [0/5] Batch 1600/14335 Train_loss 1.784967841542117 
Epoch [0/5] Batch 1700/14335 Train_loss 1.7864335431054297 
Epoch [0/5] Batch 1800/14335 Train_loss 1.7863554097319032 
Epoch [0/5] Batch 1900/14335 Train_loss 1.7814566210100427 
Epoch [0/5] Batch 2000/14335 Train_loss 1.780808598812165 
Epoch [0/5] Batch 2100/14335 Train_loss 1.782058110883524 
Epoch [0/5] Batch 2200/14335 Train_loss 1.7861731649833015 
Epoch [0/5] Batch 2300/14335 Train_loss 1.7844596332419131 
Epoch [0/5] Batch 2400/14335 Train_loss 1.7821664135221986 
Epoch [0/5] Batch 2500/14335 Train_loss 1.779215950153914 
Epoch [0/5] Batch 2600/14335 Train_loss 1.7775672756963306 
Epoch [0/5] Batch 2700/14335 Train_loss 1.773194604226061 
Epoch [0/5] Batch 2800/14335 Train_loss 1.772324082197908 
Epoch [0/5] Batch 2900/14335 Train_loss 1.7710910105460762 
Epoch [0/5] Batch 3000/14335 Train_loss 1.7710410197777813 
Epoch [0/5] Batch 3100/14335 Train_loss 1.7715233169863662 
Epoch [0/5] Batch 3200/14335 Train_loss 1.7721823168588555 
Epoch [0/5] Batch 3300/14335 Train_loss 1.7684734153390038 
Epoch [0/5] Batch 3400/14335 Train_loss 1.7689896183911578 
Epoch [0/5] Batch 3500/14335 Train_loss 1.7687926311934379 
Epoch [0/5] Batch 3600/14335 Train_loss 1.770436767518719 
Epoch [0/5] Batch 3700/14335 Train_loss 1.7689703487542248 
Epoch [0/5] Batch 3800/14335 Train_loss 1.7681182051894384 
Epoch [0/5] Batch 3900/14335 Train_loss 1.7653962851269709 
Epoch [0/5] Batch 4000/14335 Train_loss 1.7651717025778257 
Epoch [0/5] Batch 4100/14335 Train_loss 1.765270137619359 
Epoch [0/5] Batch 4200/14335 Train_loss 1.764653652393869 
Epoch [0/5] Batch 4300/14335 Train_loss 1.7644259482674116 
Epoch [0/5] Batch 4400/14335 Train_loss 1.7668736395162632 
Epoch [0/5] Batch 4500/14335 Train_loss 1.7656583776145054 
Epoch [0/5] Batch 4600/14335 Train_loss 1.7654252979378937 
Epoch [0/5] Batch 4700/14335 Train_loss 1.7645516318828343 
Epoch [0/5] Batch 4800/14335 Train_loss 1.7641736707155269 
Epoch [0/5] Batch 4900/14335 Train_loss 1.76387516931049 
Epoch [0/5] Batch 5000/14335 Train_loss 1.7654277407969268 
Epoch [0/5] Batch 5100/14335 Train_loss 1.764812270430251 
Epoch [0/5] Batch 5200/14335 Train_loss 1.7651836864451127 
Epoch [0/5] Batch 5300/14335 Train_loss 1.7650187702684712 
Epoch [0/5] Batch 5400/14335 Train_loss 1.7651398897507613 
Epoch [0/5] Batch 5500/14335 Train_loss 1.765243334540279 
Epoch [0/5] Batch 5600/14335 Train_loss 1.7654605654055489 
Epoch [0/5] Batch 5700/14335 Train_loss 1.7654912705194885 
Epoch [0/5] Batch 5800/14335 Train_loss 1.7657732389901983 
Epoch [0/5] Batch 5900/14335 Train_loss 1.7659546796297485 
Epoch [0/5] Batch 6000/14335 Train_loss 1.7645394860446662 
Epoch [0/5] Batch 6100/14335 Train_loss 1.7637938151123522 
Epoch [0/5] Batch 6200/14335 Train_loss 1.7641727728572436 
Epoch [0/5] Batch 6300/14335 Train_loss 1.7638925782930583 
Epoch [0/5] Batch 6400/14335 Train_loss 1.7630592226013693 
Epoch [0/5] Batch 6500/14335 Train_loss 1.7618779202018073 
Epoch [0/5] Batch 6600/14335 Train_loss 1.7617652618289987 
Epoch [0/5] Batch 6700/14335 Train_loss 1.761692319565114 
Epoch [0/5] Batch 6800/14335 Train_loss 1.763696868085998 
Epoch [0/5] Batch 6900/14335 Train_loss 1.764311022714262 
Epoch [0/5] Batch 7000/14335 Train_loss 1.763495976644624 
Epoch [0/5] Batch 7100/14335 Train_loss 1.7645653392114935 
Epoch [0/5] Batch 7200/14335 Train_loss 1.765264723076951 
Epoch [0/5] Batch 7300/14335 Train_loss 1.76615679783803 
Epoch [0/5] Batch 7400/14335 Train_loss 1.766014566768095 
Epoch [0/5] Batch 7500/14335 Train_loss 1.7662483228624082 
Epoch [0/5] Batch 7600/14335 Train_loss 1.7659439688526146 
Epoch [0/5] Batch 7700/14335 Train_loss 1.765663582807918 
Epoch [0/5] Batch 7800/14335 Train_loss 1.765052545307126 
Epoch [0/5] Batch 7900/14335 Train_loss 1.7648711142696816 
Epoch [0/5] Batch 8000/14335 Train_loss 1.7641468598801722 
Epoch [0/5] Batch 8100/14335 Train_loss 1.765897504786675 
Epoch [0/5] Batch 8200/14335 Train_loss 1.7656839271597842 
Epoch [0/5] Batch 8300/14335 Train_loss 1.7657280210107151 
Epoch [0/5] Batch 8400/14335 Train_loss 1.7659629259465592 
Epoch [0/5] Batch 8500/14335 Train_loss 1.76618628021132 
Epoch [0/5] Batch 8600/14335 Train_loss 1.7651494404236296 
Epoch [0/5] Batch 8700/14335 Train_loss 1.7654855435491705 
Epoch [0/5] Batch 8800/14335 Train_loss 1.766081166752813 
Epoch [0/5] Batch 8900/14335 Train_loss 1.7657030278011367 
Epoch [0/5] Batch 9000/14335 Train_loss 1.7655583671168438 
Epoch [0/5] Batch 9100/14335 Train_loss 1.7659609855480436 
Epoch [0/5] Batch 9200/14335 Train_loss 1.7667136852573913 
Epoch [0/5] Batch 9300/14335 Train_loss 1.766686622622532 
Epoch [0/5] Batch 9400/14335 Train_loss 1.7659484310660727 
Epoch [0/5] Batch 9500/14335 Train_loss 1.7667732414482782 
Epoch [0/5] Batch 9600/14335 Train_loss 1.766407479746536 
Epoch [0/5] Batch 9700/14335 Train_loss 1.7658199727613586 
Epoch [0/5] Batch 9800/14335 Train_loss 1.7671003395974874 
Epoch [0/5] Batch 9900/14335 Train_loss 1.7670018426940761 
Epoch [0/5] Batch 10000/14335 Train_loss 1.7664229808418634 
Epoch [0/5] Batch 10100/14335 Train_loss 1.7663781338510283 
Epoch [0/5] Batch 10200/14335 Train_loss 1.766253841775952 
Epoch [0/5] Batch 10300/14335 Train_loss 1.7660456311810064 
Epoch [0/5] Batch 10400/14335 Train_loss 1.7659483921456516 
Epoch [0/5] Batch 10500/14335 Train_loss 1.7655236728800874 
Epoch [0/5] Batch 10600/14335 Train_loss 1.7656934507800526 
Epoch [0/5] Batch 10700/14335 Train_loss 1.765848050062294 
Epoch [0/5] Batch 10800/14335 Train_loss 1.7659682332820974 
Epoch [0/5] Batch 10900/14335 Train_loss 1.7649532393893674 
Epoch [0/5] Batch 11000/14335 Train_loss 1.7656685453310912 
Epoch [0/5] Batch 11100/14335 Train_loss 1.7658495665289198 
Epoch [0/5] Batch 11200/14335 Train_loss 1.7653944708141522 
Epoch [0/5] Batch 11300/14335 Train_loss 1.7652683920315089 
Epoch [0/5] Batch 11400/14335 Train_loss 1.7656100022701064 
Epoch [0/5] Batch 11500/14335 Train_loss 1.7655610160022888 
Epoch [0/5] Batch 11600/14335 Train_loss 1.76450539372284 
Epoch [0/5] Batch 11700/14335 Train_loss 1.7639896706091769 
Epoch [0/5] Batch 11800/14335 Train_loss 1.7638359074950793 
Epoch [0/5] Batch 11900/14335 Train_loss 1.7635201098022215 
Epoch [0/5] Batch 12000/14335 Train_loss 1.7632653323829337 
Epoch [0/5] Batch 12100/14335 Train_loss 1.7638241707830427 
Epoch [0/5] Batch 12200/14335 Train_loss 1.7635222307042493 
Epoch [0/5] Batch 12300/14335 Train_loss 1.7644226327647514 
Epoch [0/5] Batch 12400/14335 Train_loss 1.76474653197932 
Epoch [0/5] Batch 12500/14335 Train_loss 1.7651127139549667 
Epoch [0/5] Batch 12600/14335 Train_loss 1.7645018867620323 
Epoch [0/5] Batch 12700/14335 Train_loss 1.7644169310904303 
Epoch [0/5] Batch 12800/14335 Train_loss 1.7643229531512885 
Epoch [0/5] Batch 12900/14335 Train_loss 1.7639584745063948 
Epoch [0/5] Batch 13000/14335 Train_loss 1.7637570691328994 
Epoch [0/5] Batch 13100/14335 Train_loss 1.7641208755373772 
Epoch [0/5] Batch 13200/14335 Train_loss 1.7642678037109714 
Epoch [0/5] Batch 13300/14335 Train_loss 1.7643091950668364 
Epoch [0/5] Batch 13400/14335 Train_loss 1.764516055483323 
Epoch [0/5] Batch 13500/14335 Train_loss 1.7645846863132602 
Epoch [0/5] Batch 13600/14335 Train_loss 1.764620563071354 
Epoch [0/5] Batch 13700/14335 Train_loss 1.7643977854607245 
Epoch [0/5] Batch 13800/14335 Train_loss 1.765216299423847 
Epoch [0/5] Batch 13900/14335 Train_loss 1.7646792326834029 
Epoch [0/5] Batch 14000/14335 Train_loss 1.7641990791489275 
Epoch [0/5] Batch 14100/14335 Train_loss 1.7637705223372107 
Epoch [0/5] Batch 14200/14335 Train_loss 1.7639499250976487 
Epoch [0/5] Batch 14300/14335 Train_loss 1.7638791414481403 
Epoch: 0/5 	Training Loss: 1.763695 	Validation Loss: 1.733206 Duration seconds: 4012.150903701782 
Validation loss decreased (inf --> 1.733206).  Saving model ... 
best_valid_loss_fold [1.733205638015144] Best_Epoch [0]Epoch [1/5] Batch 0/14335 Train_loss 2.4216338992118835 
Epoch [1/5] Batch 100/14335 Train_loss 1.726505700314399 
Epoch [1/5] Batch 200/14335 Train_loss 1.6717504359670539 
Epoch [1/5] Batch 300/14335 Train_loss 1.670330792937762 
Epoch [1/5] Batch 400/14335 Train_loss 1.6774006831712853 
Epoch [1/5] Batch 500/14335 Train_loss 1.6795875376718725 
Epoch [1/5] Batch 600/14335 Train_loss 1.6887516626923929 
Epoch [1/5] Batch 700/14335 Train_loss 1.6922361934597414 
Epoch [1/5] Batch 800/14335 Train_loss 1.7037753758489267 
Epoch [1/5] Batch 900/14335 Train_loss 1.7204530200984052 
Epoch [1/5] Batch 1000/14335 Train_loss 1.720168870965858 
Epoch [1/5] Batch 1100/14335 Train_loss 1.727157773299449 
Epoch [1/5] Batch 1200/14335 Train_loss 1.7355690893099072 
Epoch [1/5] Batch 1300/14335 Train_loss 1.7342371691439264 
Epoch [1/5] Batch 1400/14335 Train_loss 1.7380127455935488 
Epoch [1/5] Batch 1500/14335 Train_loss 1.7372293053548546 
Epoch [1/5] Batch 1600/14335 Train_loss 1.7389875117556741 
Epoch [1/5] Batch 1700/14335 Train_loss 1.7411599167650549 
Epoch [1/5] Batch 1800/14335 Train_loss 1.7397441120734485 
Epoch [1/5] Batch 1900/14335 Train_loss 1.7404470420484164 
Epoch [1/5] Batch 2000/14335 Train_loss 1.7392175150723352 
Epoch [1/5] Batch 2100/14335 Train_loss 1.743317734093708 
Epoch [1/5] Batch 2200/14335 Train_loss 1.7432962697691563 
Epoch [1/5] Batch 2300/14335 Train_loss 1.7445332109960512 
Epoch [1/5] Batch 2400/14335 Train_loss 1.7463757308888117 
Epoch [1/5] Batch 2500/14335 Train_loss 1.7448284810499066 
Epoch [1/5] Batch 2600/14335 Train_loss 1.7445798212091586 
Epoch [1/5] Batch 2700/14335 Train_loss 1.7457963790370772 
Epoch [1/5] Batch 2800/14335 Train_loss 1.74433737837632 
Epoch [1/5] Batch 2900/14335 Train_loss 1.7453025794956898 
Epoch [1/5] Batch 3000/14335 Train_loss 1.745040539822174 
Epoch [1/5] Batch 3100/14335 Train_loss 1.7475448038593602 
Epoch [1/5] Batch 3200/14335 Train_loss 1.7457514394613514 
Epoch [1/5] Batch 3300/14335 Train_loss 1.7450759267692348 
Epoch [1/5] Batch 3400/14335 Train_loss 1.7441958912052116 
Epoch [1/5] Batch 3500/14335 Train_loss 1.7456146743030454 
Epoch [1/5] Batch 3600/14335 Train_loss 1.744404476755644 
Epoch [1/5] Batch 3700/14335 Train_loss 1.7439614014810274 
Epoch [1/5] Batch 3800/14335 Train_loss 1.7438746084059988 
Epoch [1/5] Batch 3900/14335 Train_loss 1.7440104752805745 
Epoch [1/5] Batch 4000/14335 Train_loss 1.7434469862871098 
Epoch [1/5] Batch 4100/14335 Train_loss 1.7445277035239992 
Epoch [1/5] Batch 4200/14335 Train_loss 1.7445516495765234 
Epoch [1/5] Batch 4300/14335 Train_loss 1.7447120481588845 
Epoch [1/5] Batch 4400/14335 Train_loss 1.7471031060027984 
Epoch [1/5] Batch 4500/14335 Train_loss 1.745793154892313 
Epoch [1/5] Batch 4600/14335 Train_loss 1.7461306036532354 
Epoch [1/5] Batch 4700/14335 Train_loss 1.745844284130763 
Epoch [1/5] Batch 4800/14335 Train_loss 1.7464626506064067 
Epoch [1/5] Batch 4900/14335 Train_loss 1.748202431455203 
Epoch [1/5] Batch 5000/14335 Train_loss 1.7484644880502302 
Epoch [1/5] Batch 5100/14335 Train_loss 1.7475963454095436 
Epoch [1/5] Batch 5200/14335 Train_loss 1.74787357987446 
Epoch [1/5] Batch 5300/14335 Train_loss 1.7492529306644382 
Epoch [1/5] Batch 5400/14335 Train_loss 1.7507136766046114 
Epoch [1/5] Batch 5500/14335 Train_loss 1.749792636934735 
Epoch [1/5] Batch 5600/14335 Train_loss 1.748241274435538 
Epoch [1/5] Batch 5700/14335 Train_loss 1.7476870240524367 
Epoch [1/5] Batch 5800/14335 Train_loss 1.7480507409856703 
Epoch [1/5] Batch 5900/14335 Train_loss 1.7475904164865166 
Epoch [1/5] Batch 6000/14335 Train_loss 1.7493716558825472 
Epoch [1/5] Batch 6100/14335 Train_loss 1.749614146222855 
Epoch [1/5] Batch 6200/14335 Train_loss 1.7496395196631693 
Epoch [1/5] Batch 6300/14335 Train_loss 1.7492657374141898 
Epoch [1/5] Batch 6400/14335 Train_loss 1.7494937392477505 
Epoch [1/5] Batch 6500/14335 Train_loss 1.7492481333703156 
Epoch [1/5] Batch 6600/14335 Train_loss 1.7490847680337898 
Epoch [1/5] Batch 6700/14335 Train_loss 1.7489293840356752 
Epoch [1/5] Batch 6800/14335 Train_loss 1.749327836379928 
Epoch [1/5] Batch 6900/14335 Train_loss 1.7492031789328237 
Epoch [1/5] Batch 7000/14335 Train_loss 1.750246740615831 
Epoch [1/5] Batch 7100/14335 Train_loss 1.7498090296066693 
Epoch [1/5] Batch 7200/14335 Train_loss 1.749609707389221 
Epoch [1/5] Batch 7300/14335 Train_loss 1.749835975489589 
Epoch [1/5] Batch 7400/14335 Train_loss 1.7495077538270432 
Epoch [1/5] Batch 7500/14335 Train_loss 1.748942499827614 
Epoch [1/5] Batch 7600/14335 Train_loss 1.7486127814918329 
Epoch [1/5] Batch 7700/14335 Train_loss 1.7477520648523084 
Epoch [1/5] Batch 7800/14335 Train_loss 1.746861599189947 
Epoch [1/5] Batch 7900/14335 Train_loss 1.7479411824083588 
Epoch [1/5] Batch 8000/14335 Train_loss 1.7485017126078994 
Epoch [1/5] Batch 8100/14335 Train_loss 1.748835464674828 
Epoch [1/5] Batch 8200/14335 Train_loss 1.74851959294378 
Epoch [1/5] Batch 8300/14335 Train_loss 1.7483618425728398 
Epoch [1/5] Batch 8400/14335 Train_loss 1.7481550627603457 
Epoch [1/5] Batch 8500/14335 Train_loss 1.747452810787058 
Epoch [1/5] Batch 8600/14335 Train_loss 1.7483084395470667 
Epoch [1/5] Batch 8700/14335 Train_loss 1.7477888281698708 
Epoch [1/5] Batch 8800/14335 Train_loss 1.747985965085631 
Epoch [1/5] Batch 8900/14335 Train_loss 1.748141981096311 
Epoch [1/5] Batch 9000/14335 Train_loss 1.7476544547823982 
Epoch [1/5] Batch 9100/14335 Train_loss 1.74822144725682 
Epoch [1/5] Batch 9200/14335 Train_loss 1.749061378926191 
Epoch [1/5] Batch 9300/14335 Train_loss 1.7490134472358856 
Epoch [1/5] Batch 9400/14335 Train_loss 1.7490122458442718 
Epoch [1/5] Batch 9500/14335 Train_loss 1.7485312272736417 
Epoch [1/5] Batch 9600/14335 Train_loss 1.7483789625445414 
Epoch [1/5] Batch 9700/14335 Train_loss 1.7482795462445455 
Epoch [1/5] Batch 9800/14335 Train_loss 1.7487051778827112 
Epoch [1/5] Batch 9900/14335 Train_loss 1.749195990932161 
Epoch [1/5] Batch 10000/14335 Train_loss 1.74907177360016 
Epoch [1/5] Batch 10100/14335 Train_loss 1.7493286571268951 
Epoch [1/5] Batch 10200/14335 Train_loss 1.7493126490505322 
Epoch [1/5] Batch 10300/14335 Train_loss 1.7487041524253115 
Epoch [1/5] Batch 10400/14335 Train_loss 1.7487498047649603 
Epoch [1/5] Batch 10500/14335 Train_loss 1.7489031773940709 
Epoch [1/5] Batch 10600/14335 Train_loss 1.748359763681883 
Epoch [1/5] Batch 10700/14335 Train_loss 1.7491871489368747 
Epoch [1/5] Batch 10800/14335 Train_loss 1.7498178056611715 
Epoch [1/5] Batch 10900/14335 Train_loss 1.749118315376346 
Epoch [1/5] Batch 11000/14335 Train_loss 1.7496015064153505 
Epoch [1/5] Batch 11100/14335 Train_loss 1.7497986595738408 
Epoch [1/5] Batch 11200/14335 Train_loss 1.7507350237426635 
Epoch [1/5] Batch 11300/14335 Train_loss 1.7506080359957585 
Epoch [1/5] Batch 11400/14335 Train_loss 1.7503669690290111 
Epoch [1/5] Batch 11500/14335 Train_loss 1.7503859702477962 
Epoch [1/5] Batch 11600/14335 Train_loss 1.7505425453229708 
Epoch [1/5] Batch 11700/14335 Train_loss 1.7508871795280236 
Epoch [1/5] Batch 11800/14335 Train_loss 1.7508067475702387 
Epoch [1/5] Batch 11900/14335 Train_loss 1.7502361413383472 
Epoch [1/5] Batch 12000/14335 Train_loss 1.7500765621848389 
Epoch [1/5] Batch 12100/14335 Train_loss 1.7491552900344702 
Epoch [1/5] Batch 12200/14335 Train_loss 1.7492436629612176 
Epoch [1/5] Batch 12300/14335 Train_loss 1.7498291500833991 
Epoch [1/5] Batch 12400/14335 Train_loss 1.7496488141264708 
Epoch [1/5] Batch 12500/14335 Train_loss 1.7500346680807644 
Epoch [1/5] Batch 12600/14335 Train_loss 1.7509081724724564 
Epoch [1/5] Batch 12700/14335 Train_loss 1.7505267474490322 
Epoch [1/5] Batch 12800/14335 Train_loss 1.7504106337709051 
Epoch [1/5] Batch 12900/14335 Train_loss 1.7501341062412041 
Epoch [1/5] Batch 13000/14335 Train_loss 1.7499529673294483 
Epoch [1/5] Batch 13100/14335 Train_loss 1.7499123137416106 
Epoch [1/5] Batch 13200/14335 Train_loss 1.750590620319321 
Epoch [1/5] Batch 13300/14335 Train_loss 1.7501694688701055 
Epoch [1/5] Batch 13400/14335 Train_loss 1.750443060170398 
Epoch [1/5] Batch 13500/14335 Train_loss 1.7503819523841246 
Epoch [1/5] Batch 13600/14335 Train_loss 1.7504488107297151 
Epoch [1/5] Batch 13700/14335 Train_loss 1.7501702688813305 
Epoch [1/5] Batch 13800/14335 Train_loss 1.749971134669236 
Epoch [1/5] Batch 13900/14335 Train_loss 1.7496446123603016 
Epoch [1/5] Batch 14000/14335 Train_loss 1.749958544966898 
Epoch [1/5] Batch 14100/14335 Train_loss 1.7496264649283106 
Epoch [1/5] Batch 14200/14335 Train_loss 1.7494548356510595 
Epoch [1/5] Batch 14300/14335 Train_loss 1.7497242832554152 
Epoch: 1/5 	Training Loss: 1.749627 	Validation Loss: 1.737568 Duration seconds: 4018.6537125110626 
best_valid_loss_fold [1.733205638015144] Best_Epoch [1]Epoch [2/5] Batch 0/14335 Train_loss 1.5889883041381836 
Epoch [2/5] Batch 100/14335 Train_loss 1.7806747599993602 
Epoch [2/5] Batch 200/14335 Train_loss 1.7401827690168399 
Epoch [2/5] Batch 300/14335 Train_loss 1.7648894946242488 
Epoch [2/5] Batch 400/14335 Train_loss 1.7679639049153077 
Epoch [2/5] Batch 500/14335 Train_loss 1.7569816583942273 
Epoch [2/5] Batch 600/14335 Train_loss 1.758466544196927 
Epoch [2/5] Batch 700/14335 Train_loss 1.7485957128260172 
Epoch [2/5] Batch 800/14335 Train_loss 1.753629239813219 
Epoch [2/5] Batch 900/14335 Train_loss 1.7586057399969122 
Epoch [2/5] Batch 1000/14335 Train_loss 1.7532302560163784 
Epoch [2/5] Batch 1100/14335 Train_loss 1.7489675483535247 
Epoch [2/5] Batch 1200/14335 Train_loss 1.7442194798916306 
Epoch [2/5] Batch 1300/14335 Train_loss 1.7413932436949744 
Epoch [2/5] Batch 1400/14335 Train_loss 1.744376753964099 
Epoch [2/5] Batch 1500/14335 Train_loss 1.7443969746745085 
Epoch [2/5] Batch 1600/14335 Train_loss 1.7443175629004697 
Epoch [2/5] Batch 1700/14335 Train_loss 1.7446879414663043 
Epoch [2/5] Batch 1800/14335 Train_loss 1.7468572776353009 
Epoch [2/5] Batch 1900/14335 Train_loss 1.7457941023418302 
Epoch [2/5] Batch 2000/14335 Train_loss 1.7464688963357775 
Epoch [2/5] Batch 2100/14335 Train_loss 1.7468993674816544 
Epoch [2/5] Batch 2200/14335 Train_loss 1.7447966290659007 
Epoch [2/5] Batch 2300/14335 Train_loss 1.7447209809750954 
Epoch [2/5] Batch 2400/14335 Train_loss 1.7435320036354685 
Epoch [2/5] Batch 2500/14335 Train_loss 1.7440621430327634 
Epoch [2/5] Batch 2600/14335 Train_loss 1.7432307399829412 
Epoch [2/5] Batch 2700/14335 Train_loss 1.743423623032523 
Epoch [2/5] Batch 2800/14335 Train_loss 1.7414384964096763 
Epoch [2/5] Batch 2900/14335 Train_loss 1.743244160735907 
Epoch [2/5] Batch 3000/14335 Train_loss 1.740585142788153 
Epoch [2/5] Batch 3100/14335 Train_loss 1.737395997745727 
Epoch [2/5] Batch 3200/14335 Train_loss 1.735153959535111 
Epoch [2/5] Batch 3300/14335 Train_loss 1.73539399916757 
Epoch [2/5] Batch 3400/14335 Train_loss 1.7365391714888894 
Epoch [2/5] Batch 3500/14335 Train_loss 1.7375041958039332 
Epoch [2/5] Batch 3600/14335 Train_loss 1.7369875008221203 
Epoch [2/5] Batch 3700/14335 Train_loss 1.7379452695506903 
Epoch [2/5] Batch 3800/14335 Train_loss 1.7381355588948435 
Epoch [2/5] Batch 3900/14335 Train_loss 1.7368707877971277 
Epoch [2/5] Batch 4000/14335 Train_loss 1.736035450903796 
Epoch [2/5] Batch 4100/14335 Train_loss 1.7358648628486972 
Epoch [2/5] Batch 4200/14335 Train_loss 1.7364663365315862 
Epoch [2/5] Batch 4300/14335 Train_loss 1.7378460104241396 
Epoch [2/5] Batch 4400/14335 Train_loss 1.7402590269430662 
Epoch [2/5] Batch 4500/14335 Train_loss 1.7393558651417447 
Epoch [2/5] Batch 4600/14335 Train_loss 1.739531978956709 
Epoch [2/5] Batch 4700/14335 Train_loss 1.7397481725776838 
Epoch [2/5] Batch 4800/14335 Train_loss 1.7373294190000654 
Epoch [2/5] Batch 4900/14335 Train_loss 1.7396048338005576 
Epoch [2/5] Batch 5000/14335 Train_loss 1.739979623814114 
Epoch [2/5] Batch 5100/14335 Train_loss 1.739488515796217 
Epoch [2/5] Batch 5200/14335 Train_loss 1.7396878665630071 
Epoch [2/5] Batch 5300/14335 Train_loss 1.7399413283184169 
Epoch [2/5] Batch 5400/14335 Train_loss 1.738326540439245 
Epoch [2/5] Batch 5500/14335 Train_loss 1.7391885770662572 
Epoch [2/5] Batch 5600/14335 Train_loss 1.7395102423980733 
Epoch [2/5] Batch 5700/14335 Train_loss 1.7383617568820573 
Epoch [2/5] Batch 5800/14335 Train_loss 1.7384170705458661 
Epoch [2/5] Batch 5900/14335 Train_loss 1.7374736738230714 
Epoch [2/5] Batch 6000/14335 Train_loss 1.7374759273399634 
Epoch [2/5] Batch 6100/14335 Train_loss 1.7382500585003127 
Epoch [2/5] Batch 6200/14335 Train_loss 1.7378576153520133 
Epoch [2/5] Batch 6300/14335 Train_loss 1.7384073991666065 
Epoch [2/5] Batch 6400/14335 Train_loss 1.7378916106786397 
Epoch [2/5] Batch 6500/14335 Train_loss 1.7378138577334332 
Epoch [2/5] Batch 6600/14335 Train_loss 1.7379093507310148 
Epoch [2/5] Batch 6700/14335 Train_loss 1.7392862531907023 
Epoch [2/5] Batch 6800/14335 Train_loss 1.739127435060726 
Epoch [2/5] Batch 6900/14335 Train_loss 1.7390919756805563 
Epoch [2/5] Batch 7000/14335 Train_loss 1.7384331724785376 
Epoch [2/5] Batch 7100/14335 Train_loss 1.739487929791401 
Epoch [2/5] Batch 7200/14335 Train_loss 1.7404125790296536 
Epoch [2/5] Batch 7300/14335 Train_loss 1.7396407965976333 
Epoch [2/5] Batch 7400/14335 Train_loss 1.7412988448014952 
Epoch [2/5] Batch 7500/14335 Train_loss 1.7409506896772697 
Epoch [2/5] Batch 7600/14335 Train_loss 1.7401613435052348 
Epoch [2/5] Batch 7700/14335 Train_loss 1.740706059402064 
Epoch [2/5] Batch 7800/14335 Train_loss 1.7416472516504102 
Epoch [2/5] Batch 7900/14335 Train_loss 1.7410693471359462 
Epoch [2/5] Batch 8000/14335 Train_loss 1.7406573132427317 
Epoch [2/5] Batch 8100/14335 Train_loss 1.7397936215766079 
Epoch [2/5] Batch 8200/14335 Train_loss 1.740004138578374 
Epoch [2/5] Batch 8300/14335 Train_loss 1.739643863874083 
Epoch [2/5] Batch 8400/14335 Train_loss 1.7391126172712639 
Epoch [2/5] Batch 8500/14335 Train_loss 1.739839727851962 
Epoch [2/5] Batch 8600/14335 Train_loss 1.7393290574992968 
Epoch [2/5] Batch 8700/14335 Train_loss 1.739980376385167 
Epoch [2/5] Batch 8800/14335 Train_loss 1.7405357305796467 
Epoch [2/5] Batch 8900/14335 Train_loss 1.740276842695008 
Epoch [2/5] Batch 9000/14335 Train_loss 1.740148808281927 
Epoch [2/5] Batch 9100/14335 Train_loss 1.7394845196382709 
Epoch [2/5] Batch 9200/14335 Train_loss 1.7391233980200587 
Epoch [2/5] Batch 9300/14335 Train_loss 1.738704724703735 
Epoch [2/5] Batch 9400/14335 Train_loss 1.738266080848531 
Epoch [2/5] Batch 9500/14335 Train_loss 1.7369146937767703 
Epoch [2/5] Batch 9600/14335 Train_loss 1.7368668465122445 
Epoch [2/5] Batch 9700/14335 Train_loss 1.7369466258886672 
Epoch [2/5] Batch 9800/14335 Train_loss 1.7372816084862157 
Epoch [2/5] Batch 9900/14335 Train_loss 1.7380976375824886 
Epoch [2/5] Batch 10000/14335 Train_loss 1.7380039398893214 
Epoch [2/5] Batch 10100/14335 Train_loss 1.7380884617792771 
Epoch [2/5] Batch 10200/14335 Train_loss 1.7383032436486716 
Epoch [2/5] Batch 10300/14335 Train_loss 1.7379891936670067 
Epoch [2/5] Batch 10400/14335 Train_loss 1.7372297834894734 
Epoch [2/5] Batch 10500/14335 Train_loss 1.7372999796050523 
Epoch [2/5] Batch 10600/14335 Train_loss 1.7370664359647288 
Epoch [2/5] Batch 10700/14335 Train_loss 1.7368450281507455 
Epoch [2/5] Batch 10800/14335 Train_loss 1.736094156998764 
Epoch [2/5] Batch 10900/14335 Train_loss 1.7362465856224503 
Epoch [2/5] Batch 11000/14335 Train_loss 1.7365797334561868 
Epoch [2/5] Batch 11100/14335 Train_loss 1.7361697341997433 
Epoch [2/5] Batch 11200/14335 Train_loss 1.7356253914191153 
Epoch [2/5] Batch 11300/14335 Train_loss 1.7358812886610746 
Epoch [2/5] Batch 11400/14335 Train_loss 1.7360293558351816 
Epoch [2/5] Batch 11500/14335 Train_loss 1.7371317367839114 
Epoch [2/5] Batch 11600/14335 Train_loss 1.7371446259191978 
Epoch [2/5] Batch 11700/14335 Train_loss 1.7359742842555432 
Epoch [2/5] Batch 11800/14335 Train_loss 1.7361804436263761 
Epoch [2/5] Batch 11900/14335 Train_loss 1.736163741658314 
Epoch [2/5] Batch 12000/14335 Train_loss 1.7360734941592892 
Epoch [2/5] Batch 12100/14335 Train_loss 1.7362157110998813 
Epoch [2/5] Batch 12200/14335 Train_loss 1.7356674889365618 
Epoch [2/5] Batch 12300/14335 Train_loss 1.73576609866218 
Epoch [2/5] Batch 12400/14335 Train_loss 1.7358435899933666 
Epoch [2/5] Batch 12500/14335 Train_loss 1.735294486446153 
Epoch [2/5] Batch 12600/14335 Train_loss 1.735195031372004 
Epoch [2/5] Batch 12700/14335 Train_loss 1.7347628218571687 
Epoch [2/5] Batch 12800/14335 Train_loss 1.7351533026323822 
Epoch [2/5] Batch 12900/14335 Train_loss 1.7347384157806633 
Epoch [2/5] Batch 13000/14335 Train_loss 1.7346611342084617 
Epoch [2/5] Batch 13100/14335 Train_loss 1.7347299268685463 
Epoch [2/5] Batch 13200/14335 Train_loss 1.7342679210006626 
Epoch [2/5] Batch 13300/14335 Train_loss 1.7345955761487157 
Epoch [2/5] Batch 13400/14335 Train_loss 1.7346982476829318 
Epoch [2/5] Batch 13500/14335 Train_loss 1.7351848075055836 
Epoch [2/5] Batch 13600/14335 Train_loss 1.7349853288442822 
Epoch [2/5] Batch 13700/14335 Train_loss 1.7351617800755255 
Epoch [2/5] Batch 13800/14335 Train_loss 1.734758597848515 
Epoch [2/5] Batch 13900/14335 Train_loss 1.7346156086151219 
Epoch [2/5] Batch 14000/14335 Train_loss 1.7342009896456527 
Epoch [2/5] Batch 14100/14335 Train_loss 1.733996868749099 
Epoch [2/5] Batch 14200/14335 Train_loss 1.7346474112709738 
Epoch [2/5] Batch 14300/14335 Train_loss 1.734932007668056 
Epoch: 2/5 	Training Loss: 1.734785 	Validation Loss: 1.729155 Duration seconds: 4018.2840733528137 
Validation loss decreased (1.733206 --> 1.729155).  Saving model ... 
best_valid_loss_fold [1.7291552743772627] Best_Epoch [2]Epoch [3/5] Batch 0/14335 Train_loss 2.4101583659648895 
Epoch [3/5] Batch 100/14335 Train_loss 1.7684611508456787 
Epoch [3/5] Batch 200/14335 Train_loss 1.7667382729439 
Epoch [3/5] Batch 300/14335 Train_loss 1.7667041610047667 
Epoch [3/5] Batch 400/14335 Train_loss 1.7300981275755865 
Epoch [3/5] Batch 500/14335 Train_loss 1.7214549019070204 
Epoch [3/5] Batch 600/14335 Train_loss 1.719216168571431 
Epoch [3/5] Batch 700/14335 Train_loss 1.730342693467453 
Epoch [3/5] Batch 800/14335 Train_loss 1.7272290486037805 
Epoch [3/5] Batch 900/14335 Train_loss 1.7324604747298025 
Epoch [3/5] Batch 1000/14335 Train_loss 1.7255759984626995 
Epoch [3/5] Batch 1100/14335 Train_loss 1.7336641130571362 
Epoch [3/5] Batch 1200/14335 Train_loss 1.7346989697498345 
Epoch [3/5] Batch 1300/14335 Train_loss 1.731563158287487 
Epoch [3/5] Batch 1400/14335 Train_loss 1.73006472443041 
Epoch [3/5] Batch 1500/14335 Train_loss 1.726888730441984 
Epoch [3/5] Batch 1600/14335 Train_loss 1.7273614439022011 
Epoch [3/5] Batch 1700/14335 Train_loss 1.7244755382759651 
Epoch [3/5] Batch 1800/14335 Train_loss 1.7230247957906015 
Epoch [3/5] Batch 1900/14335 Train_loss 1.7278547830946316 
Epoch [3/5] Batch 2000/14335 Train_loss 1.7249265413494899 
Epoch [3/5] Batch 2100/14335 Train_loss 1.724822854570892 
Epoch [3/5] Batch 2200/14335 Train_loss 1.7177150496152627 
Epoch [3/5] Batch 2300/14335 Train_loss 1.7196885302908935 
Epoch [3/5] Batch 2400/14335 Train_loss 1.720396928483002 
Epoch [3/5] Batch 2500/14335 Train_loss 1.7176053403723675 
Epoch [3/5] Batch 2600/14335 Train_loss 1.7172705918057796 
Epoch [3/5] Batch 2700/14335 Train_loss 1.717509525638075 
Epoch [3/5] Batch 2800/14335 Train_loss 1.7182480924493795 
Epoch [3/5] Batch 2900/14335 Train_loss 1.7159046640286402 
Epoch [3/5] Batch 3000/14335 Train_loss 1.716609238629856 
Epoch [3/5] Batch 3100/14335 Train_loss 1.7169308374818777 
Epoch [3/5] Batch 3200/14335 Train_loss 1.715057686911602 
Epoch [3/5] Batch 3300/14335 Train_loss 1.7159362827980384 
Epoch [3/5] Batch 3400/14335 Train_loss 1.7170340269453488 
Epoch [3/5] Batch 3500/14335 Train_loss 1.717250523836025 
Epoch [3/5] Batch 3600/14335 Train_loss 1.7197337502060714 
Epoch [3/5] Batch 3700/14335 Train_loss 1.7192954846255941 
Epoch [3/5] Batch 3800/14335 Train_loss 1.7201505004928415 
Epoch [3/5] Batch 3900/14335 Train_loss 1.72154311492745 
Epoch [3/5] Batch 4000/14335 Train_loss 1.7204275134540266 
Epoch [3/5] Batch 4100/14335 Train_loss 1.7192841732728716 
Epoch [3/5] Batch 4200/14335 Train_loss 1.7204865072099007 
Epoch [3/5] Batch 4300/14335 Train_loss 1.7189204617312719 
Epoch [3/5] Batch 4400/14335 Train_loss 1.721501253482646 
Epoch [3/5] Batch 4500/14335 Train_loss 1.7220583639855227 
Epoch [3/5] Batch 4600/14335 Train_loss 1.7217576331779818 
Epoch [3/5] Batch 4700/14335 Train_loss 1.7228901846513827 
Epoch [3/5] Batch 4800/14335 Train_loss 1.7228744772604867 
Epoch [3/5] Batch 4900/14335 Train_loss 1.7219350222324115 
Epoch [3/5] Batch 5000/14335 Train_loss 1.7217203604206042 
Epoch [3/5] Batch 5100/14335 Train_loss 1.7240908453041983 
Epoch [3/5] Batch 5200/14335 Train_loss 1.7251036508688213 
Epoch [3/5] Batch 5300/14335 Train_loss 1.7249266294331353 
Epoch [3/5] Batch 5400/14335 Train_loss 1.7256639277056574 
Epoch [3/5] Batch 5500/14335 Train_loss 1.7260727475820032 
Epoch [3/5] Batch 5600/14335 Train_loss 1.7262800722859348 
Epoch [3/5] Batch 5700/14335 Train_loss 1.7255606707018878 
Epoch [3/5] Batch 5800/14335 Train_loss 1.7253921265024972 
Epoch [3/5] Batch 5900/14335 Train_loss 1.7246624765643992 
Epoch [3/5] Batch 6000/14335 Train_loss 1.7241960596569457 
Epoch [3/5] Batch 6100/14335 Train_loss 1.7244774842971544 
Epoch [3/5] Batch 6200/14335 Train_loss 1.7258949343032788 
Epoch [3/5] Batch 6300/14335 Train_loss 1.7262746834141018 
Epoch [3/5] Batch 6400/14335 Train_loss 1.7260930445781444 
Epoch [3/5] Batch 6500/14335 Train_loss 1.7256955177433086 
Epoch [3/5] Batch 6600/14335 Train_loss 1.724983930284147 
Epoch [3/5] Batch 6700/14335 Train_loss 1.7248005978735308 
Epoch [3/5] Batch 6800/14335 Train_loss 1.7240266478295239 
Epoch [3/5] Batch 6900/14335 Train_loss 1.7236139750494903 
Epoch [3/5] Batch 7000/14335 Train_loss 1.723411100413855 
Epoch [3/5] Batch 7100/14335 Train_loss 1.7237909778809903 
Epoch [3/5] Batch 7200/14335 Train_loss 1.7236082648855582 
Epoch [3/5] Batch 7300/14335 Train_loss 1.7229513302006603 
Epoch [3/5] Batch 7400/14335 Train_loss 1.7237902611973253 
Epoch [3/5] Batch 7500/14335 Train_loss 1.7235345586611897 
Epoch [3/5] Batch 7600/14335 Train_loss 1.723095354875394 
Epoch [3/5] Batch 7700/14335 Train_loss 1.7233310407856008 
Epoch [3/5] Batch 7800/14335 Train_loss 1.7218353873131413 
Epoch [3/5] Batch 7900/14335 Train_loss 1.7211452161582297 
Epoch [3/5] Batch 8000/14335 Train_loss 1.72155109562288 
Epoch [3/5] Batch 8100/14335 Train_loss 1.721391609540296 
Epoch [3/5] Batch 8200/14335 Train_loss 1.7205888989196727 
Epoch [3/5] Batch 8300/14335 Train_loss 1.7205811722219573 
Epoch [3/5] Batch 8400/14335 Train_loss 1.7212636236253487 
Epoch [3/5] Batch 8500/14335 Train_loss 1.720444378330769 
Epoch [3/5] Batch 8600/14335 Train_loss 1.7198393800281921 
Epoch [3/5] Batch 8700/14335 Train_loss 1.7197593197067254 
Epoch [3/5] Batch 8800/14335 Train_loss 1.7197997960420837 
Epoch [3/5] Batch 8900/14335 Train_loss 1.7195560244841062 
Epoch [3/5] Batch 9000/14335 Train_loss 1.7194340392738603 
Epoch [3/5] Batch 9100/14335 Train_loss 1.7207639191187931 
Epoch [3/5] Batch 9200/14335 Train_loss 1.7212766139797318 
Epoch [3/5] Batch 9300/14335 Train_loss 1.721899185761042 
Epoch [3/5] Batch 9400/14335 Train_loss 1.7202028596579375 
Epoch [3/5] Batch 9500/14335 Train_loss 1.7204016848572077 
Epoch [3/5] Batch 9600/14335 Train_loss 1.720349924989435 
Epoch [3/5] Batch 9700/14335 Train_loss 1.7190721584047168 
Epoch [3/5] Batch 9800/14335 Train_loss 1.7192517791341342 
Epoch [3/5] Batch 9900/14335 Train_loss 1.7187043919003488 
Epoch [3/5] Batch 10000/14335 Train_loss 1.7195440887616653 
Epoch [3/5] Batch 10100/14335 Train_loss 1.7191597068480025 
Epoch [3/5] Batch 10200/14335 Train_loss 1.7181904531037349 
Epoch [3/5] Batch 10300/14335 Train_loss 1.718066713737725 
Epoch [3/5] Batch 10400/14335 Train_loss 1.7175706279948575 
Epoch [3/5] Batch 10500/14335 Train_loss 1.7178657705686387 
Epoch [3/5] Batch 10600/14335 Train_loss 1.718369797402767 
Epoch [3/5] Batch 10700/14335 Train_loss 1.7192282886358803 
Epoch [3/5] Batch 10800/14335 Train_loss 1.7193585026961997 
Epoch [3/5] Batch 10900/14335 Train_loss 1.7189063068211718 
Epoch [3/5] Batch 11000/14335 Train_loss 1.71915582835379 
Epoch [3/5] Batch 11100/14335 Train_loss 1.71905269482382 
Epoch [3/5] Batch 11200/14335 Train_loss 1.7184469724450993 
Epoch [3/5] Batch 11300/14335 Train_loss 1.7186210705442888 
Epoch [3/5] Batch 11400/14335 Train_loss 1.716825998907847 
Epoch [3/5] Batch 11500/14335 Train_loss 1.7167519806614493 
Epoch [3/5] Batch 11600/14335 Train_loss 1.7165364242165975 
Epoch [3/5] Batch 11700/14335 Train_loss 1.7163892087741761 
Epoch [3/5] Batch 11800/14335 Train_loss 1.7168038964376349 
Epoch [3/5] Batch 11900/14335 Train_loss 1.7171775362055328 
Epoch [3/5] Batch 12000/14335 Train_loss 1.7171108481401196 
Epoch [3/5] Batch 12100/14335 Train_loss 1.7167285939099945 
Epoch [3/5] Batch 12200/14335 Train_loss 1.7160965369383963 
Epoch [3/5] Batch 12300/14335 Train_loss 1.7164043090409569 
Epoch [3/5] Batch 12400/14335 Train_loss 1.7162555999228977 
Epoch [3/5] Batch 12500/14335 Train_loss 1.7161528063353495 
Epoch [3/5] Batch 12600/14335 Train_loss 1.7165122524940932 
Epoch [3/5] Batch 12700/14335 Train_loss 1.7166886722635128 
Epoch [3/5] Batch 12800/14335 Train_loss 1.7160747366071296 
Epoch [3/5] Batch 12900/14335 Train_loss 1.7161637661897315 
Epoch [3/5] Batch 13000/14335 Train_loss 1.7164849152241375 
Epoch [3/5] Batch 13100/14335 Train_loss 1.7166237079779179 
Epoch [3/5] Batch 13200/14335 Train_loss 1.7165550290036948 
Epoch [3/5] Batch 13300/14335 Train_loss 1.716933335290261 
Epoch [3/5] Batch 13400/14335 Train_loss 1.7162161002265153 
Epoch [3/5] Batch 13500/14335 Train_loss 1.7156291451906949 
Epoch [3/5] Batch 13600/14335 Train_loss 1.7157111301416685 
Epoch [3/5] Batch 13700/14335 Train_loss 1.7160545004838035 
Epoch [3/5] Batch 13800/14335 Train_loss 1.7160058077258757 
Epoch [3/5] Batch 13900/14335 Train_loss 1.7163417178918523 
Epoch [3/5] Batch 14000/14335 Train_loss 1.7165623660913818 
Epoch [3/5] Batch 14100/14335 Train_loss 1.7170320886163015 
Epoch [3/5] Batch 14200/14335 Train_loss 1.7175653983928243 
Epoch [3/5] Batch 14300/14335 Train_loss 1.7174623934224504 
Epoch: 3/5 	Training Loss: 1.717744 	Validation Loss: 1.700522 Duration seconds: 4686.651045560837 
Validation loss decreased (1.729155 --> 1.700522).  Saving model ... 
best_valid_loss_fold [1.7005218047415838] Best_Epoch [3]Epoch [4/5] Batch 0/14335 Train_loss 1.0947811603546143 
Epoch [4/5] Batch 100/14335 Train_loss 1.6766843745614042 
Epoch [4/5] Batch 200/14335 Train_loss 1.6859866030032362 
Epoch [4/5] Batch 300/14335 Train_loss 1.6895966962029372 
Epoch [4/5] Batch 400/14335 Train_loss 1.705645702946513 
Epoch [4/5] Batch 500/14335 Train_loss 1.6833547745160238 
Epoch [4/5] Batch 600/14335 Train_loss 1.6682074887185248 
Epoch [4/5] Batch 700/14335 Train_loss 1.6799141421977872 
Epoch [4/5] Batch 800/14335 Train_loss 1.683369938949223 
Epoch [4/5] Batch 900/14335 Train_loss 1.680471490113505 
Epoch [4/5] Batch 1000/14335 Train_loss 1.674347193976799 
Epoch [4/5] Batch 1100/14335 Train_loss 1.6751041281613082 
Epoch [4/5] Batch 1200/14335 Train_loss 1.6741257763896555 
Epoch [4/5] Batch 1300/14335 Train_loss 1.674521471460355 
Epoch [4/5] Batch 1400/14335 Train_loss 1.673441545015399 
Epoch [4/5] Batch 1500/14335 Train_loss 1.6771000546268588 
Epoch [4/5] Batch 1600/14335 Train_loss 1.6721045842241824 
Epoch [4/5] Batch 1700/14335 Train_loss 1.6731755411157112 
Epoch [4/5] Batch 1800/14335 Train_loss 1.6747279327232463 
Epoch [4/5] Batch 1900/14335 Train_loss 1.6701170010614683 
Epoch [4/5] Batch 2000/14335 Train_loss 1.6735463824936714 
Epoch [4/5] Batch 2100/14335 Train_loss 1.6731367501182421 
Epoch [4/5] Batch 2200/14335 Train_loss 1.6743237243246782 
Epoch [4/5] Batch 2300/14335 Train_loss 1.6748074317971866 
Epoch [4/5] Batch 2400/14335 Train_loss 1.6786167358685562 
Epoch [4/5] Batch 2500/14335 Train_loss 1.6763600078923422 
Epoch [4/5] Batch 2600/14335 Train_loss 1.6777174303545168 
Epoch [4/5] Batch 2700/14335 Train_loss 1.677446999648839 
Epoch [4/5] Batch 2800/14335 Train_loss 1.6810238132734079 
Epoch [4/5] Batch 2900/14335 Train_loss 1.6803384557628336 
Epoch [4/5] Batch 3000/14335 Train_loss 1.6769429943991359 
Epoch [4/5] Batch 3100/14335 Train_loss 1.6767251982645848 
Epoch [4/5] Batch 3200/14335 Train_loss 1.6799127114532293 
Epoch [4/5] Batch 3300/14335 Train_loss 1.6797138248581267 
Epoch [4/5] Batch 3400/14335 Train_loss 1.6834870646566686 
Epoch [4/5] Batch 3500/14335 Train_loss 1.684627739515212 
Epoch [4/5] Batch 3600/14335 Train_loss 1.686688812428367 
Epoch [4/5] Batch 3700/14335 Train_loss 1.6842707646147557 
Epoch [4/5] Batch 3800/14335 Train_loss 1.6850559307584259 
Epoch [4/5] Batch 3900/14335 Train_loss 1.6865409995861098 
Epoch [4/5] Batch 4000/14335 Train_loss 1.687288056575814 
Epoch [4/5] Batch 4100/14335 Train_loss 1.6866103733143292 
Epoch [4/5] Batch 4200/14335 Train_loss 1.6861600527693703 
Epoch [4/5] Batch 4300/14335 Train_loss 1.6861606436142587 
Epoch [4/5] Batch 4400/14335 Train_loss 1.6866763862401375 
Epoch [4/5] Batch 4500/14335 Train_loss 1.6848867914708316 
Epoch [4/5] Batch 4600/14335 Train_loss 1.6857786679272417 
Epoch [4/5] Batch 4700/14335 Train_loss 1.686858754138304 
Epoch [4/5] Batch 4800/14335 Train_loss 1.687750687934823 
Epoch [4/5] Batch 4900/14335 Train_loss 1.688542281055336 
Epoch [4/5] Batch 5000/14335 Train_loss 1.690867218522102 
Epoch [4/5] Batch 5100/14335 Train_loss 1.6899215247006631 
Epoch [4/5] Batch 5200/14335 Train_loss 1.6897198015784924 
Epoch [4/5] Batch 5300/14335 Train_loss 1.688415567300844 
Epoch [4/5] Batch 5400/14335 Train_loss 1.6883852062245095 
Epoch [4/5] Batch 5500/14335 Train_loss 1.689579029281591 
Epoch [4/5] Batch 5600/14335 Train_loss 1.691185461616297 
Epoch [4/5] Batch 5700/14335 Train_loss 1.6891228904043598 
Epoch [4/5] Batch 5800/14335 Train_loss 1.6888246666964344 
Epoch [4/5] Batch 5900/14335 Train_loss 1.690294849115789 
Epoch [4/5] Batch 6000/14335 Train_loss 1.6899099166634937 
Epoch [4/5] Batch 6100/14335 Train_loss 1.6893903107376709 
Epoch [4/5] Batch 6200/14335 Train_loss 1.6906414808243768 
Epoch [4/5] Batch 6300/14335 Train_loss 1.6918749320312656 
Epoch [4/5] Batch 6400/14335 Train_loss 1.6922083738862472 
Epoch [4/5] Batch 6500/14335 Train_loss 1.692595252103346 
Epoch [4/5] Batch 6600/14335 Train_loss 1.6937470017516005 
Epoch [4/5] Batch 6700/14335 Train_loss 1.6946746689851044 
Epoch [4/5] Batch 6800/14335 Train_loss 1.6945133640279824 
Epoch [4/5] Batch 6900/14335 Train_loss 1.6943209499731788 
Epoch [4/5] Batch 7000/14335 Train_loss 1.6940337978808935 
Epoch [4/5] Batch 7100/14335 Train_loss 1.693631338527162 
Epoch [4/5] Batch 7200/14335 Train_loss 1.6946006059251366 
Epoch [4/5] Batch 7300/14335 Train_loss 1.6929998321219137 
Epoch [4/5] Batch 7400/14335 Train_loss 1.693902807651243 
Epoch [4/5] Batch 7500/14335 Train_loss 1.6935173853131282 
Epoch [4/5] Batch 7600/14335 Train_loss 1.6925248863128217 
Epoch [4/5] Batch 7700/14335 Train_loss 1.6928150154840806 
Epoch [4/5] Batch 7800/14335 Train_loss 1.6922833698643749 
Epoch [4/5] Batch 7900/14335 Train_loss 1.6924600447356557 
Epoch [4/5] Batch 8000/14335 Train_loss 1.6925861692241602 
Epoch [4/5] Batch 8100/14335 Train_loss 1.6927734444945877 
Epoch [4/5] Batch 8200/14335 Train_loss 1.6923585340631413 
Epoch [4/5] Batch 8300/14335 Train_loss 1.6921183803089483 
Epoch [4/5] Batch 8400/14335 Train_loss 1.6937228490929634 
Epoch [4/5] Batch 8500/14335 Train_loss 1.6948785707214316 
Epoch [4/5] Batch 8600/14335 Train_loss 1.6945948133195519 
Epoch [4/5] Batch 8700/14335 Train_loss 1.695346126551019 
Epoch [4/5] Batch 8800/14335 Train_loss 1.6956901765531023 
Epoch [4/5] Batch 8900/14335 Train_loss 1.6954146650740236 
Epoch [4/5] Batch 9000/14335 Train_loss 1.6963443131127194 
Epoch [4/5] Batch 9100/14335 Train_loss 1.6961744179546592 
Epoch [4/5] Batch 9200/14335 Train_loss 1.6960709229226658 
Epoch [4/5] Batch 9300/14335 Train_loss 1.6964995694755163 
Epoch [4/5] Batch 9400/14335 Train_loss 1.696190499149698 
Epoch [4/5] Batch 9500/14335 Train_loss 1.6959139161457288 
Epoch [4/5] Batch 9600/14335 Train_loss 1.6957623424172812 
Epoch [4/5] Batch 9700/14335 Train_loss 1.6958143267772479 
Epoch [4/5] Batch 9800/14335 Train_loss 1.694450323122057 
Epoch [4/5] Batch 9900/14335 Train_loss 1.6940279106695404 
Epoch [4/5] Batch 10000/14335 Train_loss 1.6945195501416388 
Epoch [4/5] Batch 10100/14335 Train_loss 1.6938902044025415 
Epoch [4/5] Batch 10200/14335 Train_loss 1.69378908050696 
Epoch [4/5] Batch 10300/14335 Train_loss 1.6933143401547215 
Epoch [4/5] Batch 10400/14335 Train_loss 1.6937369657591745 
Epoch [4/5] Batch 10500/14335 Train_loss 1.6937395560457336 
Epoch [4/5] Batch 10600/14335 Train_loss 1.6938500500721376 
Epoch [4/5] Batch 10700/14335 Train_loss 1.6935847011154506 
Epoch [4/5] Batch 10800/14335 Train_loss 1.6930662116206374 
Epoch [4/5] Batch 10900/14335 Train_loss 1.6945905464313225 
Epoch [4/5] Batch 11000/14335 Train_loss 1.6956389921849158 
Epoch [4/5] Batch 11100/14335 Train_loss 1.6960007982017618 
Epoch [4/5] Batch 11200/14335 Train_loss 1.6956323963704625 
Epoch [4/5] Batch 11300/14335 Train_loss 1.6956675088145323 
Epoch [4/5] Batch 11400/14335 Train_loss 1.6956664663229362 
Epoch [4/5] Batch 11500/14335 Train_loss 1.69551507661759 
Epoch [4/5] Batch 11600/14335 Train_loss 1.6948094858989697 
Epoch [4/5] Batch 11700/14335 Train_loss 1.6940258700314947 
Epoch [4/5] Batch 11800/14335 Train_loss 1.6942221507980615 
Epoch [4/5] Batch 11900/14335 Train_loss 1.6942407858384505 
Epoch [4/5] Batch 12000/14335 Train_loss 1.6942704237613238 
Epoch [4/5] Batch 12100/14335 Train_loss 1.6945767780965533 
Epoch [4/5] Batch 12200/14335 Train_loss 1.6940589410315996 
Epoch [4/5] Batch 12300/14335 Train_loss 1.6940411537038913 
Epoch [4/5] Batch 12400/14335 Train_loss 1.6937824993702002 
Epoch [4/5] Batch 12500/14335 Train_loss 1.6938074029527344 
Epoch [4/5] Batch 12600/14335 Train_loss 1.6939675954262394 
Epoch [4/5] Batch 12700/14335 Train_loss 1.6943600704796238 
Epoch [4/5] Batch 12800/14335 Train_loss 1.6943628446685506 
Epoch [4/5] Batch 12900/14335 Train_loss 1.6950766566519118 
Epoch [4/5] Batch 13000/14335 Train_loss 1.6950337960571107 
Epoch [4/5] Batch 13100/14335 Train_loss 1.6957227278092182 
Epoch [4/5] Batch 13200/14335 Train_loss 1.6953116716981684 
Epoch [4/5] Batch 13300/14335 Train_loss 1.6951718820617052 
Epoch [4/5] Batch 13400/14335 Train_loss 1.695579985043654 
Epoch [4/5] Batch 13500/14335 Train_loss 1.695724617239811 
Epoch [4/5] Batch 13600/14335 Train_loss 1.695371570640667 
Epoch [4/5] Batch 13700/14335 Train_loss 1.6957406837129652 
Epoch [4/5] Batch 13800/14335 Train_loss 1.6958530751492837 
Epoch [4/5] Batch 13900/14335 Train_loss 1.6960315782951714 
Epoch [4/5] Batch 14000/14335 Train_loss 1.6964805166420447 
Epoch [4/5] Batch 14100/14335 Train_loss 1.6961987868123642 
Epoch [4/5] Batch 14200/14335 Train_loss 1.6963614639516247 
Epoch [4/5] Batch 14300/14335 Train_loss 1.6964708621973226 
Epoch: 4/5 	Training Loss: 1.696551 	Validation Loss: 1.686016 Duration seconds: 4803.051908254623 
Validation loss decreased (1.700522 --> 1.686016).  Saving model ... 
best_valid_loss_fold [1.6860163543938793] Best_Epoch [4]Fold: 1/5 
Epoch [0/5] Batch 0/14335 Train_loss 1.5809924900531769 
Epoch [0/5] Batch 100/14335 Train_loss 1.822995927074168 
Epoch [0/5] Batch 200/14335 Train_loss 1.8011654198021438 
Epoch [0/5] Batch 300/14335 Train_loss 1.7753766180074888 
Epoch [0/5] Batch 400/14335 Train_loss 1.7641857604582114 
Epoch [0/5] Batch 500/14335 Train_loss 1.7496023995582453 
Epoch [0/5] Batch 600/14335 Train_loss 1.7424015212996231 
Epoch [0/5] Batch 700/14335 Train_loss 1.7399546838818536 
Epoch [0/5] Batch 800/14335 Train_loss 1.7392600791414876 
Epoch [0/5] Batch 900/14335 Train_loss 1.7319044239661934 
Epoch [0/5] Batch 1000/14335 Train_loss 1.7291872130779478 
Epoch [0/5] Batch 1100/14335 Train_loss 1.7269201133126133 
Epoch [0/5] Batch 1200/14335 Train_loss 1.7273395726275782 
Epoch [0/5] Batch 1300/14335 Train_loss 1.7250314754055245 
Epoch [0/5] Batch 1400/14335 Train_loss 1.7206356057007768 
Epoch [0/5] Batch 1500/14335 Train_loss 1.7130687540964156 
Epoch [0/5] Batch 1600/14335 Train_loss 1.721693329573571 
Epoch [0/5] Batch 1700/14335 Train_loss 1.7201316112686367 
Epoch [0/5] Batch 1800/14335 Train_loss 1.7172127518635336 
Epoch [0/5] Batch 1900/14335 Train_loss 1.7212340386603018 
Epoch [0/5] Batch 2000/14335 Train_loss 1.7246894119144498 
Epoch [0/5] Batch 2100/14335 Train_loss 1.7220907291306138 
Epoch [0/5] Batch 2200/14335 Train_loss 1.7229524764254764 
Epoch [0/5] Batch 2300/14335 Train_loss 1.721508402502029 
Epoch [0/5] Batch 2400/14335 Train_loss 1.722719558390142 
Epoch [0/5] Batch 2500/14335 Train_loss 1.7244514128098676 
Epoch [0/5] Batch 2600/14335 Train_loss 1.725482269677576 
Epoch [0/5] Batch 2700/14335 Train_loss 1.726483822224737 
Epoch [0/5] Batch 2800/14335 Train_loss 1.728281510534328 
Epoch [0/5] Batch 2900/14335 Train_loss 1.7252996287179256 
Epoch [0/5] Batch 3000/14335 Train_loss 1.7252005586169117 
Epoch [0/5] Batch 3100/14335 Train_loss 1.7238744317413683 
Epoch [0/5] Batch 3200/14335 Train_loss 1.7219904251920362 
Epoch [0/5] Batch 3300/14335 Train_loss 1.7199986964414533 
Epoch [0/5] Batch 3400/14335 Train_loss 1.7210699825212732 
Epoch [0/5] Batch 3500/14335 Train_loss 1.719307473466179 
Epoch [0/5] Batch 3600/14335 Train_loss 1.718317421442335 
Epoch [0/5] Batch 3700/14335 Train_loss 1.7197193691526609 
Epoch [0/5] Batch 3800/14335 Train_loss 1.7194121451722544 
Epoch [0/5] Batch 3900/14335 Train_loss 1.7174491065682524 
Epoch [0/5] Batch 4000/14335 Train_loss 1.717756403197172 
Epoch [0/5] Batch 4100/14335 Train_loss 1.717852307413154 
Epoch [0/5] Batch 4200/14335 Train_loss 1.716852602636465 
Epoch [0/5] Batch 4300/14335 Train_loss 1.7168106138792822 
Epoch [0/5] Batch 4400/14335 Train_loss 1.7181142095634678 
Epoch [0/5] Batch 4500/14335 Train_loss 1.7178503282316868 
Epoch [0/5] Batch 4600/14335 Train_loss 1.7184124771044893 
Epoch [0/5] Batch 4700/14335 Train_loss 1.7160596663100216 
Epoch [0/5] Batch 4800/14335 Train_loss 1.7152037008994694 
Epoch [0/5] Batch 4900/14335 Train_loss 1.7147679032461056 
Epoch [0/5] Batch 5000/14335 Train_loss 1.7159548234898456 
Epoch [0/5] Batch 5100/14335 Train_loss 1.7166960046098434 
Epoch [0/5] Batch 5200/14335 Train_loss 1.7158409163722554 
Epoch [0/5] Batch 5300/14335 Train_loss 1.715279257578898 
Epoch [0/5] Batch 5400/14335 Train_loss 1.714694582152104 
Epoch [0/5] Batch 5500/14335 Train_loss 1.711925513110547 
Epoch [0/5] Batch 5600/14335 Train_loss 1.7135226162517312 
Epoch [0/5] Batch 5700/14335 Train_loss 1.7142995294929073 
Epoch [0/5] Batch 5800/14335 Train_loss 1.7135937291781382 
Epoch [0/5] Batch 5900/14335 Train_loss 1.7119864199150823 
Epoch [0/5] Batch 6000/14335 Train_loss 1.7120850975539084 
Epoch [0/5] Batch 6100/14335 Train_loss 1.7127977642680245 
Epoch [0/5] Batch 6200/14335 Train_loss 1.7131619424966338 
Epoch [0/5] Batch 6300/14335 Train_loss 1.7125332246241427 
Epoch [0/5] Batch 6400/14335 Train_loss 1.7119489066038556 
Epoch [0/5] Batch 6500/14335 Train_loss 1.7133765268387235 
Epoch [0/5] Batch 6600/14335 Train_loss 1.7153845645612595 
Epoch [0/5] Batch 6700/14335 Train_loss 1.715924711396242 
Epoch [0/5] Batch 6800/14335 Train_loss 1.7159136244280866 
Epoch [0/5] Batch 6900/14335 Train_loss 1.7162280945398034 
Epoch [0/5] Batch 7000/14335 Train_loss 1.716320792162798 
Epoch [0/5] Batch 7100/14335 Train_loss 1.717021136829642 
Epoch [0/5] Batch 7200/14335 Train_loss 1.716775400042865 
Epoch [0/5] Batch 7300/14335 Train_loss 1.7165539618808592 
Epoch [0/5] Batch 7400/14335 Train_loss 1.7165638694061232 
Epoch [0/5] Batch 7500/14335 Train_loss 1.7169361919216308 
Epoch [0/5] Batch 7600/14335 Train_loss 1.7166502211610983 
Epoch [0/5] Batch 7700/14335 Train_loss 1.7160695149465175 
Epoch [0/5] Batch 7800/14335 Train_loss 1.7165105504999405 
Epoch [0/5] Batch 7900/14335 Train_loss 1.7162605690859554 
Epoch [0/5] Batch 8000/14335 Train_loss 1.7167417582419198 
Epoch [0/5] Batch 8100/14335 Train_loss 1.7168714473415578 
Epoch [0/5] Batch 8200/14335 Train_loss 1.7167415154091454 
Epoch [0/5] Batch 8300/14335 Train_loss 1.7175244776481118 
Epoch [0/5] Batch 8400/14335 Train_loss 1.7179944968666296 
Epoch [0/5] Batch 8500/14335 Train_loss 1.718301161393609 
Epoch [0/5] Batch 8600/14335 Train_loss 1.717263320559451 
Epoch [0/5] Batch 8700/14335 Train_loss 1.7167297746301546 
Epoch [0/5] Batch 8800/14335 Train_loss 1.7165734276341424 
Epoch [0/5] Batch 8900/14335 Train_loss 1.7161719194114202 
Epoch [0/5] Batch 9000/14335 Train_loss 1.7156963339126146 
Epoch [0/5] Batch 9100/14335 Train_loss 1.7154363446971594 
Epoch [0/5] Batch 9200/14335 Train_loss 1.7151330379651184 
Epoch [0/5] Batch 9300/14335 Train_loss 1.7153130622023716 
Epoch [0/5] Batch 9400/14335 Train_loss 1.7149714421912428 
Epoch [0/5] Batch 9500/14335 Train_loss 1.715334901317002 
Epoch [0/5] Batch 9600/14335 Train_loss 1.7151111378371808 
Epoch [0/5] Batch 9700/14335 Train_loss 1.7143021916526886 
Epoch [0/5] Batch 9800/14335 Train_loss 1.7133253510197977 
Epoch [0/5] Batch 9900/14335 Train_loss 1.7136616144039971 
Epoch [0/5] Batch 10000/14335 Train_loss 1.7131653791070938 
Epoch [0/5] Batch 10100/14335 Train_loss 1.7129220032053778 
Epoch [0/5] Batch 10200/14335 Train_loss 1.7119112029619081 
Epoch [0/5] Batch 10300/14335 Train_loss 1.7120491596438412 
Epoch [0/5] Batch 10400/14335 Train_loss 1.7118493039596139 
Epoch [0/5] Batch 10500/14335 Train_loss 1.7117802694485296 
Epoch [0/5] Batch 10600/14335 Train_loss 1.7120099996076295 
Epoch [0/5] Batch 10700/14335 Train_loss 1.7117009665818763 
Epoch [0/5] Batch 10800/14335 Train_loss 1.711945029857004 
Epoch [0/5] Batch 10900/14335 Train_loss 1.7107460238863084 
Epoch [0/5] Batch 11000/14335 Train_loss 1.710746272563333 
Epoch [0/5] Batch 11100/14335 Train_loss 1.7111707978811674 
Epoch [0/5] Batch 11200/14335 Train_loss 1.711948659281312 
Epoch [0/5] Batch 11300/14335 Train_loss 1.7115858736738159 
Epoch [0/5] Batch 11400/14335 Train_loss 1.7120180996268028 
Epoch [0/5] Batch 11500/14335 Train_loss 1.7121357915447013 
Epoch [0/5] Batch 11600/14335 Train_loss 1.711977710623868 
Epoch [0/5] Batch 11700/14335 Train_loss 1.7117579923967359 
Epoch [0/5] Batch 11800/14335 Train_loss 1.711087204176898 
Epoch [0/5] Batch 11900/14335 Train_loss 1.711057948558814 
Epoch [0/5] Batch 12000/14335 Train_loss 1.7114023445891933 
Epoch [0/5] Batch 12100/14335 Train_loss 1.7120120196527278 
Epoch [0/5] Batch 12200/14335 Train_loss 1.7116676028349216 
Epoch [0/5] Batch 12300/14335 Train_loss 1.7114727162736265 
Epoch [0/5] Batch 12400/14335 Train_loss 1.7121962375344697 
Epoch [0/5] Batch 12500/14335 Train_loss 1.7125609277982767 
Epoch [0/5] Batch 12600/14335 Train_loss 1.7126596109605614 
Epoch [0/5] Batch 12700/14335 Train_loss 1.7125231086968455 
Epoch [0/5] Batch 12800/14335 Train_loss 1.7122847649322135 
Epoch [0/5] Batch 12900/14335 Train_loss 1.7124451034861972 
Epoch [0/5] Batch 13000/14335 Train_loss 1.7123261749063599 
Epoch [0/5] Batch 13100/14335 Train_loss 1.7123080658217475 
Epoch [0/5] Batch 13200/14335 Train_loss 1.7126428275006838 
Epoch [0/5] Batch 13300/14335 Train_loss 1.7119924685451537 
Epoch [0/5] Batch 13400/14335 Train_loss 1.7120130425286413 
Epoch [0/5] Batch 13500/14335 Train_loss 1.7117852618994116 
Epoch [0/5] Batch 13600/14335 Train_loss 1.7120875963161566 
Epoch [0/5] Batch 13700/14335 Train_loss 1.7119701369959555 
Epoch [0/5] Batch 13800/14335 Train_loss 1.71192613144129 
Epoch [0/5] Batch 13900/14335 Train_loss 1.712401889148813 
Epoch [0/5] Batch 14000/14335 Train_loss 1.7125962461094058 
Epoch [0/5] Batch 14100/14335 Train_loss 1.7121782279782418 
Epoch [0/5] Batch 14200/14335 Train_loss 1.7117610133821826 
Epoch [0/5] Batch 14300/14335 Train_loss 1.7119095392869565 
Epoch: 0/5 	Training Loss: 1.712068 	Validation Loss: 1.678747 Duration seconds: 3997.391023159027 
Validation loss decreased (inf --> 1.678747).  Saving model ... 
best_valid_loss_fold [1.6787473899748875] Best_Epoch [0]Epoch [1/5] Batch 0/14335 Train_loss 1.7442640662193298 
Epoch [1/5] Batch 100/14335 Train_loss 1.7227877248631847 
Epoch [1/5] Batch 200/14335 Train_loss 1.707072059498794 
Epoch [1/5] Batch 300/14335 Train_loss 1.6918012803030569 
Epoch [1/5] Batch 400/14335 Train_loss 1.7069246762076815 
Epoch [1/5] Batch 500/14335 Train_loss 1.7119847646284245 
Epoch [1/5] Batch 600/14335 Train_loss 1.712866718516671 
Epoch [1/5] Batch 700/14335 Train_loss 1.722260237367194 
Epoch [1/5] Batch 800/14335 Train_loss 1.7147045512305812 
Epoch [1/5] Batch 900/14335 Train_loss 1.7100655816321764 
Epoch [1/5] Batch 1000/14335 Train_loss 1.7076690093084768 
Epoch [1/5] Batch 1100/14335 Train_loss 1.7010124756207692 
Epoch [1/5] Batch 1200/14335 Train_loss 1.6967251753243777 
Epoch [1/5] Batch 1300/14335 Train_loss 1.68853587397216 
Epoch [1/5] Batch 1400/14335 Train_loss 1.6893097223031954 
Epoch [1/5] Batch 1500/14335 Train_loss 1.6864970082207413 
Epoch [1/5] Batch 1600/14335 Train_loss 1.6886328340861143 
Epoch [1/5] Batch 1700/14335 Train_loss 1.6925554190801215 
Epoch [1/5] Batch 1800/14335 Train_loss 1.6924381720678863 
Epoch [1/5] Batch 1900/14335 Train_loss 1.6882983538890939 
Epoch [1/5] Batch 2000/14335 Train_loss 1.6902688834285629 
Epoch [1/5] Batch 2100/14335 Train_loss 1.6925748988191665 
Epoch [1/5] Batch 2200/14335 Train_loss 1.6961088990356803 
Epoch [1/5] Batch 2300/14335 Train_loss 1.6983091153660996 
Epoch [1/5] Batch 2400/14335 Train_loss 1.6993364685683239 
Epoch [1/5] Batch 2500/14335 Train_loss 1.7026601038107583 
Epoch [1/5] Batch 2600/14335 Train_loss 1.7011025074621615 
Epoch [1/5] Batch 2700/14335 Train_loss 1.7014246462523297 
Epoch [1/5] Batch 2800/14335 Train_loss 1.7019684333586982 
Epoch [1/5] Batch 2900/14335 Train_loss 1.7027544391639107 
Epoch [1/5] Batch 3000/14335 Train_loss 1.7046079379827608 
Epoch [1/5] Batch 3100/14335 Train_loss 1.704223569937865 
Epoch [1/5] Batch 3200/14335 Train_loss 1.7039865377670116 
Epoch [1/5] Batch 3300/14335 Train_loss 1.704588980058203 
Epoch [1/5] Batch 3400/14335 Train_loss 1.704199554952356 
Epoch [1/5] Batch 3500/14335 Train_loss 1.7055580777032857 
Epoch [1/5] Batch 3600/14335 Train_loss 1.7038339610146636 
Epoch [1/5] Batch 3700/14335 Train_loss 1.7032119323859598 
Epoch [1/5] Batch 3800/14335 Train_loss 1.7001983812100885 
Epoch [1/5] Batch 3900/14335 Train_loss 1.6992714682150363 
Epoch [1/5] Batch 4000/14335 Train_loss 1.6978713399755063 
Epoch [1/5] Batch 4100/14335 Train_loss 1.697074862174786 
Epoch [1/5] Batch 4200/14335 Train_loss 1.6978746101480102 
Epoch [1/5] Batch 4300/14335 Train_loss 1.6976230422897107 
Epoch [1/5] Batch 4400/14335 Train_loss 1.6977001489701935 
Epoch [1/5] Batch 4500/14335 Train_loss 1.6965263297583124 
Epoch [1/5] Batch 4600/14335 Train_loss 1.6985862834350334 
Epoch [1/5] Batch 4700/14335 Train_loss 1.6999766989192082 
Epoch [1/5] Batch 4800/14335 Train_loss 1.6993428485914583 
Epoch [1/5] Batch 4900/14335 Train_loss 1.6978766916859784 
Epoch [1/5] Batch 5000/14335 Train_loss 1.69721808834264 
Epoch [1/5] Batch 5100/14335 Train_loss 1.6969152066949371 
Epoch [1/5] Batch 5200/14335 Train_loss 1.6960306933990947 
Epoch [1/5] Batch 5300/14335 Train_loss 1.6952530938026547 
Epoch [1/5] Batch 5400/14335 Train_loss 1.6936720071653264 
Epoch [1/5] Batch 5500/14335 Train_loss 1.6936780432964798 
Epoch [1/5] Batch 5600/14335 Train_loss 1.693285529346599 
Epoch [1/5] Batch 5700/14335 Train_loss 1.6923975433394316 
Epoch [1/5] Batch 5800/14335 Train_loss 1.6920352681579929 
Epoch [1/5] Batch 5900/14335 Train_loss 1.6902608373921275 
Epoch [1/5] Batch 6000/14335 Train_loss 1.6899588748556915 
Epoch [1/5] Batch 6100/14335 Train_loss 1.6900469469469193 
Epoch [1/5] Batch 6200/14335 Train_loss 1.689079592034156 
Epoch [1/5] Batch 6300/14335 Train_loss 1.6892666198103943 
Epoch [1/5] Batch 6400/14335 Train_loss 1.688605248485761 
Epoch [1/5] Batch 6500/14335 Train_loss 1.6882324709725038 
Epoch [1/5] Batch 6600/14335 Train_loss 1.6889791272793948 
Epoch [1/5] Batch 6700/14335 Train_loss 1.690111550630482 
Epoch [1/5] Batch 6800/14335 Train_loss 1.6896627385346192 
Epoch [1/5] Batch 6900/14335 Train_loss 1.690462310471201 
Epoch [1/5] Batch 7000/14335 Train_loss 1.6910762974742037 
Epoch [1/5] Batch 7100/14335 Train_loss 1.690824854898127 
Epoch [1/5] Batch 7200/14335 Train_loss 1.691716617324289 
Epoch [1/5] Batch 7300/14335 Train_loss 1.6926775826071079 
Epoch [1/5] Batch 7400/14335 Train_loss 1.6921922116978412 
Epoch [1/5] Batch 7500/14335 Train_loss 1.692001927872965 
Epoch [1/5] Batch 7600/14335 Train_loss 1.6923308059565332 
Epoch [1/5] Batch 7700/14335 Train_loss 1.6919358010520997 
Epoch [1/5] Batch 7800/14335 Train_loss 1.6927283175491152 
Epoch [1/5] Batch 7900/14335 Train_loss 1.6930755867341427 
Epoch [1/5] Batch 8000/14335 Train_loss 1.6923842365880144 
Epoch [1/5] Batch 8100/14335 Train_loss 1.6923085367634714 
Epoch [1/5] Batch 8200/14335 Train_loss 1.6918230384366568 
Epoch [1/5] Batch 8300/14335 Train_loss 1.6915616671599734 
Epoch [1/5] Batch 8400/14335 Train_loss 1.6918438161207712 
Epoch [1/5] Batch 8500/14335 Train_loss 1.6925573450315 
Epoch [1/5] Batch 8600/14335 Train_loss 1.6933711653268 
Epoch [1/5] Batch 8700/14335 Train_loss 1.6924560936731918 
Epoch [1/5] Batch 8800/14335 Train_loss 1.6928829731746244 
Epoch [1/5] Batch 8900/14335 Train_loss 1.6927261072872342 
Epoch [1/5] Batch 9000/14335 Train_loss 1.6923399966546608 
Epoch [1/5] Batch 9100/14335 Train_loss 1.693138058685481 
Epoch [1/5] Batch 9200/14335 Train_loss 1.692747838488287 
Epoch [1/5] Batch 9300/14335 Train_loss 1.6924772038615246 
Epoch [1/5] Batch 9400/14335 Train_loss 1.69244506624503 
Epoch [1/5] Batch 9500/14335 Train_loss 1.6923478357678161 
Epoch [1/5] Batch 9600/14335 Train_loss 1.6924532998262836 
Epoch [1/5] Batch 9700/14335 Train_loss 1.6932362492955932 
Epoch [1/5] Batch 9800/14335 Train_loss 1.693472630641659 
Epoch [1/5] Batch 9900/14335 Train_loss 1.6938792656380568 
Epoch [1/5] Batch 10000/14335 Train_loss 1.693835359529732 
Epoch [1/5] Batch 10100/14335 Train_loss 1.6943986118968353 
Epoch [1/5] Batch 10200/14335 Train_loss 1.6949481801668074 
Epoch [1/5] Batch 10300/14335 Train_loss 1.6952692440584116 
Epoch [1/5] Batch 10400/14335 Train_loss 1.695614870819962 
Epoch [1/5] Batch 10500/14335 Train_loss 1.6958070379085808 
Epoch [1/5] Batch 10600/14335 Train_loss 1.6972742063694322 
Epoch [1/5] Batch 10700/14335 Train_loss 1.6971272893466522 
Epoch [1/5] Batch 10800/14335 Train_loss 1.6968356251148216 
Epoch [1/5] Batch 10900/14335 Train_loss 1.6965742544796902 
Epoch [1/5] Batch 11000/14335 Train_loss 1.6964189012073276 
Epoch [1/5] Batch 11100/14335 Train_loss 1.6973130655091644 
Epoch [1/5] Batch 11200/14335 Train_loss 1.6977348621429456 
Epoch [1/5] Batch 11300/14335 Train_loss 1.6982909325803974 
Epoch [1/5] Batch 11400/14335 Train_loss 1.6986741397309937 
Epoch [1/5] Batch 11500/14335 Train_loss 1.6982283069614577 
Epoch [1/5] Batch 11600/14335 Train_loss 1.6981190449300743 
Epoch [1/5] Batch 11700/14335 Train_loss 1.6988962770569183 
Epoch [1/5] Batch 11800/14335 Train_loss 1.6992588507250026 
Epoch [1/5] Batch 11900/14335 Train_loss 1.699237799812376 
Epoch [1/5] Batch 12000/14335 Train_loss 1.6992036933798749 
Epoch [1/5] Batch 12100/14335 Train_loss 1.7001507811740246 
Epoch [1/5] Batch 12200/14335 Train_loss 1.6993316815448984 
Epoch [1/5] Batch 12300/14335 Train_loss 1.6992419332135025 
Epoch [1/5] Batch 12400/14335 Train_loss 1.6992986171418702 
Epoch [1/5] Batch 12500/14335 Train_loss 1.6993565968743 
Epoch [1/5] Batch 12600/14335 Train_loss 1.6994708320103025 
Epoch [1/5] Batch 12700/14335 Train_loss 1.6993999486158058 
Epoch [1/5] Batch 12800/14335 Train_loss 1.6988502581796696 
Epoch [1/5] Batch 12900/14335 Train_loss 1.69855411194277 
Epoch [1/5] Batch 13000/14335 Train_loss 1.698276104138898 
Epoch [1/5] Batch 13100/14335 Train_loss 1.6980500737231166 
Epoch [1/5] Batch 13200/14335 Train_loss 1.69838573490715 
Epoch [1/5] Batch 13300/14335 Train_loss 1.6977681121215114 
Epoch [1/5] Batch 13400/14335 Train_loss 1.6975979826430956 
Epoch [1/5] Batch 13500/14335 Train_loss 1.6978278989382747 
Epoch [1/5] Batch 13600/14335 Train_loss 1.6986328392342236 
Epoch [1/5] Batch 13700/14335 Train_loss 1.6982808916059848 
Epoch [1/5] Batch 13800/14335 Train_loss 1.6980796322765304 
Epoch [1/5] Batch 13900/14335 Train_loss 1.6981724249402033 
Epoch [1/5] Batch 14000/14335 Train_loss 1.6977277208266237 
Epoch [1/5] Batch 14100/14335 Train_loss 1.6976789685275173 
Epoch [1/5] Batch 14200/14335 Train_loss 1.6971337679493144 
Epoch [1/5] Batch 14300/14335 Train_loss 1.6972300418892963 
Epoch: 1/5 	Training Loss: 1.696980 	Validation Loss: 1.672664 Duration seconds: 4179.964728355408 
Validation loss decreased (1.678747 --> 1.672664).  Saving model ... 
best_valid_loss_fold [1.6726641575317314] Best_Epoch [1]Epoch [2/5] Batch 0/14335 Train_loss 1.520918756723404 
Epoch [2/5] Batch 100/14335 Train_loss 1.6168456771733737 
Epoch [2/5] Batch 200/14335 Train_loss 1.6781984942395296 
Epoch [2/5] Batch 300/14335 Train_loss 1.7006431601669305 
Epoch [2/5] Batch 400/14335 Train_loss 1.6836230847009102 
Epoch [2/5] Batch 500/14335 Train_loss 1.6657257242176584 
Epoch [2/5] Batch 600/14335 Train_loss 1.645653622469767 
Epoch [2/5] Batch 700/14335 Train_loss 1.642827534896671 
Epoch [2/5] Batch 800/14335 Train_loss 1.6500074159209797 
Epoch [2/5] Batch 900/14335 Train_loss 1.6526634803043883 
Epoch [2/5] Batch 1000/14335 Train_loss 1.6577066675007164 
Epoch [2/5] Batch 1100/14335 Train_loss 1.6601130565616566 
Epoch [2/5] Batch 1200/14335 Train_loss 1.6565413056228382 
Epoch [2/5] Batch 1300/14335 Train_loss 1.6631166345735497 
Epoch [2/5] Batch 1400/14335 Train_loss 1.6640829237750987 
Epoch [2/5] Batch 1500/14335 Train_loss 1.6686077564110922 
Epoch [2/5] Batch 1600/14335 Train_loss 1.6700590048439052 
Epoch [2/5] Batch 1700/14335 Train_loss 1.673629381910168 
Epoch [2/5] Batch 1800/14335 Train_loss 1.6723842833031886 
Epoch [2/5] Batch 1900/14335 Train_loss 1.671764912717691 
Epoch [2/5] Batch 2000/14335 Train_loss 1.6730322446981292 
Epoch [2/5] Batch 2100/14335 Train_loss 1.6733453897089972 
Epoch [2/5] Batch 2200/14335 Train_loss 1.6723565497469057 
Epoch [2/5] Batch 2300/14335 Train_loss 1.6732409404107458 
Epoch [2/5] Batch 2400/14335 Train_loss 1.6738734783752915 
Epoch [2/5] Batch 2500/14335 Train_loss 1.6760509987560952 
Epoch [2/5] Batch 2600/14335 Train_loss 1.6732037560681297 
Epoch [2/5] Batch 2700/14335 Train_loss 1.672712481273452 
Epoch [2/5] Batch 2800/14335 Train_loss 1.672994658478623 
Epoch [2/5] Batch 2900/14335 Train_loss 1.6754412502358593 
Epoch [2/5] Batch 3000/14335 Train_loss 1.6736517459407365 
Epoch [2/5] Batch 3100/14335 Train_loss 1.6721310844342772 
Epoch [2/5] Batch 3200/14335 Train_loss 1.6733322452238224 
Epoch [2/5] Batch 3300/14335 Train_loss 1.6742710804838152 
Epoch [2/5] Batch 3400/14335 Train_loss 1.6718996943611848 
Epoch [2/5] Batch 3500/14335 Train_loss 1.6724725470896007 
Epoch [2/5] Batch 3600/14335 Train_loss 1.6741566519519084 
Epoch [2/5] Batch 3700/14335 Train_loss 1.67631509216838 
Epoch [2/5] Batch 3800/14335 Train_loss 1.6774889000173745 
Epoch [2/5] Batch 3900/14335 Train_loss 1.6782025676206331 
Epoch [2/5] Batch 4000/14335 Train_loss 1.6795325056332941 
Epoch [2/5] Batch 4100/14335 Train_loss 1.6802251270738964 
Epoch [2/5] Batch 4200/14335 Train_loss 1.681004521689495 
Epoch [2/5] Batch 4300/14335 Train_loss 1.681345522003558 
Epoch [2/5] Batch 4400/14335 Train_loss 1.6820195818967885 
Epoch [2/5] Batch 4500/14335 Train_loss 1.6838995108810881 
Epoch [2/5] Batch 4600/14335 Train_loss 1.6836612236011395 
Epoch [2/5] Batch 4700/14335 Train_loss 1.6849128347879976 
Epoch [2/5] Batch 4800/14335 Train_loss 1.6824890428273733 
Epoch [2/5] Batch 4900/14335 Train_loss 1.682751122660672 
Epoch [2/5] Batch 5000/14335 Train_loss 1.6829758325256101 
Epoch [2/5] Batch 5100/14335 Train_loss 1.681786424874196 
Epoch [2/5] Batch 5200/14335 Train_loss 1.6831904759537806 
Epoch [2/5] Batch 5300/14335 Train_loss 1.68308142165045 
Epoch [2/5] Batch 5400/14335 Train_loss 1.6830793699400333 
Epoch [2/5] Batch 5500/14335 Train_loss 1.684066217004646 
Epoch [2/5] Batch 5600/14335 Train_loss 1.6859172703024852 
Epoch [2/5] Batch 5700/14335 Train_loss 1.685599862903205 
Epoch [2/5] Batch 5800/14335 Train_loss 1.6844637204752135 
Epoch [2/5] Batch 5900/14335 Train_loss 1.6826683146302386 
Epoch [2/5] Batch 6000/14335 Train_loss 1.6830281413491914 
Epoch [2/5] Batch 6100/14335 Train_loss 1.6838223064662374 
Epoch [2/5] Batch 6200/14335 Train_loss 1.6840391808967883 
Epoch [2/5] Batch 6300/14335 Train_loss 1.6828185087964092 
Epoch [2/5] Batch 6400/14335 Train_loss 1.6816316726647342 
Epoch [2/5] Batch 6500/14335 Train_loss 1.6815309097866904 
Epoch [2/5] Batch 6600/14335 Train_loss 1.681503127803813 
Epoch [2/5] Batch 6700/14335 Train_loss 1.6810944003890103 
Epoch [2/5] Batch 6800/14335 Train_loss 1.6807845883797747 
Epoch [2/5] Batch 6900/14335 Train_loss 1.6810660081656579 
Epoch [2/5] Batch 7000/14335 Train_loss 1.6805858401654277 
Epoch [2/5] Batch 7100/14335 Train_loss 1.6800382483680807 
Epoch [2/5] Batch 7200/14335 Train_loss 1.6805901148026312 
Epoch [2/5] Batch 7300/14335 Train_loss 1.680536772104187 
Epoch [2/5] Batch 7400/14335 Train_loss 1.6799455454479664 
Epoch [2/5] Batch 7500/14335 Train_loss 1.6830074937522228 
Epoch [2/5] Batch 7600/14335 Train_loss 1.68265936626402 
Epoch [2/5] Batch 7700/14335 Train_loss 1.6827033948622003 
Epoch [2/5] Batch 7800/14335 Train_loss 1.6834726168943237 
Epoch [2/5] Batch 7900/14335 Train_loss 1.6837110276947052 
Epoch [2/5] Batch 8000/14335 Train_loss 1.6838324223718946 
Epoch [2/5] Batch 8100/14335 Train_loss 1.6835319387399184 
Epoch [2/5] Batch 8200/14335 Train_loss 1.6836419951594497 
Epoch [2/5] Batch 8300/14335 Train_loss 1.683755134971813 
Epoch [2/5] Batch 8400/14335 Train_loss 1.6840233968001237 
Epoch [2/5] Batch 8500/14335 Train_loss 1.6840855273269244 
Epoch [2/5] Batch 8600/14335 Train_loss 1.6835901806660065 
Epoch [2/5] Batch 8700/14335 Train_loss 1.6834425599919134 
Epoch [2/5] Batch 8800/14335 Train_loss 1.6827108473967265 
Epoch [2/5] Batch 8900/14335 Train_loss 1.6826814797276555 
Epoch [2/5] Batch 9000/14335 Train_loss 1.6835323452565447 
Epoch [2/5] Batch 9100/14335 Train_loss 1.6829823431598918 
Epoch [2/5] Batch 9200/14335 Train_loss 1.6832253108433297 
Epoch [2/5] Batch 9300/14335 Train_loss 1.6829128792464778 
Epoch [2/5] Batch 9400/14335 Train_loss 1.6836707557067823 
Epoch [2/5] Batch 9500/14335 Train_loss 1.683447644598339 
Epoch [2/5] Batch 9600/14335 Train_loss 1.6834287513379207 
Epoch [2/5] Batch 9700/14335 Train_loss 1.68324984830119 
Epoch [2/5] Batch 9800/14335 Train_loss 1.6834667834268275 
Epoch [2/5] Batch 9900/14335 Train_loss 1.6843028756665794 
Epoch [2/5] Batch 10000/14335 Train_loss 1.684376812354587 
Epoch [2/5] Batch 10100/14335 Train_loss 1.6843128665940925 
Epoch [2/5] Batch 10200/14335 Train_loss 1.6852291020208767 
Epoch [2/5] Batch 10300/14335 Train_loss 1.6850472860520713 
Epoch [2/5] Batch 10400/14335 Train_loss 1.6849671219376265 
Epoch [2/5] Batch 10500/14335 Train_loss 1.6855935388057643 
Epoch [2/5] Batch 10600/14335 Train_loss 1.6859955489410565 
Epoch [2/5] Batch 10700/14335 Train_loss 1.6863670880346586 
Epoch [2/5] Batch 10800/14335 Train_loss 1.6871867736349855 
Epoch [2/5] Batch 10900/14335 Train_loss 1.6874984180888455 
Epoch [2/5] Batch 11000/14335 Train_loss 1.6868330578908695 
Epoch [2/5] Batch 11100/14335 Train_loss 1.6866769515996087 
Epoch [2/5] Batch 11200/14335 Train_loss 1.6869923825111413 
Epoch [2/5] Batch 11300/14335 Train_loss 1.6868283704012887 
Epoch [2/5] Batch 11400/14335 Train_loss 1.6871312116693848 
Epoch [2/5] Batch 11500/14335 Train_loss 1.6874970156469766 
Epoch [2/5] Batch 11600/14335 Train_loss 1.68724414450556 
Epoch [2/5] Batch 11700/14335 Train_loss 1.6872299133262953 
Epoch [2/5] Batch 11800/14335 Train_loss 1.6863471526883334 
Epoch [2/5] Batch 11900/14335 Train_loss 1.6866290848678716 
Epoch [2/5] Batch 12000/14335 Train_loss 1.6872210973331594 
Epoch [2/5] Batch 12100/14335 Train_loss 1.6878026267659092 
Epoch [2/5] Batch 12200/14335 Train_loss 1.687668368416349 
Epoch [2/5] Batch 12300/14335 Train_loss 1.6875398287069758 
Epoch [2/5] Batch 12400/14335 Train_loss 1.6873983080786434 
Epoch [2/5] Batch 12500/14335 Train_loss 1.687095103167494 
Epoch [2/5] Batch 12600/14335 Train_loss 1.6865093888812912 
Epoch [2/5] Batch 12700/14335 Train_loss 1.6868036917878102 
Epoch [2/5] Batch 12800/14335 Train_loss 1.6859918882426186 
Epoch [2/5] Batch 12900/14335 Train_loss 1.686383312717213 
Epoch [2/5] Batch 13000/14335 Train_loss 1.6864951091994231 
Epoch [2/5] Batch 13100/14335 Train_loss 1.6868078950745633 
Epoch [2/5] Batch 13200/14335 Train_loss 1.6865593989178427 
Epoch [2/5] Batch 13300/14335 Train_loss 1.6866054570302507 
Epoch [2/5] Batch 13400/14335 Train_loss 1.6864148144485898 
Epoch [2/5] Batch 13500/14335 Train_loss 1.6860409796957563 
Epoch [2/5] Batch 13600/14335 Train_loss 1.686147280447155 
Epoch [2/5] Batch 13700/14335 Train_loss 1.6857614777163819 
Epoch [2/5] Batch 13800/14335 Train_loss 1.6860474042287255 
Epoch [2/5] Batch 13900/14335 Train_loss 1.6859771683061777 
Epoch [2/5] Batch 14000/14335 Train_loss 1.686019184390193 
Epoch [2/5] Batch 14100/14335 Train_loss 1.6860896953992595 
Epoch [2/5] Batch 14200/14335 Train_loss 1.6855209309083878 
Epoch [2/5] Batch 14300/14335 Train_loss 1.6852729802154243 
Epoch: 2/5 	Training Loss: 1.685145 	Validation Loss: 1.679721 Duration seconds: 3896.95174407959 
best_valid_loss_fold [1.6726641575317314] Best_Epoch [2]Epoch [3/5] Batch 0/14335 Train_loss 1.4079280197620392 
Epoch [3/5] Batch 100/14335 Train_loss 1.674604225571793 
Epoch [3/5] Batch 200/14335 Train_loss 1.656094409562462 
Epoch [3/5] Batch 300/14335 Train_loss 1.7046308387504068 
Epoch [3/5] Batch 400/14335 Train_loss 1.6751507388200249 
Epoch [3/5] Batch 500/14335 Train_loss 1.6807718247085988 
Epoch [3/5] Batch 600/14335 Train_loss 1.6631087132678453 
Epoch [3/5] Batch 700/14335 Train_loss 1.666158594286731 
Epoch [3/5] Batch 800/14335 Train_loss 1.6584182525990756 
Epoch [3/5] Batch 900/14335 Train_loss 1.6631942147287757 
Epoch [3/5] Batch 1000/14335 Train_loss 1.6723798621784558 
Epoch [3/5] Batch 1100/14335 Train_loss 1.6820188332941184 
Epoch [3/5] Batch 1200/14335 Train_loss 1.6842447673525045 
Epoch [3/5] Batch 1300/14335 Train_loss 1.6828675290353476 
Epoch [3/5] Batch 1400/14335 Train_loss 1.6783081656647614 
Epoch [3/5] Batch 1500/14335 Train_loss 1.679714972191775 
Epoch [3/5] Batch 1600/14335 Train_loss 1.6757196116073292 
Epoch [3/5] Batch 1700/14335 Train_loss 1.6716106132610205 
Epoch [3/5] Batch 1800/14335 Train_loss 1.6705780334021898 
Epoch [3/5] Batch 1900/14335 Train_loss 1.6678314148862383 
Epoch [3/5] Batch 2000/14335 Train_loss 1.666686976107879 
Epoch [3/5] Batch 2100/14335 Train_loss 1.6737900311566147 
Epoch [3/5] Batch 2200/14335 Train_loss 1.6749899409904312 
Epoch [3/5] Batch 2300/14335 Train_loss 1.6781681049768948 
Epoch [3/5] Batch 2400/14335 Train_loss 1.6778789305503246 
Epoch [3/5] Batch 2500/14335 Train_loss 1.6752444941257059 
Epoch [3/5] Batch 2600/14335 Train_loss 1.6767237708258977 
Epoch [3/5] Batch 2700/14335 Train_loss 1.675124282830404 
Epoch [3/5] Batch 2800/14335 Train_loss 1.673858222012667 
Epoch [3/5] Batch 2900/14335 Train_loss 1.6720449492612695 
Epoch [3/5] Batch 3000/14335 Train_loss 1.6740576311032282 
Epoch [3/5] Batch 3100/14335 Train_loss 1.6728608142638621 
Epoch [3/5] Batch 3200/14335 Train_loss 1.6734200188240123 
Epoch [3/5] Batch 3300/14335 Train_loss 1.6771373204532554 
Epoch [3/5] Batch 3400/14335 Train_loss 1.675942712741384 
Epoch [3/5] Batch 3500/14335 Train_loss 1.674228598733726 
Epoch [3/5] Batch 3600/14335 Train_loss 1.67317752129202 
Epoch [3/5] Batch 3700/14335 Train_loss 1.6714524843102692 
Epoch [3/5] Batch 3800/14335 Train_loss 1.6735480223277373 
Epoch [3/5] Batch 3900/14335 Train_loss 1.6722957467408677 
Epoch [3/5] Batch 4000/14335 Train_loss 1.6714400810838281 
Epoch [3/5] Batch 4100/14335 Train_loss 1.6713454821881681 
Epoch [3/5] Batch 4200/14335 Train_loss 1.668742491888719 
Epoch [3/5] Batch 4300/14335 Train_loss 1.6696676467167475 
Epoch [3/5] Batch 4400/14335 Train_loss 1.6700062812495384 
Epoch [3/5] Batch 4500/14335 Train_loss 1.669146158678469 
Epoch [3/5] Batch 4600/14335 Train_loss 1.6693600601160612 
Epoch [3/5] Batch 4700/14335 Train_loss 1.667553454421982 
Epoch [3/5] Batch 4800/14335 Train_loss 1.6677687815597122 
Epoch [3/5] Batch 4900/14335 Train_loss 1.6683891312677357 
Epoch [3/5] Batch 5000/14335 Train_loss 1.6685754930352097 
Epoch [3/5] Batch 5100/14335 Train_loss 1.6675789554933313 
Epoch [3/5] Batch 5200/14335 Train_loss 1.6694174333189205 
Epoch [3/5] Batch 5300/14335 Train_loss 1.6688778728297287 
Epoch [3/5] Batch 5400/14335 Train_loss 1.6703800960804132 
Epoch [3/5] Batch 5500/14335 Train_loss 1.6697442704746341 
Epoch [3/5] Batch 5600/14335 Train_loss 1.671153538685955 
Epoch [3/5] Batch 5700/14335 Train_loss 1.6701522307466194 
Epoch [3/5] Batch 5800/14335 Train_loss 1.6687691338595347 
Epoch [3/5] Batch 5900/14335 Train_loss 1.669473577668921 
Epoch [3/5] Batch 6000/14335 Train_loss 1.6703490672424781 
Epoch [3/5] Batch 6100/14335 Train_loss 1.6696136645084911 
Epoch [3/5] Batch 6200/14335 Train_loss 1.6701971186594393 
Epoch [3/5] Batch 6300/14335 Train_loss 1.6705787546047046 
Epoch [3/5] Batch 6400/14335 Train_loss 1.6700941257422053 
Epoch [3/5] Batch 6500/14335 Train_loss 1.6700523238359204 
Epoch [3/5] Batch 6600/14335 Train_loss 1.6710485016495111 
Epoch [3/5] Batch 6700/14335 Train_loss 1.6714991547290718 
Epoch [3/5] Batch 6800/14335 Train_loss 1.6698985439576641 
Epoch [3/5] Batch 6900/14335 Train_loss 1.6686851680850987 
Epoch [3/5] Batch 7000/14335 Train_loss 1.669024612050604 
Epoch [3/5] Batch 7100/14335 Train_loss 1.668157094931908 
Epoch [3/5] Batch 7200/14335 Train_loss 1.668325268707827 
Epoch [3/5] Batch 7300/14335 Train_loss 1.6672625692800829 
Epoch [3/5] Batch 7400/14335 Train_loss 1.6691261124726067 
Epoch [3/5] Batch 7500/14335 Train_loss 1.6682996882063408 
Epoch [3/5] Batch 7600/14335 Train_loss 1.6682805778176168 
Epoch [3/5] Batch 7700/14335 Train_loss 1.6678832787882507 
Epoch [3/5] Batch 7800/14335 Train_loss 1.6672764471310053 
Epoch [3/5] Batch 7900/14335 Train_loss 1.666895425119946 
Epoch [3/5] Batch 8000/14335 Train_loss 1.6666077198678368 
Epoch [3/5] Batch 8100/14335 Train_loss 1.666725369177436 
Epoch [3/5] Batch 8200/14335 Train_loss 1.6664218833769273 
Epoch [3/5] Batch 8300/14335 Train_loss 1.6664915103786193 
Epoch [3/5] Batch 8400/14335 Train_loss 1.6665658655629287 
Epoch [3/5] Batch 8500/14335 Train_loss 1.6668841271931711 
Epoch [3/5] Batch 8600/14335 Train_loss 1.6659272245871315 
Epoch [3/5] Batch 8700/14335 Train_loss 1.6660077575456753 
Epoch [3/5] Batch 8800/14335 Train_loss 1.6658805289604477 
Epoch [3/5] Batch 8900/14335 Train_loss 1.6655929021159794 
Epoch [3/5] Batch 9000/14335 Train_loss 1.6657368734573315 
Epoch [3/5] Batch 9100/14335 Train_loss 1.666136804762227 
Epoch [3/5] Batch 9200/14335 Train_loss 1.6662797782318695 
Epoch [3/5] Batch 9300/14335 Train_loss 1.6654555716838917 
Epoch [3/5] Batch 9400/14335 Train_loss 1.66625130682258 
Epoch [3/5] Batch 9500/14335 Train_loss 1.6662981214703427 
Epoch [3/5] Batch 9600/14335 Train_loss 1.666378376388715 
Epoch [3/5] Batch 9700/14335 Train_loss 1.665874989998026 
Epoch [3/5] Batch 9800/14335 Train_loss 1.6654030732379472 
Epoch [3/5] Batch 9900/14335 Train_loss 1.6659065874634145 
Epoch [3/5] Batch 10000/14335 Train_loss 1.6653655968556558 
Epoch [3/5] Batch 10100/14335 Train_loss 1.6650353954807506 
Epoch [3/5] Batch 10200/14335 Train_loss 1.6652516262497508 
Epoch [3/5] Batch 10300/14335 Train_loss 1.6657915184560557 
Epoch [3/5] Batch 10400/14335 Train_loss 1.6665941109199751 
Epoch [3/5] Batch 10500/14335 Train_loss 1.6668237734445162 
Epoch [3/5] Batch 10600/14335 Train_loss 1.6668441806664311 
Epoch [3/5] Batch 10700/14335 Train_loss 1.6667152394217462 
Epoch [3/5] Batch 10800/14335 Train_loss 1.666915757691443 
Epoch [3/5] Batch 10900/14335 Train_loss 1.6672784498590372 
Epoch [3/5] Batch 11000/14335 Train_loss 1.6666200060494574 
Epoch [3/5] Batch 11100/14335 Train_loss 1.6665746402117907 
Epoch [3/5] Batch 11200/14335 Train_loss 1.6662098096417386 
Epoch [3/5] Batch 11300/14335 Train_loss 1.6662988433005028 
Epoch [3/5] Batch 11400/14335 Train_loss 1.6659104180921798 
Epoch [3/5] Batch 11500/14335 Train_loss 1.665480362183218 
Epoch [3/5] Batch 11600/14335 Train_loss 1.6654664764909557 
Epoch [3/5] Batch 11700/14335 Train_loss 1.664774103667856 
Epoch [3/5] Batch 11800/14335 Train_loss 1.6650287858379784 
Epoch [3/5] Batch 11900/14335 Train_loss 1.6652558857581163 
Epoch [3/5] Batch 12000/14335 Train_loss 1.665251124071316 
Epoch [3/5] Batch 12100/14335 Train_loss 1.6653557085304278 
Epoch [3/5] Batch 12200/14335 Train_loss 1.6654234357790696 
Epoch [3/5] Batch 12300/14335 Train_loss 1.66557423489388 
Epoch [3/5] Batch 12400/14335 Train_loss 1.665401571697549 
Epoch [3/5] Batch 12500/14335 Train_loss 1.6659660445675688 
Epoch [3/5] Batch 12600/14335 Train_loss 1.6653333954662664 
Epoch [3/5] Batch 12700/14335 Train_loss 1.6643244866215754 
Epoch [3/5] Batch 12800/14335 Train_loss 1.6632343365759665 
Epoch [3/5] Batch 12900/14335 Train_loss 1.6632311940210502 
Epoch [3/5] Batch 13000/14335 Train_loss 1.6629446465193964 
Epoch [3/5] Batch 13100/14335 Train_loss 1.6629520279942747 
Epoch [3/5] Batch 13200/14335 Train_loss 1.6626727071318894 
Epoch [3/5] Batch 13300/14335 Train_loss 1.6633673053259743 
Epoch [3/5] Batch 13400/14335 Train_loss 1.6631354656245323 
Epoch [3/5] Batch 13500/14335 Train_loss 1.6628709495697813 
Epoch [3/5] Batch 13600/14335 Train_loss 1.663115086333448 
Epoch [3/5] Batch 13700/14335 Train_loss 1.6629003138399614 
Epoch [3/5] Batch 13800/14335 Train_loss 1.663055051652325 
Epoch [3/5] Batch 13900/14335 Train_loss 1.6632897884289306 
Epoch [3/5] Batch 14000/14335 Train_loss 1.6634501093363567 
Epoch [3/5] Batch 14100/14335 Train_loss 1.6632175411503034 
Epoch [3/5] Batch 14200/14335 Train_loss 1.6630248753955335 
Epoch [3/5] Batch 14300/14335 Train_loss 1.6635801648603488 
Epoch: 3/5 	Training Loss: 1.663595 	Validation Loss: 1.656287 Duration seconds: 4314.762742996216 
Validation loss decreased (1.672664 --> 1.656287).  Saving model ... 
best_valid_loss_fold [1.656286999683029] Best_Epoch [3]Epoch [4/5] Batch 0/14335 Train_loss 1.0455933213233948 
Epoch [4/5] Batch 100/14335 Train_loss 1.656043568607604 
Epoch [4/5] Batch 200/14335 Train_loss 1.6255137958188555 
Epoch [4/5] Batch 300/14335 Train_loss 1.6247787044392867 
Epoch [4/5] Batch 400/14335 Train_loss 1.6346922037458778 
Epoch [4/5] Batch 500/14335 Train_loss 1.615919089037739 
Epoch [4/5] Batch 600/14335 Train_loss 1.615623997248548 
Epoch [4/5] Batch 700/14335 Train_loss 1.6137627961802246 
Epoch [4/5] Batch 800/14335 Train_loss 1.62629686091351 
Epoch [4/5] Batch 900/14335 Train_loss 1.6230256357679886 
Epoch [4/5] Batch 1000/14335 Train_loss 1.6258802544046473 
Epoch [4/5] Batch 1100/14335 Train_loss 1.6258729867752197 
Epoch [4/5] Batch 1200/14335 Train_loss 1.6294010103890342 
Epoch [4/5] Batch 1300/14335 Train_loss 1.6283947055576675 
Epoch [4/5] Batch 1400/14335 Train_loss 1.6258693504533455 
Epoch [4/5] Batch 1500/14335 Train_loss 1.62352617772955 
Epoch [4/5] Batch 1600/14335 Train_loss 1.6259269619699124 
Epoch [4/5] Batch 1700/14335 Train_loss 1.6244435897737584 
Epoch [4/5] Batch 1800/14335 Train_loss 1.6263992018761866 
Epoch [4/5] Batch 1900/14335 Train_loss 1.62860870717984 
Epoch [4/5] Batch 2000/14335 Train_loss 1.6284614400393602 
Epoch [4/5] Batch 2100/14335 Train_loss 1.629833054526229 
Epoch [4/5] Batch 2200/14335 Train_loss 1.6315001914652572 
Epoch [4/5] Batch 2300/14335 Train_loss 1.6299811314980863 
Epoch [4/5] Batch 2400/14335 Train_loss 1.629023144517353 
Epoch [4/5] Batch 2500/14335 Train_loss 1.6298576120118864 
Epoch [4/5] Batch 2600/14335 Train_loss 1.6278926570574306 
Epoch [4/5] Batch 2700/14335 Train_loss 1.6296304946490148 
Epoch [4/5] Batch 2800/14335 Train_loss 1.6306805240920679 
Epoch [4/5] Batch 2900/14335 Train_loss 1.6296301245103824 
Epoch [4/5] Batch 3000/14335 Train_loss 1.6294842794840434 
Epoch [4/5] Batch 3100/14335 Train_loss 1.628510047763019 
Epoch [4/5] Batch 3200/14335 Train_loss 1.6280625001298976 
Epoch [4/5] Batch 3300/14335 Train_loss 1.6261098091934927 
Epoch [4/5] Batch 3400/14335 Train_loss 1.6241160931130851 
Epoch [4/5] Batch 3500/14335 Train_loss 1.6232650770766672 
Epoch [4/5] Batch 3600/14335 Train_loss 1.6215798328404325 
Epoch [4/5] Batch 3700/14335 Train_loss 1.6206030074836144 
Epoch [4/5] Batch 3800/14335 Train_loss 1.620408497903652 
Epoch [4/5] Batch 3900/14335 Train_loss 1.6204341619316813 
Epoch [4/5] Batch 4000/14335 Train_loss 1.6220241247717513 
Epoch [4/5] Batch 4100/14335 Train_loss 1.6228350109750689 
Epoch [4/5] Batch 4200/14335 Train_loss 1.6227476822265101 
Epoch [4/5] Batch 4300/14335 Train_loss 1.6230800642807992 
Epoch [4/5] Batch 4400/14335 Train_loss 1.6230862665226502 
Epoch [4/5] Batch 4500/14335 Train_loss 1.6231094554010377 
Epoch [4/5] Batch 4600/14335 Train_loss 1.6238330131353333 
Epoch [4/5] Batch 4700/14335 Train_loss 1.6252957196647475 
Epoch [4/5] Batch 4800/14335 Train_loss 1.6263491359136424 
Epoch [4/5] Batch 4900/14335 Train_loss 1.6262151457565435 
Epoch [4/5] Batch 5000/14335 Train_loss 1.6272093138663655 
Epoch [4/5] Batch 5100/14335 Train_loss 1.6279723496048317 
Epoch [4/5] Batch 5200/14335 Train_loss 1.6268375987168047 
Epoch [4/5] Batch 5300/14335 Train_loss 1.6280296470262243 
Epoch [4/5] Batch 5400/14335 Train_loss 1.6269308128741644 
Epoch [4/5] Batch 5500/14335 Train_loss 1.6270371684945077 
Epoch [4/5] Batch 5600/14335 Train_loss 1.627326063090798 
Epoch [4/5] Batch 5700/14335 Train_loss 1.6266085701270745 
Epoch [4/5] Batch 5800/14335 Train_loss 1.6277511636271413 
Epoch [4/5] Batch 5900/14335 Train_loss 1.6289593077093802 
Epoch [4/5] Batch 6000/14335 Train_loss 1.6299504727755878 
Epoch [4/5] Batch 6100/14335 Train_loss 1.6294436822307246 
Epoch [4/5] Batch 6200/14335 Train_loss 1.6288699843007468 
Epoch [4/5] Batch 6300/14335 Train_loss 1.6295977067654615 
Epoch [4/5] Batch 6400/14335 Train_loss 1.628557513474515 
Epoch [4/5] Batch 6500/14335 Train_loss 1.6289476666658536 
Epoch [4/5] Batch 6600/14335 Train_loss 1.6290780713245863 
Epoch [4/5] Batch 6700/14335 Train_loss 1.6288506586052929 
Epoch [4/5] Batch 6800/14335 Train_loss 1.6298589406984463 
Epoch [4/5] Batch 6900/14335 Train_loss 1.629751186217066 
Epoch [4/5] Batch 7000/14335 Train_loss 1.6305787738376967 
Epoch [4/5] Batch 7100/14335 Train_loss 1.6310916824819521 
Epoch [4/5] Batch 7200/14335 Train_loss 1.6320604099424543 
Epoch [4/5] Batch 7300/14335 Train_loss 1.631272162646647 
Epoch [4/5] Batch 7400/14335 Train_loss 1.6313649605571572 
Epoch [4/5] Batch 7500/14335 Train_loss 1.6312513062813618 
Epoch [4/5] Batch 7600/14335 Train_loss 1.6311219287846312 
Epoch [4/5] Batch 7700/14335 Train_loss 1.6314788292350901 
Epoch [4/5] Batch 7800/14335 Train_loss 1.630827375897657 
Epoch [4/5] Batch 7900/14335 Train_loss 1.6321742279369489 
Epoch [4/5] Batch 8000/14335 Train_loss 1.6330730777251066 
Epoch [4/5] Batch 8100/14335 Train_loss 1.6342557814956786 
Epoch [4/5] Batch 8200/14335 Train_loss 1.6345984587706366 
Epoch [4/5] Batch 8300/14335 Train_loss 1.6351278993679075 
Epoch [4/5] Batch 8400/14335 Train_loss 1.634581593949374 
Epoch [4/5] Batch 8500/14335 Train_loss 1.6347757016293596 
Epoch [4/5] Batch 8600/14335 Train_loss 1.6345592458336011 
Epoch [4/5] Batch 8700/14335 Train_loss 1.6346192936378845 
Epoch [4/5] Batch 8800/14335 Train_loss 1.63390619159439 
Epoch [4/5] Batch 8900/14335 Train_loss 1.6343231885953975 
Epoch [4/5] Batch 9000/14335 Train_loss 1.635676778136108 
Epoch [4/5] Batch 9100/14335 Train_loss 1.6359589375828127 
Epoch [4/5] Batch 9200/14335 Train_loss 1.6364145907343126 
Epoch [4/5] Batch 9300/14335 Train_loss 1.6361026718384244 
Epoch [4/5] Batch 9400/14335 Train_loss 1.6362419711942433 
Epoch [4/5] Batch 9500/14335 Train_loss 1.6353449359443637 
Epoch [4/5] Batch 9600/14335 Train_loss 1.6352123002368526 
Epoch [4/5] Batch 9700/14335 Train_loss 1.635828402798491 
Epoch [4/5] Batch 9800/14335 Train_loss 1.6362449047413665 
Epoch [4/5] Batch 9900/14335 Train_loss 1.6358154901963582 
Epoch [4/5] Batch 10000/14335 Train_loss 1.6356382014950852 
Epoch [4/5] Batch 10100/14335 Train_loss 1.6366160874114026 
Epoch [4/5] Batch 10200/14335 Train_loss 1.636637501866312 
Epoch [4/5] Batch 10300/14335 Train_loss 1.6369960057470432 
Epoch [4/5] Batch 10400/14335 Train_loss 1.6370946098985426 
Epoch [4/5] Batch 10500/14335 Train_loss 1.6368126601219155 
Epoch [4/5] Batch 10600/14335 Train_loss 1.6365658577172084 
Epoch [4/5] Batch 10700/14335 Train_loss 1.6369447353960989 
Epoch [4/5] Batch 10800/14335 Train_loss 1.6372270975046364 
Epoch [4/5] Batch 10900/14335 Train_loss 1.6376472180870714 
Epoch [4/5] Batch 11000/14335 Train_loss 1.6378027629474652 
Epoch [4/5] Batch 11100/14335 Train_loss 1.6377030720780072 
Epoch [4/5] Batch 11200/14335 Train_loss 1.6372936987349278 
Epoch [4/5] Batch 11300/14335 Train_loss 1.6375846764816615 
Epoch [4/5] Batch 11400/14335 Train_loss 1.6380891659796244 
Epoch [4/5] Batch 11500/14335 Train_loss 1.638245601830545 
Epoch [4/5] Batch 11600/14335 Train_loss 1.6383189600644703 
Epoch [4/5] Batch 11700/14335 Train_loss 1.6385296394169946 
Epoch [4/5] Batch 11800/14335 Train_loss 1.6386391339718958 
Epoch [4/5] Batch 11900/14335 Train_loss 1.638867169087719 
Epoch [4/5] Batch 12000/14335 Train_loss 1.6381952500036137 
Epoch [4/5] Batch 12100/14335 Train_loss 1.6376385969891696 
Epoch [4/5] Batch 12200/14335 Train_loss 1.63755068096721 
Epoch [4/5] Batch 12300/14335 Train_loss 1.6376366271827338 
Epoch [4/5] Batch 12400/14335 Train_loss 1.637252507222587 
Epoch [4/5] Batch 12500/14335 Train_loss 1.6370016095806537 
Epoch [4/5] Batch 12600/14335 Train_loss 1.6374764364201222 
Epoch [4/5] Batch 12700/14335 Train_loss 1.637710823393926 
Epoch [4/5] Batch 12800/14335 Train_loss 1.63707511675152 
Epoch [4/5] Batch 12900/14335 Train_loss 1.636562407306669 
Epoch [4/5] Batch 13000/14335 Train_loss 1.6369376893126408 
Epoch [4/5] Batch 13100/14335 Train_loss 1.6369779656103263 
Epoch [4/5] Batch 13200/14335 Train_loss 1.6363551415535196 
Epoch [4/5] Batch 13300/14335 Train_loss 1.6355221378789586 
Epoch [4/5] Batch 13400/14335 Train_loss 1.63600435191231 
Epoch [4/5] Batch 13500/14335 Train_loss 1.6355882018377415 
Epoch [4/5] Batch 13600/14335 Train_loss 1.6356659165977485 
Epoch [4/5] Batch 13700/14335 Train_loss 1.6361291339253476 
Epoch [4/5] Batch 13800/14335 Train_loss 1.6366069178098908 
Epoch [4/5] Batch 13900/14335 Train_loss 1.6370582579816042 
Epoch [4/5] Batch 14000/14335 Train_loss 1.636918133517034 
Epoch [4/5] Batch 14100/14335 Train_loss 1.6376214185472702 
Epoch [4/5] Batch 14200/14335 Train_loss 1.637848826923653 
Epoch [4/5] Batch 14300/14335 Train_loss 1.638001887634804 
Epoch: 4/5 	Training Loss: 1.637934 	Validation Loss: 1.645642 Duration seconds: 4288.781945705414 
Validation loss decreased (1.656287 --> 1.645642).  Saving model ... 
best_valid_loss_fold [1.6456417500781495] Best_Epoch [4]